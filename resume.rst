==========================================================
修士論文「位置提示技術を用いた状況での相互行為の分析」要約
==========================================================

1 Background
============
本論文では、実世界の環境の提示の中でも、空間に関するものが、離れた環境でどのように用いられるかを、相互行為分析の手法を用いて分析した。この背景には、コンシューマコンピューティングの技術の進展により、新たな遠隔地での共同作業の可能性が開かれたことがある。現在、SOHOやノマドワーキングなどの、特定の組織や場所に縛られない働き方が提唱されている。一方で、このような働き方ができるような業種は、いわゆるホワイトカラーや、ソフトウェア開発など一部に限られる。これは、現在普及しているPCのインタフェースがオフィスワークを目的としたものであることに大きく起因すると考えられる。画像処理、拡張現実感技術や、「タッチ」を中心としたタンジブルなインタフェースが安価に手に入りつつあるが、これを実用的に応用する試みはまだ少ない。本論文では、この可能性を模索することを目的とする。

2 Technological Overview
========================
(何かまとめ方がdourishの'Where the action is'に似ているが気にしない)
この方針を、タンジブル・インタフェースおよび遠隔共同作業の観点で整理する。

タンジブルインタフェース
------------------------
まず、本論で扱う技術は記号操作の枠に止まらず、実際に手で触ることができる空間に関わり、またそのように操作できるという特徴がある。前者に関しては、空間的広がりや、方向などを含んだものをコンピュータで扱えることを可能にするセンシング技術の進歩が関わっている。後者に関しては、ユーザーの物理的な操作を画像処理や加速度の認識によってインタフェースにできる技術が関わっている。基本的に、いわゆる拡張現実感技術も、単なる3Dの提示だけではなく、実際に手で操作できるという特性を持つ。

もう一つの特徴が、単なる情報処理ではなく、共同で作業を行えるというものである。(要調べ)

この2つにより、その場にいなくても、実空間での作業を、できるだけその場にいるのと近い形で共同して行うことができることが、近年の技術の可能性の大きな特徴であることがわかる。一方で、この様な技術や作業には、今までと異なる問題がある。私たちはどのように実際の空間を理解し、お互いにその理解を示しているのか？また、実際に見えて聞こえて触れる空間では、文字によるものとは異なるやり方でそれが行われるはずである。これは遠隔地ではどうなってしまうのか？

3 Analytic Requirement
======================
以上で取り上げたような技術は、高度に環境に依存し、即時的な特徴を持つ。このため、主要な問題もHCIでメジャーな分析手法である行動科学に基づく手法では、不十分であるかずれていることが考えられる。そこで、本論文ではエスノメソドロジーに基づく相互行為分析の適用を試行する。これは、ビデオによって、その場に居合わせた人々の行為がどのように組織化されているかを記述する手法で、CSCWなどの分野でも比較的応用が多い。以下ではエスノメソドロジーと主要な手法である会話分析について、少なくとも著者の理解を示し、それを元に相互行為分析の特徴と可能性について説明する。

エスノメソドロジー
------------------
エスノメソドロジーは、創始者のHarold Garfinkelによって以下のように特徴づけられている。「私が「エスノメソドロジー」という言葉を使う際は、日常生活の組織立った巧妙な実践の、偶発的で継続的な達成としての、文脈指標的表現やその他の実践的行為の規範的特徴の研究を指す」([Garfinkel1967]_, p11)。つまり、我々が何かの枠組みをもって行為を説明する以前に、人々の実践的行為はすでに秩序立っている。この秩序を解明することが、エスノメソドロジーの最も基本となる考え方である。とはいえ、エスノメソドロジーは、単に人々の日常を明らかにする、ということではない。(この辺そのうち説明する)

この議論では、具体的にどう明らかにするのか、というところまでは踏み込んでいない。エスノメソドロジーを具体的にどうやっていくのかということに関しては、当時エスノメソドロジーが大きな影響を与え、またその代表的な研究手法となった会話分析について触れる[#]_。会話分析は、主にSacks, Schegloff, Jeffersonらによって開始された、会話の組織化に関する広範な研究である。会話分析の対象は近年Schegloff2007によって以下のように特徴づけられている。

* 順番交代 (turn-taking) 問題:会話において誰が次に話すのか?またそれはいつ行われるのか?
* 行為形成 (action-formation) 問題:どのように、言語、身体や、相互行為の環境、相互行為内の位置などのリソースが、設計された通りの構造に、また受け手に、その規模もわからないのに特定の行為 (例えば、依頼、招待、許可、不平、同意、知らせ、警告、拒絶など) として認識されるように形成されるのか?
* シークエンス組織 (sequence-organazational) 問題:どのように、次の順番が前の順番と「筋の通った」ものとして形成されるのか?また、そもそも「筋が通った」の本質とは何か?
* トラブル (trouble) 問題:どのように話し、聞いたり、会話や相互行為を理解する際のトラブルが、それが起こった際に止まらず、間主観性が維持、修復され、順番やシークエンス、活動が可能な完了へと進むように扱われるのか?
* 言葉の選択 (word-selection) 問題:どのように順番の単位となる構成要素が選択されるのか?また、どのようにその選択が、受け手が理解を達成できるように知らせ、形成されるのか?
* 全体構造の組織化 (overall structural organization) 問題:相互行為の出来事の全体的な組織は、どのように組み立てられるのか?その構造とは何か?また、どのように全体構造の配置が、その構造と、シークエンスや順番としての会話を知らせるのか?



会話分析においては、会話の録音と、それを文字に起こして分析を容易にするトランスクリプトが分析の基礎になる。先駆的な研究によって、会話の組織化には発話の間や複数の発話のオーバーラップなどが有意であるということが明らかになっている。これらを含めて書き起こせるようにしたのが、Jefferson Systemであり、後の相互行為分析に使われるトランスクリプトでもその拡張が使われている。特有の記号などについては実際の分析で必要なものをその都度説明する。

相互行為分析
------------
「相互行為分析」は、主にGoodwin, Heathらによって始められた、会話も含めた身体的相互行為をビデオによって分析する方法である。対面した相互行為では、会話の書き出しだけでは発話のポーズなどを説明できない場合がある。もしくは、会話がなくても何らかの相互行為を組織させる、ということはよくあることである。相互行為分析は、前述の会話分析の拡張ではあるが、環境、指示などのあり方にさらに迫ることができる。

相互行為分析が明らかにした知見
------------------------------

相互行為分析と拡張現実感技術
----------------------------

相互行為分析とCSCW
-------------------

4 Issues of Design Process
==========================

5 Fieldwork: Geogeo Stamp Rally
===============================

6 Experiment: Augmented Panorama Viewer
=======================================
本章では、2010年7月に行った実験「パノラマを用いた共同作業」を取り扱う。

コンセプト
----------
遠隔で共同作業を行う手段には、様々なものがある。例えば音声や文字(チャット)、映像などは従来から利用されている。本実験で用いられたものは、その中でも「ものを配置する」ということにフォーカスを当て、そのために「パノラマ」すなわち360度全ての方向を写した映像を利用することを考えた。

この表示の形式は、葛岡、山崎らによる一連のGestureManの研究に影響を受けた。GestureManでは、Body Metaphorという設計思想により、首に配置されたカメラを動かして様々な方向を見ることができる。このため、首の動きを見ることで指示者がどこを見ているか作業者が見ることができ、円滑な指示が可能になる。一方で、現状でロボットは比較的大きなものになるため、作業場所によっては導入できるとは限らない。このため、別のインタラクションを、似たような設計論で実現できないかということを検討した。結果として首を回すかわりにパノラマの提示を、またパノラマを見ている位置を視覚的に提示する方針を採用した。

360度の映像は、以下のような利点から、ものの配置に有用であるように見える。

* 配置を行う場所の全景を見ることができる
* 作業者と物体、配置場所の位置関係を把握することができる
* 作業者に指示を行う際に、場所のどこを指すかをわかりやすく説明できる可能性がある

一方で、以下のような問題も起こる。

* パノラマをどう表示するか？ - パノラマは元々全ての方向を写したものであるため、ただ広げただけでは、位置関係がわかりにくい
* パノラマの特定の部分を見ながら指示をしていることを、どう作業者に伝えるか？

このような問題を解決するために、パノラマを円筒形に表示する形式を採用した。TWISTARに代表される、没入型で360度の視野を確保するシステムでは、人が円筒の中に入り、中から何らかの形で表示された360度の映像を見るという形式をとっている。しかし、この形式では装置が大規模になってしまい、場所をとってしまうという問題がある。このため、本実験で用いた表示形式は、円筒に360度の映像が表示されているのを、外から見る形式を採用した。

これを実現するために、拡張現実感技術を用いた。ここで用いた拡張現実感技術は、ARToolKitというマーカーを使ったシステムで、民生用として一般的に用いられているものである。ARToolKitでは、以下のようなフローで現実空間に3Dの物体を表示する。

* カメラなどで映像のフレームを読み込む
* 画像認識により、マーカーの位置を特定する
* マーカーの位置を原点として、映像に写っている空間の3次元座標を特定する
* 3次元空間に3Dの物体を描画する

この3Dの物体を円筒にし、随時パノラマ映像をテクスチャマッピングすることで、先のような表示形式を実現した。これにより、マーカーが表示された位置に、円筒形のパノラマが表示される。マーカーを見る方向を変えたり、回したりすると、パノラマの別の方向を見ることができる。この方式のもう一つの利点は、パノラマのどこを見ているかを画像処理によって特定できるということである。画面の下方向が3Dのどの方向に当たるかを見ることで、ユーザーがどこを見ているかを推定し、作業者に提示することができる。しかし、この特徴は実際には時間の関係から実装しなかった。

システムの概要
---------------
実際に実装したシステムは、指示者側、作業者側の2つに大きく分かれ、この2つをネットワークで接続することで実現している。

まず、作業者側では、パノラマ映像のキャプチャと送信を行う。パノラマ映像は、通常は全方位カメラ(Omni-Directional Camera)という特殊なカメラを用いるが、今回は予算の問題から(本研究は一切大学からの予算を用いていない)、市販のWebカメラと半球ミラーから自作した。WebカメラはLogicool QCAM-200Vを用いた。半球ミラーは、いくつかの口径のものを試し、直径7cmのものを採用した。まず半球ミラーを机などの上に設置し、Webカメラを真上から見下ろすように、ちょうど良い高さに設定すればパノラマ映像を取得できる。

7 Results
=========

8 Conclusion
============

.. [Garfinkel1967] Garfinkel, H.,1967, "Studies in Ethnomethodology", Prentice-Hall, p.11

.. rubric:: 註
.. [#] 別の手法として、概念分析などがあるがここでは触れない。

