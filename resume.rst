==========================================================
修士論文「位置提示技術を用いた状況での相互行為の分析」要約
==========================================================

(第一部)

背景と目的
============
(要出典)(分厚く)本論文では、実世界の環境の提示の中でも、空間に関するものが、離れた環境でどのように用いられるかを、相互行為分析の手法を用いて分析した。この背景には、コンシューマコンピューティングの技術の進展により、新たな遠隔地での共同作業の可能性が開かれたことがある。現在、SOHOやノマドワーキングなどの、特定の組織や場所に縛られない働き方が提唱されている。一方で、このような働き方ができるような業種は、いわゆるホワイトカラーや、ソフトウェア開発など一部に限られる。これは、現在普及しているPCのインタフェースがオフィスワークを目的としたものであることに大きく起因すると考えられる。画像処理、拡張現実感技術や、「タッチ」を中心としたタンジブルなインタフェースが安価に手に入りつつあるが、これを実用的に応用する試みはまだ少ない。本論文では、この可能性を模索することを目的とする。

本論文の構成
------------
本論文では、エスノメソドロジー、相互行為分析のシステムデザインへの適用が主軸に置かれている。しかし、これ自体が主題ではなく、あくまで技術的環境の変化がこのような手法への注目や重要性を喚起している。よって、本論はまず、昨今の技術的環境の変化を概観しながら(1,2章)、エスノメソドロジーとシステムデザインとの関係についてのレビューを行い(3,4章)、その実際例として著者が関わったフィールドワークと実験について取り扱う(5,6章)。これらを便宜上第1部から第3部とする。

技術的概観
=============

(何かまとめ方がdourishの'Where the action is'に似ているが気にしない、まとめる際に当該文献を参照するのが適切)

この方針を、タンジブル・インタフェースおよび遠隔共同作業の観点で整理する。

実世界志向インタラクション
--------------------------
要求事項

* 実世界志向インタラクションの諸相(AR,タンジブルインタフェースなど)
* GUIから実世界志向インタラクションへの変化の特徴を明らかにする
* 現在普及し始めた実装(OpenCV, ARToolKit, OpenNI)
* 設計論にどのような変化をもたらしたか

まず、本論で扱う技術は記号操作の枠に止まらず、実際に手で触ることができる空間に関わり、またそのように操作できるという特徴がある。前者に関しては、空間的広がりや、方向などを含んだものをコンピュータで扱えることを可能にするセンシング技術の進歩が関わっている。後者に関しては、ユーザーの物理的な操作を画像処理や加速度の認識によってインタフェースにできる技術が関わっている。基本的に、いわゆる拡張現実感技術も、単なる3Dの提示だけではなく、実際に手で操作できるという特性を持つ。本節では、このような特性を持つ技術コンセプトのうち、「複合現実感」「タンジブルインタフェース」の2つについてまとめる。

実世界以前(GUI)
~~~~~~~~~~~~~~~
本論文では、バーチャルリアリティや実世界を志向したインタフェースに関連する分野について取り扱う。その中で重要なのが「実世界」とは何かということである。例えば実世界を、見て触ることのできる世界と定義できるだろう。しかし、現存するパーソナルコンピュータなどは明らかに見て触ることができるものの、実世界を志向したものとして扱われることはほとんどない。この問題を明確にし、バーチャルリアリティや実世界志向インタフェースが何を実現するのかについて検討するため、まずは現在のパーソナルコンピュータについて少しまとめる。

パーソナルコンピュータのユーザインタフェースの類型として現在典型的なものが、GUI(Graphical User Interface)である。例えば、本論文の執筆環境は、LinuxのCompizというオーソドックスなGUIに、論文本体の編集画面、文献をまとめたファイルブラウザ、文献を表示するドキュメントビューワーの3つのウインドウからなる。これらをタッチパッドのクリックによって切り替えることができ、タッチパッドの右端を上下になぞると文献のページをめくることができる。

GUIによるコンピュータの操作を可能にする概念は、椎尾によって以下のようにまとめられている。

* 直接操作:コンピュータ画面に表示した物体を、ユーザが指示装置で動かすことで、コンピュータを操作する手法。ユーザは物理的な物体を操作している錯覚を覚え、わかりやすいインタフェースを実現できる。また、状態を直感的に見て操作できるため、コンピュータの動作を把握、支配している感覚を得られる。物を操作する能力は幼児期に獲得するものであるため、緊張感や負担が少なく、知的作業の妨げになりにくい。
* メタファー:GUIでは、コンピュータ画面を事務机の上(デスクトップ)に喩えた、デスクトップメタファー(desktop metaphor)が採用されて( [Siio2010]_ , p.108)いる。つまり、書類、フォルダ、アプリケーションなどが実際の机を模してアイコンとして表示されている。メタファーはコンピュータの機能の理解と学習を容易にし、現実世界の知識を利用できる。ただし、現実とかけはなれた挙動をする場合はこの限りではない。
* WYSIWIG:What you see is what you getの略。最終的に出力される文書や図版と、見かけ上全く同じものをディスプレイに表示し、操作することができる。
* やりなおし:GUIでは操作の手がかりが多く表示されているため、ユーザーは試行錯誤によって操作を習得する。このためにはやり直しができる機構が必要である。
* モード:コンピュータシステムの状態によって、ユーザーが行う操作の意味が変わったり、実行できる操作に制限がかかるインタフェース( [Siio2010]_ , p.111)を、モーダルなインタフェース、そうでないものをモードレスなインタフェースと言う。モードはユーザーの作業の妨げになるため、モードレスが推奨されるが、作業を中断してでも通知、確認する重大な場面ではモードが使われる。
* GUI設計のガイドライン:複数のアプリケーションで統一した操作を提供すれば、ユーザが操作方法を学習する負担を削減できる。そのために設計のガイドラインと、共通して使える部品を開発者に提供する必要がある。

以上 [Siio2010]_ , pp.107-115より

このうち、「直接操作」と「メタファー」はGUI全体に関わる事柄である。それは開発者にも同様に認知されている。最初に普及したGUIを搭載したコンピュータであるAppleのMacintoshでは、「Macintosh Human Interface Guidelines」という書籍を開発者向けに出版している。その中の「ヒューマンインタフェースの基礎」という章では、メタファー、直接操作、WYSIWIG、一貫した操作、モードなどについて取り上げている。これは、以上の概念が単なる設計思想に留まらないことを示している。

この2つは、一見して身体的な「タッチ」という操作を実現しているAppleの「iPhone」にも一貫して重要視されている。iPhoneのアプリケーションを開発者が提供する際にはAppleの審査を受ける必要があるが、その中で最も重要な審査基準である「iOS Human Interface Guidelines」では、タッチ機能は直接操作やメタファーをさらに補強するものと位置づけている。

  iOSのユーザーはマルチタッチのため、直接操作の強い感覚を楽しむことができる。ジェスチャーの利用は、画面上の見ている物体に大きな親近感と、それを制御している感覚を与える。(p.20)
  人々は現実的な画面上の物体と物理的にインタラクションを行い、多くの場合現実世界の物体に対するかのように操作できる。(p.21)

iPhoneでは触るという操作は、あくまで画面上のメタファーに対して行われる。これは明らかにGUIの延長線上にある製品である。

実世界志向インタフェース
~~~~~~~~~~~~~~~~~~~~~~~~~
以上で見たように、基本的にコンピュータや携帯電話のインタフェースはGUIの延長線上にある。しかし、GUIの問題点やコンピュータを取り巻く環境の変化を元に、新たなインタフェースが幾つか生み出されている。それらはGUIのような一つの概念ではないが、相互に影響しながら研究が行われてきた。

実世界志向インタフェース [Rekimoto1996]_ は、その中でも「実世界での人間の作業を支援しようという研究の流れ( [Rekimoto1996]_ , p.2 )」という広い範囲を取り扱う概念である。暦本は、実世界志向インタフェースの特徴を以下のように要約している。

* インタフェースの透明化
* 実世界状況の認識
* 人間の能力の強化
* 実世界情報とコンピュータ情報の関係

タンジブルインタフェース
~~~~~~~~~~~~~~~~~~~~~~~~

Augmented Reality/Mixed Reality
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
(「The Engineering of Mixed Reality Systems」「バーチャルリアリティ学」「ヒューマンコンピュータインタラクション入門」あたりからAR/MRのreview)
その一つの方向性が、拡張現実感(Mixed Reality)、拡張現実感(Augmented Reality)と呼ばれるものである。この2つの概念は互いに重複することも多いため、本節では同じものとして取り扱う。現在コンシューマ分野で注目を集めている(「ARのすべて」)分野であり、主に実際の空間の映像をカメラで逐一取り込み、それに合わせて3Dオブジェクトや文字情報などを重ねるというのが、よく知られている認識である。

現況
~~~~

よく知られている製品の例が、ARToolKitとセカイカメラである。ARToolKitは、「マーカー」という、コンピュータが認識しやすい模様を用い、それが映像の中で認識された場合、その場所を基準として3Dの物体を表示するものである。セカイカメラは、iPhoneのアプリケーションで、主にGPSや加速度センサーなどの情報を元に、カメラ映像の上に文字などが書き込まれた吹き出しを表示させ、あたかも吹き出しが実世界にあるかのように見せるものである。

コンシューマ領域での実世界志向技術の現況は、どのような技術がコモディティになっているかによってある程度知ることができるだろう。

CSCW
----

もう一つの特徴が、単なる情報処理ではなく、共同で作業を行えるというものである。(要調べ)

問題設定
--------

この2つにより、その場にいなくても、実空間での作業を、できるだけその場にいるのと近い形で共同して行うことができることが、近年の技術の可能性の大きな特徴であることがわかる。一方で、この様な技術や作業には、今までと異なる問題がある。私たちはどのように実際の空間を理解し、お互いにその理解を示しているのか？また、実際に見えて聞こえて触れる空間では、文字によるものとは異なるやり方でそれが行われるはずである。これは遠隔地ではどうなってしまうのか？

(第二部)
(ここを重点的に)

分析の方法論と方針
======================
(むしろ、全体を概観するより、第1部に合わせてコンセプトや方法が合わないものを大胆にバッサバッサ切り捨てていってもいいのでは？)

以上で取り上げたような技術は、高度に環境に依存し、即時的な特徴を持つ。このため、主要な問題もHCIでメジャーな分析手法である行動科学に基づく手法では、不十分であるかずれていることが考えられる。そこで、本論文ではエスノメソドロジーに基づく相互行為分析の適用を試行する。これは、ビデオによって、その場に居合わせた人々の行為がどのように組織化されているかを記述する手法で、CSCWなどの分野でも比較的応用が多い。以下ではエスノメソドロジーと主要な手法である会話分析について、少なくとも著者の理解を示し、それを元に相互行為分析の特徴と可能性について説明する。

以降の議論では、主に分析の方法について取り扱うが、社会学の分析手法と、システムデザインの目的、手法、アウトプットなどを混在して扱うことになるため、それらが錯綜してしまいがちである。つまり、

* エスノメソドロジーは何に焦点を置き、どうやってそれを分析し、それによって何を得るのか
* システムのコンセプトはどう決定され、どう作って、どうちゃんと作られているかを評価するのか

という2種類の異なる立場から、少なくとも分析を行う立場において以下のようなことを決定しなければならない。

* システムのデザインという目的設定の元で、エスノメソドロジーをどう行い、何を得るのか

本章ではこの3点について、それぞれを検討することによって、エスノメソドロジーによるシステムが関わる状況の分析について明かにする。なお、ここでは主に分析を行う側にのみ焦点を当てるが、分析側とデザイン側が共同で作業を行うことの問題については次章で検討する。

概要
----
エスノメソドロジーは、単に日常生活を研究するのではなく、それが既に秩序だっているような手続きを研究する分野である。これを実際に記述する手法が会話分析や相互行為分析で、これらは相互行為のシークエンス的な組織化を詳細に明らかにする。これは、その場面である作業を達成するために、どのようにその場その場で成立する秩序を成員が理解し、次の相互行為につなげているかということがわかる。

エスノメソドロジー
------------------
(この辺から再構築する)
エスノメソドロジーは、創始者のHarold Garfinkelによって以下のように特徴づけられている。「私が「エスノメソドロジー」という言葉を使う際は、日常生活の組織立った巧妙な実践の、偶発的で継続的な達成としての、文脈指標的表現やその他の実践的行為の規範的特徴の研究を指す」([Garfinkel1967]_, p.11)。つまり、我々が何かの枠組みをもって行為を説明する以前に、人々の実践的行為はすでに秩序立っている。この秩序を解明することが、エスノメソドロジーの最も基本となる考え方である。とはいえ、エスノメソドロジーは、単に人々の日常を明らかにする、ということではない。(説明可能性と、できれば文脈指標性の議論)

この議論では、具体的にどう明らかにするのか、というところまでは踏み込んでいない。エスノメソドロジーを具体的にどうやっていくのかということに関しては、当時エスノメソドロジーが大きな影響を与え、またその代表的な研究手法となった会話分析について触れる [#]_ 。会話分析は、主にSacks, Schegloff, Jeffersonらによって開始された、会話の組織化に関する広範な研究である。会話分析の対象は近年 [Schegloff2007]_ (ページ洗い出し)によって以下のように特徴づけられている。

* 順番交代 (turn-taking) 問題:会話において誰が次に話すのか?またそれはいつ行われるのか?
* 行為形成 (action-formation) 問題:どのように、言語、身体や、相互行為の環境、相互行為内の位置などのリソースが、設計された通りの構造に、また受け手に、その規模もわからないのに特定の行為 (例えば、依頼、招待、許可、不平、同意、知らせ、警告、拒絶など) として認識されるように形成されるのか?
* シークエンス組織 (sequence-organazational) 問題:どのように、次の順番が前の順番と「筋の通った」ものとして形成されるのか?また、そもそも「筋が通った」の本質とは何か?
* トラブル (trouble) 問題:どのように話し、聞いたり、会話や相互行為を理解する際のトラブルが、それが起こった際に止まらず、間主観性が維持、修復され、順番やシークエンス、活動が可能な完了へと進むように扱われるのか?
* 言葉の選択 (word-selection) 問題:どのように順番の単位となる構成要素が選択されるのか?また、どのようにその選択が、受け手が理解を達成できるように知らせ、形成されるのか?
* 全体構造の組織化 (overall structural organization) 問題:相互行為の出来事の全体的な組織は、どのように組み立てられるのか?その構造とは何か?また、どのように全体構造の配置が、その構造と、シークエンスや順番としての会話を知らせるのか?

会話分析においては、会話の録音と、それを文字に起こして分析を容易にするトランスクリプトが分析の基礎になる。先駆的な研究によって、会話の組織化には発話の間や複数の発話のオーバーラップなどが有意であるということが明らかになっている。これらを含めて書き起こせるようにしたのが、Jefferson Systemであり、後の相互行為分析に使われるトランスクリプトでもその拡張が使われている。特有の記号などについては実際の分析で必要なものをその都度説明する。

(再構築前)

相互行為分析
------------

「相互行為分析」は、主にGoodwin, Heathらによって始められた、会話も含めた身体的相互行為をビデオによって分析する方法である。対面した相互行為では、会話の書き出しだけでは発話のポーズなどを説明できない場合がある。もしくは、会話がなくても何らかの相互行為を組織させる、ということはよくあることである。相互行為分析は、前述の会話分析の拡張ではあるが、環境、指示などのあり方にさらに迫ることができる。

相互行為分析が明らかにした知見
--------------------------------

Goodwin, Heath/Luffなどの「CSCW以前の」成果(流れの都合)

エスノメソドロジーとCSCW
------------------------

エスノメソドロジーが貢献しうる役割
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
エスノメソドロジーによる共同作業システムの分析がどのような役割を果たすかに関しては、いくつかの見解がある。これは後述するデザインプロセスの問題にも関連している。

Buttonによるまとめ([Button2009]_, pp.39-43)では、エスノメソドロジーのワーク研究が設計の目的に対して使われる際には、4種類の使い道があるとしている( [Button2009]_ , p.39)

* 批判:既存の設計手法で作られたワークフローシステムは、実際の場面に導入された場合に、詳細な分析をした際に明らかになるような、作業の組織化の状況に埋め込まれており即時的な特徴のために困難に直面してしまうということを示すために用いられる
* 評価:特定の技術デザインを評価するために用いられる。実際のワークプレイスにシステムを導入した際に得られたデータを分析し、システムの改善に活かす。
* 要求:実際のワークプレイスを分析して得られたデータを元に、システムの要求を決める。 Bentley1992 によれば、ワークプレイスの分析は要求を詳細に定義するのにはあまり有用ではないが、設計の際の適切な意思決定を提供する。
* 基礎的な関係:設計者とワークプレイスの分析者

(このほか、 [Randall2007]_ の5章、6章前半の議論)


具体的な成果例
~~~~~~~~~~~~~~

(Heath/Luff)

(Mixed Reality Labの一連のmixed reality関連の調査、Benford, Rodden, Crabtreeなど)

(Brownらの地図に関する研究)

(Kirkらのテーブルトップの実験)

( [Randall2007]_ の8章など)

システムデザインへの適用の問題
==================================

相互行為分析などの、エスノメソドロジーに影響を受けた手法(Ethnomethodology-informed Ethnographyや、会話分析なども含む)をどう実際のシステム設計に取り入れるかに関しては、その当初から議論が存在する。前章ではシステムが関わる状況でのエスノメソドロジーについて検討したが、分析のアウトプットは必ずしも設計者の関心の中にないかもしれない。例えば、あるタスクを行わせて各段階での作業時間を計測することは、システムの評価に有用だろう。また、新たなシステムを設計するために以前のシステムについてインタビューを行ったり、SD法によって感性を調査することは、少なくとも筋が通っている。しかし、エスノメソドロジーや相互行為分析に関しては、前章で見てきたように、単純に「実際の環境での使用を見る」「日常生活について理解する」などの視点で見ることができない。何より、分析結果が単純に何が良い悪いということを必ずしも提示しない。

そのような前提を元に、エスノメソドロジー的調査はどう行えばよいのだろうか。その中には、完全に設計を無視して行う方法から、設計の際に必要なことだけを集中的に分析する方法まで多様な可能性があり得る。また、それに応じて分析の設計に対する位置づけも変わってくる。本章では、エスノメソドロジー的分析の知見のシステムデザインでの位置づけられるか、システムデザインのプロセスの中の分析と分析者の位置づけ、またその実例について検討する。

90年代の論文(Suchman, Button, Hughes etc.)
00年代の解説書(Crabtree, Randall)

10年の入門書(Button, Heath)
Button「Studies of work and workplace in HCI」
1.motivation
■Grudinの「HCIのfifth stageはユーザーとの対話だ」はwork settingへの注目を意味するが、それはCSCW、特に社会学と共同した分野である。社会学の中でも、経験的なアプローチが理論より好まれる。
■Suchmanは、従来のHCIにおける認知科学的アプローチ、つまりユーザーを単独で見ることに対抗し、「使用」の社会的文化的状況という視点を導入した。一方、CSCW分野でも、人々の共同作業を促進するには、認知科学的モデルは適切でないことがわかった。Suchmanはそれに対してEMCAによる経験的研究という指針を示した。このほか、スカンジナビアのParticipatory Design運動は、技術開発における、ユーザーの作業状況での使用の重要性を指摘しつづけてきた。
2.Overview: A Paradigmatic Case
■HCIに対するワークの研究の適用は、システムへの批判につながる場合がある。Suchman-Winograd論争の事例。Bowersらの研究では、印刷作業が今までどうだったか、システムが導入されたらどう変わったかを分析した。システムが導入されたら、円滑な共同作業が妨げられてしまった。この原因は、設計者がワークフローを強制してしまったためだった。様々な過程は、状況に合わせられなければならない。そのためにうまくいかせるプロセスがあったはずだが、たまたま起こらなかったためにシステムに反映されなかったのだ。
■ワークの研究は、組織化をうまくいかせるやり方を明らかにする。それは、デザイン方針への批判だけでなく、それをうまくいかせることにもつながる。
4.Detailed description
1.批判:Suchman-Winograd論争
2.評価:Disembodied Conduct→読むか
3.要求定義
4.基礎的関係:Technomethodology

(roughなのでどうにかする)

なんかどうも界隈で意見が割れている話題として、新しいインタラクティブなものを作る際に、アイデアを重視するか、分析や観察を重視するかというものがある。パソコンでのGUIの発展とか、バーチャルリアリティとかの分野では、伝統的にまじめな工学から少し浮いた人間がいて、そいつがとんでもない発想をして時代を進化させるみたいな風潮がある。それに対し、まじめに数式とか計算とかをして分析をして、改善していくみたいな人たちや、近年の社会的な製品に対応するために社会学からやってきた連中が、こいつらが作っているものは、本当に世の中を良くしているのかわからんということを言い出したのが最近の話。

結果がどうであるかというと、どっちもどっちである。イマイチなアイデアでも、少し分析と改善を回しただけで凄まじいものになる場合があるし、逆に最初の製品のイメージがないと、分析のプロセスは回らない。典型的なのがAppleとMSで、Appleはアイデア重視にしたとたん爆発し、MSは研究所で分析の専門家をふんだんに入れた結果、地味だが良いものを出し始めてきた。これに関しては甲乙つけがたい。

で、いろいろなところでいろいろな態度が取られているわけだ。

* 設計と分析を完全に分ける。分析からインスピレーションを得る
* 自分の目で見たもの、体験したものを克明に記録し、それを設計に取り入れたりブレインストーミングしたりする
* 分析なんてどうでもいいからアイデアを作ってとにかく出す
* 最初から作るものは決まっている。あとは分析で洗練させる

まあこんな感じが典型かと。この内部でもいろいろあるので、一人一言あるといってもいい。一応デザイン思考とか人間中心設計とかある程度の方針はあるが、ほぼ必ずと言っていいほどアレンジがある。

一応近年の風潮としては、某国際的に権威のある会議では、アイデアを出すだけのが中心だったのが、分析をちゃんとやるのが通りやすくなっていると聞いた。で、「安易に参与観察とか取り入れるのはどうよ」みたいなセッションが中にある。

問題は、別の立場の人々と組む場合である。私が今まさにそれを考えているところである。私は基本的に社会学の人間である。しかし、過去のしがらみからバーチャルリアリティに関する制作物、コンセプトを出しているという感じである。だから、一応私個人で制作から分析まで見通せることにはなる(実際はとても無理)が、それでは単純に体が持たない。

今考えている態度としては、どうせみんな設計に対する立場が違うのだから、共同作業ではなく分業という側面でとらえるとうまく行くんじゃないかと思う。例えば、全く新しい技術コンセプトなどを出す場合、技術自体が定まっていないのだから、アイデアが主になる。一方、ある新技術が決まっていて、それを特定の場面に適用していくとなると、Workplaceの分析が不可欠である。しかし、この2つは矛盾しないし、ある程度の情報交換があれば平行して行うこともできるし、お互いにとってリソースとなる。

要は、インタラクティブなものに関わってる人は、まじめなやつにしても変なやつにしてもみんなアクが強いから、「何を作るか、分析するか」についてコンセンサスを得る必要がないし、互いになんか似たようなことをやって影響を与え合うのが良い。以前のように「いろんなアイデアを持った人がいて、アイデア同士が影響し合う」という時代ではなく、「いろんな態度を持った人がいて、分業を意識しないと話が通じない」という妥当な結論。


HCIとの関連における初期の議論
-------------------------------

(主にSuchman)

反復型開発とエスノグラフィー
------------------------------

(HughesのMoving-と、 [Randall2007]_ , できればCrabtreeも)

(およびその批判、Dourishとか「Ethonography considered harmful」など)

これらの議論に影響を及ぼしうるいくつかの新しい設計論
-------------------------------------------------------

(Agile Developmentなど、Iteration Approachの後に出てきたシステム開発)

(Design Thinkingについても一応)

(第3部)

Fieldwork: Geogeo Stamp Rally
===============================
これまで見てきたように、あるシステムが使われる状況をビデオに撮影し、分析するということは必ずしも定型的な作業ではない。本研究では、特定の場面やシステムに対して分析を行うのではなく、複合現実感や位置情報技術など、比較的漠然としたコンセプトでまとめることのできるシステムを、どう分析することができるかということを検討するのが目的である。

(基本的にint2010に出したもののreviceで行く。参考文献やデータなどを再構築する必要)

現在，iPhoneやスマートフォンなどの高度な携帯電話端末が，一般ユーザーに普及している段階にある．これらは，通話やメールなどの枠を遥かに超え，「セカイカメラ」などの位置に対応した情報をカメラ映像に重ねる技術など，従来からMixed Realityと分類されてきた技術を，エンドユーザーにまでもたらしつつある．現在は未だ普及の段階にまで達していないが，実世界とオンラインを結びつける試みに，携帯電話は今後も重要な役割を果たす可能性がある．

一方で，実世界の環境で，携帯端末がどう使われるかに関しては，十分な検討がされていないと見られる．携帯電話には，一人で画面に向き合うだけではなく，例えば電車内で若者が携帯電話に表示されたメール，画像などを見せあっているように，複数人で，場面に応じて共同的に利用するものとしての側面がある．本論文では，実際に携帯端末がどのように複数人によって，実世界の場面の組織化に利用されるかに関して，詳細な分析を行う．

フィールドについて
-------------------

屋外での情報機器の使用を観察する際は，公共のイベントなどの利用が有効である．実際の研究としては，Can You See Me NowというMixed Reality Gameの分析が挙げられる．2009年現在，国内ではその一種と言えるiPhoneを利用した位置情報ゲームが複数行われ始めている．

本研究では，「ジオジオスタンプラリー」という，レーダーのような形式で提示されたポイントの情報やヒントを頼りに，宝探しを行うゲームの調査を行った．これは2009年7月20日に行われた，全体で50人程度が参加したイベントである．

参加者はGPSの専門スタッフ1人を含む5人程度の8つのチームに分かれ，各チームにiPhoneが1台配布された．iPhoneにはDGRadar（図）がインストールされており，それを用いてゲームを行う．DGRadarはGPSで現在位置を取得し，レーダーのように現在位置を中心として，周辺（拡大縮小可）の登録されたポイントへの方角・距離と画像などの付加情報が表示されるアプリケーションである．

実際に行われたゲームは，（１）立教大学キャンパス内での人形探し（２）都電沿線でのスタンプラリーの2つであったが，本論文に関連する前者についてのみ記す．人形は1cm程度の高さのアヒルであり，マグネットによって金属部分に接着可能である．この人形がキャンパス内の5カ所に配置され，それぞれのポイントの位置情報のみがDGRadarに登録された．

各チームはこのアヒルを30分程度で可能な限り見つけるというルールであるが，特に勝敗などを決めるものではなく，純粋に楽しむ目的のものであった．ゲームの終わりに全員集合し，各チームの結果や動いた軌跡などを主催者が発表した．

本イベントには，田島が技術サポートの集団の一人として参加しており，その中で企画者に調査の提案をした．参加者には最初に集合した際に調査内容に関して説明を行い，全員に口頭で撮影の許可を得た．その後，1チームに対して全体で30分程度，小型のデジタルムービーカメラを用いて追跡して撮影を行った．このチームでは，持参のものと含めて2台のiPhoneを用いていた．

分析
----
本研究では，携帯端末の使用を，人々の共同作業の相互行為的な達成の観点で分析した．すなわち，単に一人で画面に向き合い，画面上の情報とインタラクションを図るというだけでなく，周囲の環境/人間と協調しながら，実世界に関係する作業を達成していくという観点である．

共同作業の達成を分析するにあたり，社会学のエスノメソドロジー的な相互行為分析の手法を用いた．これは，ビデオデータなどを用いて，その場に居合わせた人間の会話，指さしなどの身体的な相互行為が，継起的な秩序の中でどのように組織化されるかを分析する手法である．本研究では，特にiPhoneやその使用が，環境の中でどのように見られ，相互行為の中に組み込まれていくかに焦点を当てる．

指さしによる環境の指示
~~~~~~~~~~~~~~~~~~~~~~~
Goodwinは，環境の特定の対象を指す種類の指さしをSymbiotic Gestureとし，会話と全く異なる記号であるが，会話と協調して使われるものとしている．「ジオジオスタンプラリー」で見られた指さしは20件あったが，そのうちの10件がDGRadarを参照した「方角」の指示であった．典型的なものを断片1（図）に示す．以下では，Aの持つiPhoneをiA，Bの持つものをiBとする．

(Datas)

Aは自身のiPhoneを見ながら，次のポイントを発見して報告する．Bはそれを受け，Aの方向を向いて歩き始める．その途中で，AはiPhoneを継続して見ながら，ポイントについてもう一度報告し，一度iPhoneから目を離してポイントの方向を指差し，またiPhoneに視線を戻す．Bはそれを受け，指さしの方向を見てから二人とも歩き始める．

ここで注目する点が，断片1の2,3行目でAが自身のiPhoneを見ているということを，Bが見ているということである（図）．これにより，Bはその後の指さしがDGRadarの提示するポイントを指していることを理解できる．「向こうに」に伴った指さしは，特定の物体や，道路に沿って指したものではない．iPhoneの，方角を提示するDGRadarを見ているということを見た上で，方角を提示していると，意味のある形で理解できるのである．

「方角」と，進むべき「方向」は相互行為の中で明確に区別されていた．DGRadarを見た後の指さしと共に「曲がってってもいいんじゃない」という発話を行い，その後チームで建物を迂回する例が見られた．指さしは表示の方角を指しているが，その先には建物があった．このため，「あっち」「東」などの方角ではなく，「曲がってって」という発話が行われた．方角を，進むべき方向に再構成して発話を行ったのである．

iPhoneを見ているということにより，見ている人の体の向きが，DGRadarの方角を指していると見られた場合があった．ある場面では，Aは最初道路に沿って歩いていたが，iPhoneを覗き込んで横を向いた．それを見た他のメンバーが，向いている方向に歩き始めてしまった．それを受け，Aは「あ，違う，真向こう，真向こう，真向こう，向こう」と訂正を行い，本当にDGRadarが提示している方角を指さす．この場面ではAの見ているiPhoneと，メンバーが利用する資源であるAの体の向きという，2つの異なるエコロジーが問題を起こしている．

以上のように，ジオジオスタンプラリーではiPhoneを見ていることと，指さしや身体的配置は，関連づけられて理解されていた．

2台のiPhoneによる問題解決の試み
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ほとんどのチームで，GPSの精度の問題が発生していた．GPSの誤差は明確には表示されていなかったが，チームの相互行為の中で，複数のiPhoneを用いて明らかにした部分があった．断片2（図）はもともと進んでいた方向の異常に気づき，集合する直前のデータ，断片3（図）は集合してから問題解決を始めたデータである．

(Datas)

当初2人が別のiPhoneを持って歩いており，Aが指さしで先導していた．しかし，BがAの指差しの方向を見て，iBと照らし合わせ，Aに見える形でiBを指差す．Aは止まりiAを見て，BはiBを見ながらAに向かって歩き始める．それを受けてチーム全員が集合する．

集合後，1行目の発話で，Bの胴の向きがAのiPhoneへ向かい始める．Bの「北」の発話の段階では，Bは自身のiBを見ているが，iAを見て「きた？」と言いiAを指差す（図6）．その後ジェスチャーで2台の向きの違いを指摘し，iAの指す方角を聞く．それを受けたAの「イースト」の発話と指さしの後，iPhoneをBに手渡し，並べて見る．そこで初めて，専門家であるCが衛星状態について述べる（13行目）．

注目する点は2つある．まず，どのようにBがAのiPhoneを参照する状況ができたかである．集合前に既にBはiBの異常を示していたが，01行目と胴の動きでiAを見る準備がされている．その後，「北」でiBの表示の具体的な内容を示す．その後の「きた？」でiAを指差したことで，iAとiBの違いが示される．

次が，2台のiPhoneの比較である．iAとiBの表示の違いは理解されていたが，具体的にどう違うのかは，恐らく2台のiPhoneの向きの違いから，直観的にはわかりにくかった．03行目のなぞる動きや，06行目の「どっちなんですか」10行目の「てーと」という疑問がそれを示している．その直後，AはiAをiBと平行になるようにBに渡す（図7）．2つのiPhoneの示す方角は，既に「北」「イースト」で示されている．しかし，精度を問題にする場合，2台を比較可能，つまり平行にすることが必要であった．Cによる専門的な指摘は，2人の比較を見た直後である．

まとめ
------
本調査では，GPSを用いた宝探しゲームの中でiPhoneが環境の中でどのように理解され，複数人の相互行為の中に組織化されていくかを分析した．以下に分析の知見をより一般的な形でまとめる．

* 携帯端末を見たり操作していることは，他の参加者が見ることができ，使用者の身体的相互行為は携帯端末に関連したものとして理解された．
* 身体的配置により，誰かが使っている携帯端末は他の参加者にも利用可能になった．
* 複数の端末などがある場合，それらの配置が問題になり，調整される場合がある．また，それも見ることができる．

本分析の知見は，ゲームという特殊な設定の元でのものであるが，携帯端末を見ながら何かを行うということは，位置情報に限らず表示された文書，画像などに関連したものであることが示唆される．例えば「セカイカメラ」の場合，表示されたエアタグを実際に見なくても，ある程度近くにいれば，体の向きからどの方向のエアタグを見ているのか瞬時に理解できる．

また，例えばiPhoneの場合電子コンパスや加速度センサで，表示を回転させることが可能であるが，これらは持っている人の向きのみを反映でき，他の人間の身体の志向の反映は難しい．場合によっては渡すなどのインタフェース外の相互行為を考慮した設計も必要だろう．このように，本知見を通じて既存のシステムを再検討することも有効である可能性がある．

(オチる)

これによって何がわかったのか？
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
このフィールドで行われたことは、ゲームであり、位置や方向の特定という問題の解決であり、iPhoneの使用である。これらは単純に平行しているわけではなく、例えばゲームで点を取るために位置や方向を特定し、iPhoneを使用することでゲームを進めるなど相互に関係している。本分析でピックアップした断片では、iPhoneの使用を取り巻く指差しなどの身体的相互行為に主に注目した。しかし、これはiPhoneでの情報の提示が間違っているという批判にはならない。また、ゲーム全体に関わるような意思決定も主題としていない。このため、主に位置や方向の特定という問題がどのように解決されるか、ということが本分析の主要な知見だろう。これは、より外部環境のデータをセンシングして、提示するようなシステムでは身振りのあり方を考慮でき、またそれが実際に使用される場面で異なっていくということを示している。この点で、新たなシステムへの要求事項を扱っていると言える。

一方で、この分析では本当にゲームという場面全体を記述できなかったのだろうか。宝探しという主題を元に、我々は様々な場面を想像するだろう。しかし、今回は場面で起こりうる様々な局面を厳密に洗い出し、行為のモデルを作成し、ゲームをデザインしたというわけではない。つまり、ある意味で実際に始まってみないと、ゲームで起こることは予測できないことになる。これはプレイヤーにとっても同様である。この分析で何か場面について分かったものがあったとすれば、それはまだ知られていない事柄である。

そこでまず指摘できるのが、アヒル探しがチームの共同作業として行われたことである。これは注目に値する。例えば完全に障害物がない状況で、GPSの方角指示を元に移動を行ったとしたら、各人は同じ方向に進むため、コミュニケーションは必要ないと思われる。人が集まったら共同作業がされるとは限らない。

そこでゲームを一種の問題解決としてとらえた場合、問題とは何かということを問うことができる。前半のキャンバス内でのアヒル探しと、後半の都電沿線での宝探しではどう問題が異なるだろうか。例えば、ゲームのルールとDGRadarを元にすれば、「方向」の問題は見えてこない。また、GPSの不具合がゲームの障害となることは容易に想像できるが、実際にゲームをどう妨げたのか、また本当に妨げたかどうかには疑問が残る。GPSの問題をお互いに共有して、方向を見定めながら移動するということは、ゲームのルールを破壊するようなことではない。むしろ、ゲーム全体の問題解決の中で、間違えながら試行錯誤していく過程の中にうまく取り込まれている。このように、「iPhoneの位置表示アプリを使った」「宝探しゲーム」の見えない特徴が本分析によって明らかになっている。

この際、本分析はゲームの実際の達成の際の(ゲームのデザインが問題を解決するものではなく、問題をうまく作り出すことにあるという差異はあれど)問題を浮き彫りにしている。これは、ゲームの評価をしているといえ、この結果は例えば方角ではなく方向を提示してみる、GPSにわざと誤差を作っておくなどの、新たなゲームデザインにつなげることができる。

Experiment: Augmented Panorama Viewer
=======================================
本章では、2010年7月に行った実験「パノラマを用いた共同作業」を取り扱う。

コンセプト
----------
遠隔で共同作業を行う手段には、様々なものがある。例えば音声や文字(チャット)、映像などは従来から利用されている。本実験で用いられたものは、その中でも「ものを配置する」ということにフォーカスを当て、そのために「パノラマ」すなわち360度全ての方向を写した映像を利用することを考えた。

この表示の形式は、葛岡、山崎らによる一連のGestureManの研究に影響を受けた。GestureManでは、Body Metaphorという設計思想により、首に配置されたカメラを動かして様々な方向を見ることができる。このため、首の動きを見ることで指示者がどこを見ているか作業者が見ることができ、円滑な指示が可能になる。一方で、現状でロボットは比較的大きなものになるため、作業場所によっては導入できるとは限らない。このため、別のインタラクションを、似たような設計論で実現できないかということを検討した。結果として首を回すかわりにパノラマの提示を、またパノラマを見ている位置を視覚的に提示する方針を採用した。

360度の映像は、以下のような利点から、ものの配置に有用であるように見える。

* 配置を行う場所の全景を見ることができる
* 作業者と物体、配置場所の位置関係を把握することができる
* 作業者に指示を行う際に、場所のどこを指すかをわかりやすく説明できる可能性がある

一方で、以下のような問題も起こる。

* パノラマをどう表示するか？ - パノラマは元々全ての方向を写したものであるため、ただ広げただけでは、位置関係がわかりにくい
* パノラマの特定の部分を見ながら指示をしていることを、どう作業者に伝えるか？

このような問題を解決するために、パノラマを円筒形に表示する形式を採用した。TWISTARに代表される、没入型で360度の視野を確保するシステムでは、人が円筒の中に入り、中から何らかの形で表示された360度の映像を見るという形式をとっている。しかし、この形式では装置が大規模になってしまい、場所をとってしまうという問題がある。このため、本実験で用いた表示形式は、円筒に360度の映像が表示されているのを、外から見る形式を採用した。

これを実現するために、拡張現実感技術を用いた。ここで用いた拡張現実感技術は、ARToolKitというマーカーを使ったシステムで、民生用として一般的に用いられているものである。ARToolKitでは、以下のようなフローで現実空間に3Dの物体を表示する。

* カメラなどで映像のフレームを読み込む
* 画像認識により、マーカーの位置を特定する
* マーカーの位置を原点として、映像に写っている空間の3次元座標を特定する
* 3次元空間に3Dの物体を描画する

この3Dの物体を円筒にし、随時パノラマ映像をテクスチャマッピングすることで、先のような表示形式を実現した。これにより、マーカーが表示された位置に、円筒形のパノラマが表示される。マーカーを見る方向を変えたり、回したりすると、パノラマの別の方向を見ることができる。この方式のもう一つの利点は、パノラマのどこを見ているかを画像処理によって特定できるということである。画面の下方向が3Dのどの方向に当たるかを見ることで、ユーザーがどこを見ているかを推定し、作業者に提示することができる。しかし、この特徴は実際には時間の関係から実装しなかった。

システムの概要
---------------
実際に実装したシステムは、指示者側、作業者側の2つに大きく分かれ、この2つをネットワークで接続することで実現している。

まず、作業者側では、PCにWebカメラが接続され、パノラマ映像のキャプチャと送信を行う。パノラマ映像は、通常は全方位カメラ(Omni-Directional Camera)という特殊なカメラを用いるが、今回は予算の問題から(本研究は一切大学からの予算を用いていない)、市販のWebカメラと半球ミラーから自作した。WebカメラはLogicool QCAM-200Vを用いた。半球ミラーは、新宿東急ハンズで販売されているいくつかの口径のものを試し、直径7cmのものを採用した。まず半球ミラーを机などの上に設置し、Webカメラを真上から見下ろすように、ちょうど良い高さに設定すればパノラマ映像を取得できる。

これを、PCでOpenCVという画像処理ライブラリによってキャプチャし、送信するプログラムを作成した。転送の形式はリアルタイム処理の実現のため、無圧縮でそのままフレームを送信している。

指示者側ではPCに一眼デジタルカメラ(ビデオキャプチャにより接続)が接続され、受け取ったパノラマ映像をARToolKitによってマッピングする処理を行う。一眼デジタルカメラは近くの机に配置され、マーカーを写す。

実験の目的
-----------
上記のようなパノラマを用いた共同作業システムには、いくつかの根本的に不明瞭な点がある。まず、複合現実感を用いたシステムの中でさらに映像合成を行っているため、システムについての理解や、システムを通じた視点の理解がスムーズに行われるのかという問題がある。これはいわゆるユーザビリティに当たる(できれば定量評価でだめな理由)。また、本システムは簡潔で、基礎技術的な位置づけである。これを共同作業に適したシステムにするために、基礎的な技術のみを用いたインタラクションについて理解することが有用である。主にこの2つを目的とする。

実験の概要
-----------
本実験では、ミニチュアの家具を配置するタスクを、指示者、配置者の2名の共同作業によって行った。指示者は家具の配置の写真を見ることができるほか、技術的手段によって設定によっては配置の様子を見ることができる。配置者の前には家具配置スペース(紙によって示されている)と、ばらばらに置かれた家具がある。指示者と配置者は同じ部屋にいるが、お互いを見られないように配置されており、肉声によって会話をしながら家具の配置作業を行う。

指示者の環境設定は、目の前に表示用のPC(MacBook Pro 13inch Early 2009)があり、映像やパノラマ映像が表示される。また、写真表示用のデジタル一眼カメラ(Panasonic DMC-G1)やiPhone 3GS(パノラマ実験ではデジタル一眼カメラがシステムに利用されたためこちらを利用)があり、それぞれ基本的な操作によって写真の閲覧や拡大縮小が可能である。パノラマ実験の場合は、この他にパノラマ操作用にマーカーとマーカー認識用のデジタル一眼カメラが配置されているが、配置は途中で変更した。

配置者の環境設定は、目の前に2つの机があり、手前と奥に配置されている。手前の机では配置するためのA4の用紙や、パノラマ実験の場合は中央にパノラマ用のカメラが配置されている。奥の机には、あらかじめミニチュアの家具がバラバラに置いてある。

実験手順を以下に示す。

* 前の配置を利用しない場合、ミニチュア家具を配置する
* ミニチュア家具の配置の写真を撮影する
* ミニチュア家具をバラバラに奥の机に置く
* 被験者に実験について説明する
* 実験と撮影を開始する
* 指示者と配置者が共同してミニチュア家具を配置する
* 指示者が終わりだと宣言した場合、実験、撮影を終了する

実験は、以下の3つの技術設定で行った。

* 音声のみ:指示者は配置を真上から撮影した写真のみを見ることができ、配置者の状況は会話によってしかわからない。
* 映像:指示者は写真の他に、配置者を斜め上から撮影した映像(カメラ1をそのまま表示したもの)を見ることができる。
* パノラマ映像:指示者は写真の他に、家具配置スペースの中央から撮影したパノラマ映像を、前節で説明したパノラマ映像表示装置によって見ることができる。

以下に、個別の実験の詳細についてまとめた。

======== ============ ====== ====== ======== ============ ============
実験番号 技術設定     指示者 配置者 使用写真 カメラ1      カメラ2
======== ============ ====== ====== ======== ============ ============
1        写真のみ     A      B      1        配置者斜め上 配置者斜め上
2        写真のみ     C      D      2        配置者斜め上 配置者斜め上
3        映像         E      F      3        指示者斜め上 配置者斜め上
4        映像         G      H      4        指示者斜め上 配置者斜め上
5        パノラマ映像 I      J      5        指示者斜め上 配置者斜め上
6        パノラマ映像 J      K      6        指示者斜め上 配置者斜め上
7        パノラマ映像 K      L      7        指示者斜め上 配置者斜め上
8        パノラマ映像 L      M      8        指示者斜め上 配置者斜め上
======== ============ ====== ====== ======== ============ ============

ただし、2,3,4,6,7,8はそれぞれ実験1,2,3,5,6,7の結果を撮影したものである。

実験に使用した写真を以下に示す。

実験1

.. figure:: 6-1-1.eps
   :scale: 50 %

   写真1-1

.. figure:: 6-1-2.eps
   :scale: 50 %

   写真1-2

.. figure:: 6-1-3.eps
   :scale: 50 %

   写真1-3

.. figure:: 6-2-1.eps
   :scale: 50 %

   写真2-1

.. figure:: 6-2-2.eps
   :scale: 50 %

   写真2-2

.. figure:: 6-2-3.eps
   :scale: 50 %

   写真2-3

.. figure:: 6-3-1.eps
   :scale: 50 %

   写真3-1

.. figure:: 6-3-2.eps
   :scale: 50 %

   写真3-2

.. figure:: 6-3-3.eps
   :scale: 50 %

   写真3-3

.. figure:: 6-4-1.eps
   :scale: 50 %

   写真4-1

.. figure:: 6-4-2.eps
   :scale: 50 %

   写真4-2

.. figure:: 6-4-1.eps
   :scale: 50 %

   写真4-1

.. figure:: 6-4-3.eps
   :scale: 50 %

   写真4-3

.. figure:: 6-4-4.eps
   :scale: 50 %

   写真4-4

.. figure:: 6-4-5.eps
   :scale: 50 %

   写真4-5

.. figure:: 6-4-6.eps
   :scale: 50 %

   写真4-6

.. figure:: 6-4-7.eps
   :scale: 50 %

   写真4-7


.. figure:: 6-4-8.eps
   :scale: 50 %

   写真4-8

.. figure:: 6-4-9.eps
   :scale: 50 %

   写真4-9

.. figure:: 6-5-1.eps
   :scale: 50 %

   写真5-1

.. figure:: 6-5-2.eps
   :scale: 50 %

   写真5-2

.. figure:: 6-5-3.eps
   :scale: 50 %

   写真5-3

.. figure:: 6-6-1.eps
   :scale: 50 %

   写真6-1

.. figure:: 6-7-1.eps
   :scale: 50 %

   写真7-1

.. figure:: 6-8-1.eps
   :scale: 50 %

   写真8-1

これによって何がわかったのか？
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
まず前提として挙げておきたいのが、このシステムは元々一つの部屋を領域として、本物の家具と同じ程度の物体を配置することを目的として設計されており、ミニチュアの家具を用いた実験を行ったのは、あくまでそれを擬似的に再現したものであるということである。この場合、「映像を用いた実験」のような設定を行うことは難しくなる。映像を用いた実験では、ミニチュアの家具よりかなり高い場所にカメラが配置され、全体を俯瞰できるようになっている。しかし、実際に部屋にこのようなカメラを配置することは物理的に難しく、例えば監視カメラのような配置だと死角ができるだろう。このため、もし「パノラマを用いた実験」が「映像を用いた実験」より何らかの劣った面があったとしても、それは必ずしもパノラマシステムが劣っていることを意味しない。

また、この実験をミニチュアで行うことが、実際の部屋で家具を配置することと異なる特徴を持つ可能性がありうる。しかし、パノラマ表示インタフェースに関しては、ミニチュア家具、展示会場、都市空間で特に特性が変わらないことを確認している(以下の写真を参照)。あまりに小さすぎる場合だと焦点距離の問題で像がぼやけてしまうが、今回の実験はA4の用紙を配置場所として選択しており、パノラマの周囲4cm(カメラの接近できる限界)には物体が配置されていない。


結果としてのシステムコンセプトと、実装例
========================================

結論
====

.. [Garfinkel1967] Garfinkel, H.,1967, "Studies in Ethnomethodology", Prentice-Hall
.. [Randall2007] Randall, D., et al., 2007, "Fieldwork for Design", Springer
.. [Button2009] Button, G., Sharrock, W., 2009, "Studies of Work and the Workplace in HCI", Morgan & Claypool
.. [Schegloff2007] Schegloff, E., A., 2007, "Sequence Organization in Interaction: A Primer in Conversation Analysis I", Cambridge University Press
.. [Suchman2007] Suchman, L., 2006, "Human-Machine Configuration: Plan and Situated Action 2nd Edition", Cambridge University Press
.. [Siio2010] 椎尾一郎, 「ヒューマンコンピュータインタラクション入門」, サイエンス社, 2010
.. [Rekimoto1996] 暦本純一, 「実世界志向インタフェースの研究動向」, コンピュータソフトウェア, Vol.13, No.3, pp.4–18


.. rubric:: 註
.. [#] 別の手法として、概念分析などがあるがここでは触れない。
