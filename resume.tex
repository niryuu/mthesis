\documentclass[a4j,11pt,report]{jsbook}

%% package
\usepackage{plext, layout, geometry}
\usepackage[dvipdfm]{graphicx}
%%\usepackage{picins}

%% layout
\geometry{top=25mm, left=30mm,right=20mm, bottom=20mm}

%% 以下2行が章のラベルを書き換える^M
%%\renewcommand{\presectionname}{第}^M
%%\renewcommand{\postsectionname}{章}

%% command definition - begin
\setcounter{tocdepth}{2}

\makeatletter
\long\def\@makecaption#1#2{%
\vskip\abovecaptionskip
\iftdir\sbox\@tempboxa{#1\hskip1zw#2}%
%% \else\sbox\@tempboxa{#1: #2}%
\else\sbox\@tempboxa{#1: #2}%ここで変更
\fi
\ifdim \wd\@tempboxa >\hsize
\iftdir #1\hskip1zw#2\relax\par
\else #1: #2\relax\par\fi
\else
\global \@minipagefalse
\hbox to\hsize{\hfil\box\@tempboxa\hfil}%
\fi
\vskip\belowcaptionskip}
\makeatother

\makeatletter
\def\@makechapterhead#1{%
  \vspace*{2\Cvs}% 欧文は50pt
  {\parindent \z@ \raggedright \normalfont
    \huge\headfont
    \ifnum \c@secnumdepth >\m@ne
      \if@mainmatter
        \@chapapp\thechapter\@chappos
        \hskip1zw
      \fi
    \fi
    #1\par\nobreak
    \vskip 3\Cvs}}
\makeatother

\renewcommand{\emph}[1]%
{\bou{#1}}

\newcommand{\result}%
{\begin{math}\rightarrow\end{math}}

\newcommand{\note}[1]{{\footnotesize
#1}}

\newcommand{\sic}%
{{\tiny ママ}}

\newenvironment{thesis}{%
    \par \parindent=0pt \em%
    \vspace{5mm}\hspace{5mm}%
    \begin{minipage}[t]{160mm}
}{%
    \end{minipage}%
    \vspace{5mm}%
    \par%
}
\newenvironment{terms}{%
    \par \parindent=0pt%
    \vspace{5mm}\hspace{5mm}%
    \begin{minipage}[t]{160mm}
}{%
    \end{minipage}%
    \vspace{5mm}%
    \par%
}

\makeatletter
\count@\z@
\@whilenum\count@<16\do{%
   \advance\count@\@ne
   \expandafter\newinsert\csname bx@\romannumeral\count@\endcsname
   \@cons\@freelist{\csname bx@\romannumeral\count@\endcsname}}
\makeatother

%% command definition - end

\begin{document}
\setcounter{page}{2}
%\begin{titlepage}
\tableofcontents
\listoffigures

%\end{titlepage}
\newpage

\chapter{背景と目的}
本論文では、実世界の環境の提示の中でも、空間に関するものが、離れた環境でどのように用いられるかを、相互行為分析の手法を用いて分析した。この背景には、コンシューマコンピューティングの技術の進展により、新たな遠隔地での共同作業の可能性が開かれたことがある。現在、SOHOやノマドワーキングなどの、特定の組織や場所に縛られない働き方が提唱されている。一方で、このような働き方ができるような業種は、いわゆるホワイトカラーや、ソフトウェア開発など一部に限られる。これは、現在普及しているPCのインタフェースがオフィスワークを目的としたものであることに大きく起因すると考えられる。画像処理、拡張現実感技術や、「タッチ」を中心としたタンジブルなインタフェースが安価に手に入りつつあるが、これを実用的に応用する試みはまだ少ない。本論文では、この可能性を模索することを目的とする。 

\section{本論文の構成と全体の方針}
本論文では、エスノメソドロジー、相互行為分析のシステムデザインへの適用が主軸に置かれている。しかし、これ自体が主題ではなく、あくまで技術的環境の変化がこのような手法への注目や重要性を喚起している。よって、本論はまず、昨今の技術的環境の変化を概観しながら(2章)、エスノメソドロジーとシステムデザインとの関係についてのレビューを行い(3,4章)、その実際例として著者が関わったフィールドワークと実験について取り扱う(5,6章)。これらを便宜上第1部から第3部とする。

一方、本研究の状況と主題特有の困難な点について、後の議論を先取りする形ではあるが述べておく。まず結論から言えば本研究は失敗である。著者の主に行った作業は、以下の通りである。

\begin{itemize}
\item 両面液晶端末の開発と、デザインコンセプト「Jointed Reality」の考案(2章)
\item 位置情報ゲーム「ジオジオスタンプラリー」のフィールドワークと分析(5章)
\item 実験「画像と音声を用いた道案内」(撮影に失敗したため分析できず)
\item 360度全方位の視点を確保できる「セカイカンヅメ」の開発と分析
\end{itemize}

エスノメソドロジー研究によって、あるシステムを分析して知見を得る際には、以下の全ての条件が整っている必要があると考えられる。

\begin{enumerate}
\item 分析の可能性を判断できる最低限の方法論的知識
\item システムの新規性を評価できる概念史的知識
\item システム
\item データ収集のためのビデオ、音声などの機材
\item システムを実際に導入できる環境とユーザー
\end{enumerate}

1に関しては、システム開発者/工学者としての成否と、エスノメソドロジー研究者の関心をもつ事柄が異なるために必要となる。システムの使用の明らかな失敗、例えばタスクを実行できなかったりしたとしても、それに至る相互行為の組織には興味を引く部分があるかもしれない(一例として、システムへのエスノメソドロジーを最初に適用したSuchmanは、コピー機の使用の「失敗」を題材に状況的行為の概念を明らかにした(Suchman 2006))。2に関しては、本研究では、ある程度日常に浸透したテクノロジーを扱う場合がある。この際、システムが研究の先端からある程度外れた場合、「工学的」研究としては成立しない場合がある。3に関しては、自作する場合著者自身の開発能力とリソースに依存する。4に関しては、ある程度の機材があれば問題はないかもしれない。5に関しては、通常は実験が行われることが多いが、イベントなどのより日常に近い状況を分析できる機会もありうる。

次に、なぜエスノメソドロジーによるシステムの分析の研究がうまくいくのかについて述べる。基本的に、工学者との共同研究を行えば多くのリスクは回避される。まず、システムとその新規性が担保される。また、4章でこれに関する問題も取り上げるが、工学者とエスノメソドロジー研究者の共同開発の場合、お互いの情報交換によって、エスノメソドロジー研究者の持つ知識の範疇で評価できるようにシステムを設定できる可能性がある。最後に、プロジェクト自体がの規模が大きくなるため、実験環境の整備と被験者のリクルートを行いやすい。

一方、本研究では著者がシステムコンセプトの着想と開発を行うか、著者が関わった民間団体の開催したイベントのフィールドワークを行った。この段階で、以上のあらゆる条件の成立が難しくなる。具体的には

\begin{itemize}
\item 両面液晶端末:2章3節、4節を見ればわかるように、このコンセプトの新規性は担保される。実際、CHI2009において類似のシステムが提唱されている。「セカイカンヅメ」の次期インタフェースとして考慮している。しかし、当時の著者の実世界志向のイメージは五感を提示するものであったため、このコンセプト自体が棄却された。
\item ジオジオスタンプラリー:システムは新しいものではない。機材は足りなかった。「道案内」の考案の過程である程度分析の可能性は見つけられたが、手持ちのビデオデータでは例証が難しかった。
\item 実験「画像と音声を用いた道案内」(撮影に失敗したため分析できず):自明。
\item 「セカイカンヅメ」:新規性がある程度担保されており(情報処理学会「インタラクション」「インタラクティブ発表」preprint)、システムも何とか実験をできるようにはなっていた。機材もあり、実験も行えたが、分析の方法がまったく思いつかなかった。
\end{itemize}

\chapter{技術的概観}
本論文では、コンピュータとのインタフェースの中でも、実際の空間で手で触ることができるようなものや、実際の空間から何らかの形で情報を得るようなものを取り扱う。実際の空間を指向したような技術は、情報分野では複数の研究分野から生まれ、互いに影響しあって形成されている。このため、似たように見える技術コンセプトでも、実世界での作業を支援する側面、あるいはテーブルトップでの作業を拡張したもの、空間の境界自体をインタフェースにしたものなど、多くのバリエーションや、また先端の分野で忘れられた概念なども存在する。このため、まず実空間を志向した様々な分野のレビューを行い、概念史をまとめる。 

\section{実世界以前}
本論文では、バーチャルリアリティや実世界を志向したインタフェースに関連する分野について取り扱う。その中で重要なのが「実世界」とは何かということである。例えば実世界を、見て触ることのできる世界と定義できるだろう。しかし、現存するパーソナルコンピュータなどは明らかに見て触ることができるものの、実世界を志向したものとして扱われることはほとんどない。この問題を明確にし、バーチャルリアリティや実世界志向インタフェースが何を実現するのかについて検討するため、まずは現在のパーソナルコンピュータや、実世界を指向する以前の試みについて少しまとめる。 

\subsection{GUI}
パーソナルコンピュータのユーザインタフェースの類型として現在典型的なものが、GUI(Graphical User Interface)である。例えば、本論文の執筆環境は、LinuxのCompizというオーソドックスなGUIに、論文本体の編集画面、文献をまとめたファイルブラウザ、文献を表示するドキュメントビューワーの3つのウインドウからなる。これらをタッチパッドのクリックによって切り替えることができ、タッチパッドの右端を上下になぞると文献のページをめくることができる。 

GUIによるコンピュータの操作を可能にする概念は、椎尾によって以下のようにまとめられている。 

\begin{itemize}
\item  直接操作:コンピュータ画面に表示した物体を、ユーザが指示装置で動かすことで、コンピュータを操作する手法。ユーザは物理的な物体を操作している錯覚を覚え、わかりやすいインタフェースを実現できる。また、状態を直感的に見て操作できるため、コンピュータの動作を把握、支配している感覚を得られる。物を操作する能力は幼児期に獲得するものであるため、緊張感や負担が少なく、知的作業の妨げになりにくい。 

\item  メタファー:GUIでは、コンピュータ画面を事務机の上(デスクトップ)に喩えた、デスクトップメタファー(desktop metaphor)が採用されて(椎尾 2010, p.108)いる。つまり、書類、フォルダ、アプリケーションなどが実際の机を模してアイコンとして表示されている。メタファーはコンピュータの機能の理解と学習を容易にし、現実世界の知識を利用できる。ただし、現実とかけはなれた挙動をする場合はこの限りではない。 

\item  WYSIWIG:What you see is what you getの略。最終的に出力される文書や図版と、見かけ上全く同じものをディスプレイに表示し、操作することができる。 

\item  やりなおし:GUIでは操作の手がかりが多く表示されているため、ユーザーは試行錯誤によって操作を習得する。このためにはやり直しができる機構が必要である。 

\item  モード:コンピュータシステムの状態によって、ユーザーが行う操作の意味が変わったり、実行できる操作に制限がかかるインタフェース(椎尾 2010, p.111)を、モーダルなインタフェース、そうでないものをモードレスなインタフェースと言う。モードはユーザーの作業の妨げになるため、モードレスが推奨されるが、作業を中断してでも通知、確認する重大な場面ではモードが使われる。 

\item  GUI設計のガイドライン:複数のアプリケーションで統一した操作を提供すれば、ユーザが操作方法を学習する負担を削減できる。そのために設計のガイドラインと、共通して使える部品を開発者に提供する必要がある。 

\end{itemize}
以上 (椎尾 2010: 107-115)より著者が作成 

この2つの重要性は開発者にも同様に認知されている。最初に普及したGUIを搭載したコンピュータであるAppleのMacintoshでは、「Macintosh Human Interface Guidelines」という書籍を開発者向けに出版している。その中の「ヒューマンインタフェースの基礎」という章では、メタファー、直接操作、WYSIWIG、一貫した操作、モードなどについて取り上げている。これは、以上の概念が単なる設計思想に留まらないことを示している。 

この2つは、一見して身体的な「タッチ」という操作を実現しているAppleの「iPhone」にも一貫して重要視されている。iPhoneのアプリケーションを開発者が提供する際にはAppleの審査を受ける必要があるが、その中で最も重要な審査基準である「iOS Human Interface Guidelines」では、タッチ機能は直接操作やメタファーをさらに補強するものと位置づけている。 

\begin{figure}[!h]
\begin{verbatim}
   iOSのユーザーはマルチタッチのため、直接操作の強い感覚を楽しむことができる。ジェスチャーの利用は、画面上の見ている物体に大きな親近感と、それを制御している感覚を与える。(Apple 2010: 20)
   人々は現実的な画面上の物体と物理的にインタラクションを行い、多くの場合現実世界の物体に対するかのように操作できる。(Apple 2010, p.21)
\end{verbatim}
\caption{iOSの開発ガイドラインに見るGUIの要素}
\end{figure}
iPhoneでは触るという操作は、あくまで画面上のメタファーに対して行われる。これは明らかにGUIの延長線上にある製品である。 

\section{CSCW}
一方で、実世界を重視するという流れには、CSCW(コンピュータ支援共同作業)分野の一連の研究が深く関わっている。CSCWは、一言で言えば、実際のオフィスワークを念頭において、それをコンピュータによって支援する研究を総称する。その中には、例えばスケジュール管理に代表される「グループウェア」も当然重要な位置を占めるが、実際のオフィスについての分析を行う、もしくは実際のオフィスに適合するようなインタフェースの研究は、前節の実世界志向インタフェースにも接続されている。  

CSCWの中でも、机上の共同作業を支援する試み、特に紙の文書とデジタル文書をシームレスに扱うようなモデルは、複数の研究者によって提唱されており、後の実世界を志向したインタフェースや、映像を用いたコミュニケーションへの礎となっていった。本章でのレビューはこれを出発点とする。 

\subsection{TeamWorkStation}
石井らによるTeamWorkStation(TWS)は、デスクトップ画面をビデオ制御することで作業領域の共有を可能にするシステムである(Ishii 1991)。これは単純な概念であるが、拡張現実感に至る出発点であった。TWSのキー概念は以下のようになる。 

\begin{itemize}
\item  ホワイトボードのような「共有描画表面」があり、全員が見て差し、描くことができる 

\item  共有作業領域と個人作業領域の間をシームレスに移行できる 

\end{itemize}
これらを実現するために、「個人作業領域をオーバーレイする」ようにTWSは設計されている。つまり、例えばAの画面にBの画面が表示され、Bの画面をAがマウスポインタで指すことで、それがフィードバックされAの画面にも現れるような設計になっている。この他にも様々なオーバーレイの形式が提示されている。それだけではなく。基本的にビデオ媒体を利用しているため、ビデオカメラ映像のオーバーレイも可能である。これにより、実際の机や顔なども共有することができ、デスクトップに留まらない「作業領域」の共有が可能になる。 

\subsection{DigitalDesk}
紙の文書とデジタル文書における作業の統合を目指したのがWellnerによる、「DigitalDesk」(Wellner 1993)である。Wellnerは、紙とデジタルの文書が分離されている状況を「dual desk」として描写している。紙文書とデジタル文書は別の機能を持ち、媒体の違いから相互に変換することも難しい。この両者をうまく統合させる方法が「Computer Augmented Environments」だとWellnerは提唱する。 

Computer Augmented Environmentはバーチャルリアリティ(VR)に着想を得ているが、逆のアプローチを取っている。VRはコンピュータの作り出した世界に仮想的な物体を配置することができ、それは日常生活を支援するのに有用であるが、実際の世界から遮断されてしまう。これに対してComputer Augmented Environmentは実世界の物体をコンピュータによって拡張することを目指す。これによって物理的環境の慣れ親しんだ特徴を失わずに、コンピュータの支援を受けることができる。この考えはユビキタスコンピューティングと拡張現実感ともつながっている。 

DigitalDeskでは、実際の机の上にプロジェクターによりコンピュータ画面を投影し、またカメラで机の画面を撮影することで、実際の机上の紙をコンピュータで処理することを可能にしている。これによって、メタファーではなく実際のペンや指での操作が可能になる。また、紙の上にコンピュータの画像をオーバーラップさせたり、紙文書を認識してスキャンすることもできる。DigitalDeskのインタラクションは、指を用いた現実、仮想の物体との「tactile interaction」を目指す。つまり、紙とデジタルデータの両方に同じ方法で接することができる。 

\subsection{ClearBoard}
石井らによる「ClearBoard」(Ishii 1992)は、以上のような「ホワイトボード的」な共同作業支援システムが、視線やジェスチャーの問題を持っていることから考案されたシステムである。TeamWorkStationの実験から、対面会話から共有描画活動にスムーズに移行することが重要であるという結果が出た。 

対面の会議では「隣接した空間」、つまりホワイトボードと人の間に物理的な継ぎ目がないものとして部屋が知覚され、目や頭を動かすだけで参加者とホワイトボードを見渡せる。しかし、TWSでは分かれて扱われ、仮想的な会議空間が分離してしまった。この問題に対処するため、シームレスな共有作業空間と、アイコンタクトに焦点を当てた2人用の遠隔リアルタイムコラボレーションシステムが、ClearBoardである。 

ClearBoardではシームレスでアイコンタクトのある空間を実現するために、「ホワイトボードの前にいて」「テーブルの向こうにいる」、そして「通り抜けて話し、描けるような透明なガラスのウインドウ」の3つのメタファーが用いられる。この3つにより、まず仲間の顔を見ることができ、次にあまり目を動かすことなく、仲間の顔と描画の間で視線を動かすことができる。 

\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{digitaldesk.eps}
\caption{DigitalDeskの概念図(Wellner 1993)より}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{clearboard.eps}
\caption{ClearBoardの概念図(Ishii 1992)より}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\section{実世界志向インタラクション}
CSCWにおける、机などのオフィスの実際の物体に即したインタフェースの試み、もしくはオフィスワーク以外の現実世界での活動の支援の試みは、現実世界に十分適合したインタフェースの研究へと継承されることになった。このテーマはそれ自体が独立したものであり、実際に現在研究されている実世界を指向したインタフェースが、必ずしも共同作業の支援という問題意識につながっているわけではない。本節では、実世界を指向したインタフェースの初期の概念について整理し、現状についてまとめる。 

\subsection{Augmented Reality/Mixed Reality}
実世界を指向したインタフェースの一つの方向性が、複合現実感(Mixed Reality)、拡張現実感(Augmented Reality)と呼ばれるものである。この2つの概念は互いに重複することも多いため、本節では同じものとして取り扱う。これは、単純に要約すれば現実世界の物体や空間と、コンピュータが作り出した知覚を重ね合わせるという概念であるが、2つのまったく異なる起源を持つ。 

その一つが、前節で触れた「Computer Augmeneted Environments」(Wellner 1993)やClearBoardをはじめとするテーブルトップ環境である。既に見てきたように、共有作業空間と、実際の人間の視線や指差しなどのを両立させる試みは、仮想的なデータ表示と実際の映像を重ねるデザインに至った。 こちらの拡張現実感のイメージは、ユビキタスコンピューティングに近い。Buxtonは、ユビキタスメディアは拡張現実感であるとする(Buxton 1995)。 

もう一つが、バーチャルリアリティ研究から派生した、シースルー型HMDなどの利用の研究である。シースルー型HMDは、顔に装着するタイプのHMDの中でも、透明で情報の表示と現実の視覚を同時に確保できるものである。これに、さらに通常のディスプレイなどで表示できるものなどを含めると、技術的手段のみを見ても非常に多様である。

このような多様な拡張現実感技術を、バーチャルリアリティとの関連を手がかりに特徴付けたのがMilgram(1994)である。当時のバーチャルリアリティは、没入型のもの、つまり、現実世界との感覚を一旦特別な部屋やヘッドマウントディスプレイなどでシャットアウトした上で、3Dなどで人工的に作り出した知覚を提供するものであった。一方、拡張現実感技術は、現実世界の一部のみを人工的な知覚にする。これより、「現実世界のどの程度を人工的にするか」という尺度が生まれる。Milgramは、何も手を加えられていない「Real Environment」から、拡張現実感である「Augmented Reality」、拡張現実感より人工的な、今後現れる可能性のある「Augmented Virtuality」、最後に完全な人工環境である「Virtual Environment」という4つの分類を「Virtuality Continuum」として提唱した。その上で、完全に手を加えられていないものと完全に人工的なものを除いたものを「Mixed Reality」と呼んだ。

また、Azuma(1997)は、それより少し先の1997年当時の拡張現実感技術のレビューを行い、その中で拡張現実感技術の特徴を以下の3つとしている。

\begin{itemize}
\item 現実とバーチャルの混合
\item リアルタイムのインタラクション
\item 3Dで登録される
\end{itemize}

この2つが、現在拡張現実感技術の定義としてもっとも有名なものである。これらの定義は、拡張現実感技術をバーチャルリアリティと併置されるもの、もしくはその一部として位置づけており、これは拡張現実感を研究する上で、もしくは製品を開発する上でのデファクトスタンダードになっている。一方で、Wellnerの「Computer Augmented Environments」の着想に、「バーチャルリアリティではなく、現実空間の物体と同じように扱えるようにする」という側面があったこと、またそれがAugmented Realityと呼ばれていたことは、これらの定義のコンセプトに合致しない。拡張現実感技術の共同作業、人やオブジェクトが複数あり、それらが協調しながら作業を達成するのを支援するという側面は、今では薄められている。

\subsection{実世界志向インタフェース}
前の節で見たように、基本的にコンピュータや携帯電話のインタフェースはGUIの延長線上にある。しかし、GUIの問題点やコンピュータを取り巻く環境の変化を元に、新たなインタフェースが幾つか生み出されている。それらはGUIのような一つの概念ではないが、相互に影響しながら研究が行われてきた。 

実世界志向インタフェース (歴本 1996) は、その中でも「実世界での人間の作業を支援しようという研究の流れ(歴本 1996: 2)」という広い範囲を取り扱う概念である。暦本は、実世界志向インタフェースの特徴を以下のように要約している。 

\begin{itemize}
\item  インタフェースの透明化:利用者のタスクは実世界のもので、実世界に注意を向けているため、システムに注意を集中させることはできない。このため、メタファーのように「見せる」方向ではなく「透明にする」方向が問題となる。究極的には人間がコンピュータを認識しなくなる。 

\item  実世界状況の認識:実世界のタスクを支援するためには、利用者が実世界で置かれている状況や意図をコンピュータが認識する必要がある。このため、コンピュータには状況を認識して積極的に情報を提供するような能動性が求められる。 

\item  人間の能力の強化:実世界志向インタフェースの目標は、人間の代わりではなく人間の能力そのものを擬似的に増強することが一つである。 

\item  実世界情報とコンピュータ情報の関係:現実世界の情報とコンピュータの情報をいかに連携させるかが重要なテーマである。これにはいくつかの種類がある(図)。(a)(左上)従来型インタフェース。コンピュータと対面する。実世界のインタラクションとの間にギャップがある。(b)(右上)仮想現実感。完全にコンピュータの作り出す世界に限定され、現実世界とのインタラクションはなくなる。(c)遍在型コンピュータによる実世界志向インタフェース。コンピュータを遍在させることで実世界と仮想世界を一体にする。(d)携帯型コンピュータによる実世界志向インタフェース。cは現実を、dは人間を強化するアプローチといえる。 

\end{itemize}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{interactionstyle.eps}
\caption{インタラクションスタイルの比較、(歴本 1996)より著者が作成}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\subsection{タンジブルインタフェース}
MIT Media Lab. の石井が提唱した「タンジブルユーザーインタフェース」(TUI)も、GUIの代わりとして実世界を志向したインタフェースの一つである。 

TUIは、97年に4つの学問領域の影響を受けて、建築空間に関するものとして提示された(Ishii 1997)。1つめがWeiserの提唱するユビキタスコンピューティングである。これについては詳しくは取り扱わないが、コンピュータが「透明」になり、遍在化することを予測している。この結果、物や建築の表面にコンピュータが埋め込まれる。次が、先に取り上げたAugmented Realityで、物を直接つかみ操作するという焦点を導入した。次がCSCWである。机上の遠隔仮想空間の提示(ClearBoard)は、表面を仮想空間と現実空間の間で、情報が自由に行き来するアクティブ・インタフェースにするという着想を与えた。最後がGrapsable User Interfaceである。これも情報を直接手でつかむという着想を与えた。 

以上のような領域に受けて、「Tangible Bits」という一連の研究のコンセプトが提示された。 

\begin{itemize}
\item  インタラクティブな表面:建築世界の表面を物理世界とディジタル世界のインタフェースとする 

\item  ビットとアトムとの結合:手で操作できる物理オブジェクトとディジタル情報をリンクできる 

\item  アンビエント・メディア:建築空間内の音や空気などを、サイバースペースとのバックグラウンドインタフェースとして利用する 

\end{itemize}
(Ishii 1997)より著者が作成 

以上により、ディジタル情報を認知の焦点でビットを直接つかんで操作でき、また認知の周縁で情報の気配にアウェアでいられるようにすることを目指す。つまり、GUIでコンピュータに焦点を当てていたものをより現実世界とスムーズにすることを目指している。 

近年の研究では、その概念はさらに具体的になっている。TUIは、人の物理的環境を感知して操作する能力を活用するため、デジタル情報を物理的空間で物理的に身体化された形で扱うものである(Ishii 2008: 470)。GUIはディスプレイ上のピクセルとして情報を表すが、それとのインタラクションは我々が生活する物理的環境と不整合であり、物理的な物体を扱う能力を十分に発揮できない。TUIはデジタル情報に物理的な形を与えることを基礎とし、デジタル情報を手で「直接操作」することを可能にする。しかし、TUIは特定の目的のために特定の物理的形状を与えるもので、GUIのようにあらゆる目的にかなうものではない。 

TUIの基本的なモデルには、GUIと共通する部分と異なる部分がある。TUIは、GUIと同じようにMVC(Model-View-Controller)という設計モデルを採用している。これは、データの取扱いを決める「モデル」、情報の提示を管理する「ビュー」、プログラム全体の制御をする「コントローラー」の3つにプログラムの部品を分ける手法で、近年のWebアプリケーションなどにも採用されている。TUIでは、コントローラーはタンジブルなものを扱うものと、そうでないものに分かれる。また、モデルは「デジタル情報」として一般化される。 

TUIはGUIと同じく、デジタル情報の直接操作を行うが、タンジブルな表象を提示する。タンジブルな表象は物理的世界との架け橋となるとともに、デジタル情報と計算モデルの制御を可能にするように計算論的に結合されている。つまり、手などによる物理的な操作による位置などのパラメータが、制御に利用されている。一方で、TUIには物理的な制約があるため、映像投影や音声などの「インタンジブルな」インタフェースも補完的に使われる。 

\subsection{実験的コンセプト:Jointed Reality}
2009年5月、著者は「実際に何か実世界に関連したもの」を製作し、それを評価することで研究を進めることを計画していた。その際、「モバイルデバイスで空間を取り扱う」ことをコンセプトに、「Jointed Reality」(これはネーミングが先行している。「コンピュータビジョン・拡張現実感に関する普通じゃない勉強会」というセミフォーマルな発表会において、発表内容に「VR」「AR」に変わる「*R」を表す名称を付けるという条件が課された。その際国鉄になぞらえた名称である)というコンセプトを発表した。それが、タンジブルインタフェースの「表面にインタフェースが埋め込まれる」という当初のコンセプトに関連していると思われるので、ここで取り上げる。 

「Jointed Reality」は、元々表と裏に液晶を持つモバイル端末の使用法について検討している中から生まれた。当初検討していた2つの液晶を持つ利点は、モードを直観的に切り替えられることである。つまり、表と裏に関連した別の機能を割り当て、それを回転させて切り替えることで直観的で豊富な機能を扱えるというコンセプトである。また、巻物のメタファを導入し、回転させると次のページが現れるようなインタフェースも試作した。しかし、これらは現状のGUIに対して大きな利点とならないと推測された。 

次に著者が検討したのが、モバイル端末の空間性の利用である。モバイル端末には、当然幅、高さ、奥行きが存在する。ある意味で、それは常に一定の空間を占有していると言える。この空間とバーチャル3D空間をマッピングし、何らかの形で操作を与えることで、平面ではなく空間を扱えるようなインタフェースが可能になると考えられる。 

具体的なインタラクションの形式は、基本的に「タッチ」操作の応用となる。試作した両面液晶端末は、表と裏にMID(Mobile Internet Device)を貼り付け相互に通信を行い、表裏判別用にWiiリモコンが横に貼り付いているという構造である。当時はMIDに本格的な3D機能がなかったため、拡大縮小回転による擬似3D機能を用いて、インタラクションのデモを作成した。その中には、両面の液晶をつまんで物体を移動できる「つまむ」機能、両面の液晶で別の方向に指を動かすことで物体を回転させる「まわす」機能などが含まれる。このように、2つのタッチ液晶を「Joint」させることで、その中に3D空間を発生させるというコンセプトが「Jointed Reality」である。 これは、元々2D+GUIのシステムをTUIとして再提示した例と言える。

\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{jointedreality.eps}
\caption{2台のMIDによる「つまむ」インタラクション}
\end{center}
\end{minipage}
\end{center}
\end{figure}

\section{消えるコンピュータと人間の拡張}
以上の「ポストGUI/実世界志向」アプローチに共通する点は、「コンピュータを見えないものにし」「人間の能力を拡張する」ことである。この2つの主張は一見して独立したものに見える。しかし、これらはある意味で共通した面を持ち、その共通点を見ることこそが実世界志向インタフェースの別の側面を明らかにする。 

例えばARToolKitについて、 

\begin{itemize}
\item  カメラで認識した映像フレームの中の特徴点を元に3次元位置の推定を行い、それを基準として3Dモデルとカメラの映像を重ねてディスプレイに表示する 

\item  現実世界に置かれたマーカーの上に、3Dモデルが配置されることで、あたかも仮想的な物体がそこにあるかのように見える 

\end{itemize}
以上のような2種類の記述を行うことができる。前者は画像処理の結果をディスプレイに表示している点で、GUIに属するものと見られる。一方、後者は実世界に仮想的な物体を提示するARシステムである。しかし、この2つは全く同じシステムである。また、この2つは「実世界で使われているから」あるいは「使い方が異なる」という理由で異なっているのではない。使われる状況や使い方に依存しない記述である。 

システム自体ではなく、この記述からARToolKitが実世界を志向している、つまり「コンピュータを見えないものにし」「人間の能力を拡張する」ことを示す。まず、「カメラ」「ウインドウ」は後者では消えているため、コンピュータは確かになくなっている。また、前者ではただ表示しているだけだが、後者では仮想的な物体を見ることができるようになっているため、例えば有用な物体を表示することを考えれば人間の能力は拡張されていると言える。 

以上のように、コンピュータによる人間の能力の増強を考える際には、達成されたものがコンピュータの能力に属するか、もしくは人間かという帰属の問題が起こる。これに関しては、人間とコンピュータの境界の問題としてSuchmanが論じている(Suchman 2006)。また、この記述の問題に関しては、4章でDourishの議論に関連して論じる。

\section{現況}
よく知られている製品の例が、ARToolKitとセカイカメラである。ARToolKitは、「マーカー」という、コンピュータが認識しやすい模様を用い、それが映像の中で認識された場合、その場所を基準として3Dの物体を表示するものである。セカイカメラは、iPhoneのアプリケーションで、主にGPSや加速度センサーなどの情報を元に、カメラ映像の上に文字などが書き込まれた吹き出しを表示させ、あたかも吹き出しが実世界にあるかのように見せるものである。 

コンシューマ領域での実世界志向技術の現況は、どのような技術がコモディティになっているかによってある程度知ることができるだろう。現在無料、あるいは安価で手に入る実世界を指向したインタフェースを実現する製品やソフトウェアライブラリは、以下の通りである。

\begin{itemize}
\item スマートフォン: カメラ表示と3Dモデルを同時に表示可能である。加速度センサなどにより動きの認識も可能である
\item Kinect: 距離センサとカメラによって、ジェスチャ、モーションの認識が可能である
\item OpenCV: 基礎的な画像処理の手法と、それに用いられる機械学習などの基礎的な手法を再利用可能にしたもの
\item ARToolKit/PTAM: マーカーや画像の特徴から3次元の位置をマッピングし、3Dの物体を表示するもの
\end{itemize}

\section{まとめ}
以上のように、実世界を志向したインタラクションという技術的な挑戦は、その初期においては人間同士の共同作業という、比較的純粋な技術から離れた分野と密接な関わりを持っていた。その接点には、人間同士の机上、オフィス空間などでのインタラクションを、可能な限り円滑な形でシステムに取り入れようというモチベーションがある。「実世界」というものを志向する意義は、人間がそこにいてこそのものであるといえる。 

一方で、幾つかの本質的な疑問が残る。例えば、共同作業システムの完成形として、人間同士のインタラクションで必要な要素のみを提示できる、という状況を考えれば、共同作業の支援に「世界」を提示するというのは冗長である。また、幾つかの研究では「視線や身体的動きなどが行われる空間」を「実世界」と呼んでいる。一方、先に見た例では、人間とシステムの境界そのものが曖昧である。それに応じて「視線や身体的動きなどが行われる空間」も変わってくるはずである。このように、「実世界」という言葉の定義は不明瞭である。既にそのような「実世界」を志向したシステムがコンシューマー領域に入りつつある。 

以上から、本論文で扱うテーマをある程度確定することができる。つまり、「実世界を志向したインタフェースは、実世界をどのように扱うのか」である。これに対して、工学的な観点のみから問題をとらえることは難しい。接近する手段があるとすれば、 

\begin{itemize}
\item  人間がインタラクションの中でどう「実世界」を形成するのか 

\item  実世界を志向したインタフェースの導入で、どう「実世界」が変わるのか 

\end{itemize}
を通じてである。本研究では、この2つに焦点を当てる。 

\section{研究対象技術:位置提示インタフェース}
本研究では、以上の問題に迫るため、実世界を指向したインタフェースの中でも、位置を提示するものに焦点を当てる。物理的な位置は、実世界を指向したインタフェースの多くが備えている要素であるが、ここでは位置を提示することが「目的」である、つまり「実世界」のあり方そのものを問題にして、それをユーザーが解決するようなインタフェースを指す。このような種類のインタフェースは、主に対象とする空間によって多岐に渡る。

そのもっとも古典的な例が、地図を使ったものである。例えば、GPSによって自身の位置を特定し、それに応じて地図を表示するアプリケーションは、一般的である、また、電子コンパスの使用により、端末を持っている方向を反映させるものもある。地図は、人類史に起源を求めるほど古典的なものであるが、実際に1人、あるいは複数人で地図をどう使いながら位置を解決しているかについては、まだ十分な解明がされていない(Brown 2004)。

また、近年登場した形式では、「セカイカメラ」のようなモバイル端末を空中にかざすと、その方向につけられたタグが表示されるものがある。これに関しては、既にこなれた技術であるため、商用利用も行われている。極めてシンプルな、目標まで何mの、どの方角に対象があるかだけを数値で表示するものも、位置提示インタフェースに当たるだろう。

ここまではいわゆる「位置情報」を扱う典型的なものを取り上げたが、位置提示インタフェースには、都市規模ではなく、視認できる範囲の情報を表示したものも存在する。「セカイカメラ」などは、その情報量の多さから周囲数100mの範囲のタグに限定されるため、ある意味この例に当たるが、典型的なものは映像を使ったものである。例えば遠隔地を直接映像で接続したCCTV(Closed Circuit TeleVision)、それを複数にしたMTV(Multiple Target Video)などもこれに当たるだろう。

また、机上の物体の位置を表示するものを、位置提示インタフェースに当たる。このため、前節までで取り上げた、机上を拡張するインタフェースで、例えば指差しなどを共有するものは、位置を指すものになるだろう。

「位置提示インタフェース」の定義を、このように、提示する位置の範囲を極めて広く取ったのには理由がある。例えば、地図は基本的に都市の大きさではなく、手で開くことのできる大きさである。また、表示の方法によっては机上のインタフェースをプロジェクターで大きく投影することも可能であり、視認できる範囲を机上に投影することも可能である。このように、提示されるスケールは、必ずしも元の空間の大きさを反映しない。拡張現実感技術の応用は、この傾向をさらに高めるだろう。本論文では、この中でも「複合現実感ゲーム」に対応するものや、拡張現実感技術と机上インタフェース、全方位映像を統合したものなど、比較的特殊な技術に目を向け、それが使われる方法を分析することで、実世界というものがどうできているかの理解を目指す。

\chapter{分析の方法論と方針}
前章では、テーブルトップ型の共有システムに人の視線や身体的配置、行為の問題が発生し、それがCSCW研究者の実世界への関心を呼び起こしたことについて論じた。実世界を指向したインタフェースは、単に現実世界を模倣したり、改変するだけでなく、複数人が共同作業をする基盤となりうる。 

一方で、実世界を指向したインタフェースは多様化し、必ずしも作業、ひいては身体の問題を指向しなくなった。むしろ、人間にさらなる別の世界をみせるような、新奇なデバイスやインタフェースの開発が推奨されている。例えば、このようなインタフェースを組み合わせて、もしくはそこから継承して新たな共同作業システムを作るとすると、その複雑さからどのような「実世界」を作り出すのか、また何を支援するようなシステムなのかが不明瞭になる可能性がある。 

ここでCSCWの別の文脈を検討する。共同作業支援システムが実世界を指向していることは、人間同士のインタラクションの研究者にとっても関心を引くテーマであった。日常会話において視線や指差しなどに注目していた研究者は、実際の作業の場面で、どのように特有の仕事を達成するかということにも、視線や指差し、付近の人工物が関わっていることを見出した。また、上記のような「実世界を指向した」システムが、実際に身体的な行為にどう影響を与えるか、ということに関しても、様々な発見をしている。 

システムの研究者と、共同作業や身体的相互行為の研究者にある程度共通の方向性があったことを推測することはたやすい。しかし、実際に共同で研究が行われたことは、比較的少なかった。相互行為の分析が、どこまで現在の状況に適用しうるかは未知数である。そこで、本章では相互行為分析とその基盤となるエスノメソドロジーの概念について、少なくとも著者の理解を示す。また、相互行為分析のCSCWへの応用と、CSCWの分野で用いられている別のエスノメソドロジー的手法についても概観する。 

以降の議論では、主に分析の方法について取り扱うが、社会学の分析手法と、システムデザインの目的、手法、アウトプットなどを混在して扱うことになるため、それらが錯綜してしまいがちである。つまり、 

\begin{itemize}
\item  エスノメソドロジーは何に焦点を置き、どうやってそれを分析し、それによって何を得るのか 

\item  システムのコンセプトはどう決定され、どう作って、どうちゃんと作られているかを評価するのか 

\end{itemize}
という2種類の異なる立場から、少なくとも分析を行う立場において以下のようなことを決定しなければならない。 

\begin{itemize}
\item  システムのデザインという目的設定の元で、エスノメソドロジーをどう行い、何を得るのか 

\end{itemize}
本章ではこの3点について、それぞれを検討することによって、エスノメソドロジーによるシステムが関わる状況の分析について明らかにする。なお、ここでは主に分析を行う側にのみ焦点を当てるが、分析側とデザイン側が共同で作業を行うことの問題については次章で検討する。 

\section{概要}
エスノメソドロジーは、単に日常生活を研究するのではなく、それが既に秩序だっているような手続きを研究する分野である。これを実際に記述する手法が会話分析や相互行為分析で、これらは相互行為のシークエンス的な組織化を詳細に明らかにする。これは、その場面である作業を達成するために、どのようにその場その場で成立する秩序を成員が理解し、次の相互行為につなげているかということがわかる。 

\section{エスノメソドロジー}
エスノメソドロジーは、創始者のHarold Garfinkelによって以下のように特徴づけられている。「私が「エスノメソドロジー」という言葉を使う際は、日常生活の組織立った巧妙な実践の、偶発的で継続的な達成としての、文脈指標的表現やその他の実践的行為の規範的特徴の研究を指す」(Garfinkel 1967: 11)。つまり、我々が何かの枠組みをもって行為を説明する以前に、人々の実践的行為はすでに秩序立っている。この秩序を解明することが、エスノメソドロジーの最も基本となる考え方である。とはいえ、エスノメソドロジーは、単に人々の日常を明らかにする、ということではない。この点を、(Garfinkel, 1967)(Garfinkel and Sacks, 1970)からまとめて説明する。

その問題の一つが、文脈指標的表現である\footnote{エスノメソドロジーは元々社会秩序の問題への取り組み、特にラザーズフェルド、パーソンズなどの「構築的分析」を行う社会学への反論として生まれた。だから、当然この議論は文脈指標的表現でなく、社会秩序から始めるべきであるが、本論文では簡潔な説明のため文脈指標的表現から始めている}。文脈指標的表現とは、ある文脈の中でしか解釈できない表現のことで、素人も専門家(社会学者)も広く利用している。しかし、この文脈指標的表現を取り扱い、日常の秩序を明らかにすることは不可能である。文脈指標的表現を客観的表現に置き換えることが不可能であるためである。ある文脈指標的表現を客観的表現にしたとしても、それに対するさらなる解釈を与えることが可能であり、また本当に客観的であるならそれが必要になる。とすると、完全に客観的な表現を与えるのは不可能である。

一方で、普段生活を行う上では、この作業を行っていながら、なおかつこの問題を我々はうまく乗り越えている。この2つは明らかである。まず、人々が日常言語を話しているように聞こえることから、明らかに「メンバー」つまり、自然言語に精通「していること」(ここでメンバーは特定の個人、あるいは集団を意味する用語ではない)が観察される。自然言語に精通しているということは、そこで起こっていることを「説明」(見て言うこと)でき、またメンバーならその説明を「理解」できることを帰結する。この「説明」は客観的表現である。また、これを「理解」しているということは、客観的表現が完全でないことがメンバーにとっては問題でないということである。これは、説明が文脈に適合したものであるためである。そのうまくいっていることを解明することが、日常の秩序を理解することにつながる。この種の説明を、エスノメソドロジストでない社会学者が行うような客観的表現への変換=社会学的推論になぞらえ、実践的社会学的推論と呼ぶ。

では、説明がうまくいっていることをどう研究すればいいのだろうか。説明を何らかの形で切り出して、それを客観的に述べることは、先に述べた通り不可能である。エスノメソドロジーは、説明がありふれていることに焦点を当てる。我々は日常のあらゆる異なる場面で説明を行うが、それができるのはそれぞれの説明の方法、説明を可能にしている方法が確立しているということで、そこには方法論の研究の余地がある。この方法論は、実際の相互行為にみる説明の方法を、何の解釈も与えず形式的に示すことでのみ立証することができる。だから、エスノメソドロジーは人々の相互行為の形式的な側面に焦点を当てる。

では、説明の方法論の研究が、何を明らかにできるのだろうか。それには、実践的社会学的推論の、「相互反映的」な特徴が関わっている。相互反映的であるとは、説明をすること自体が場面、つまりその場の社会的な秩序の組織を形作っているということである。つまり、説明は場面の一部となる。これにより、説明の方法論を解明することが、場面の成り立ちを理解することにつながる。

このようにして、エスノメソドロジー研究=自然言語に精通した「人々」の、説明の「方法」に関する「研究」は、その場の社会秩序の解明という社会学の問題に寄与する。

\section{会話分析}
この議論では、具体的にどう明らかにするのか、というところまでは踏み込んでいない。エスノメソドロジーを具体的にどうやっていくのかということに関しては、当時エスノメソドロジーが大きな影響を与え、またその代表的な研究手法となった会話分析について触れる。会話分析は、主にSacks, Schegloff, Jeffersonらによって開始された、会話の組織化に関する広範な研究である。会話分析の対象は近年 (Schegloff 2007: xiv)によって以下のように特徴づけられている。 

\begin{itemize}
\item  順番交代 (turn-taking) 問題:会話において誰が次に話すのか?またそれはいつ行われるのか? 

\item  行為形成 (action-formation) 問題:どのように、言語、身体や、相互行為の環境、相互行為内の位置などのリソースが、設計された通りの構造に、また受け手に、その規模もわからないのに特定の行為 (例えば、依頼、招待、許可、不平、同意、知らせ、警告、拒絶など) として認識されるように形成されるのか? 

\item  シークエンス組織 (sequence-organazational) 問題:どのように、次の順番が前の順番と「筋の通った」ものとして形成されるのか?また、そもそも「筋が通った」の本質とは何か? 

\item  トラブル (trouble) 問題:どのように話し、聞いたり、会話や相互行為を理解する際のトラブルが、それが起こった際に止まらず、間主観性が維持、修復され、順番やシークエンス、活動が可能な完了へと進むように扱われるのか? 

\item  言葉の選択 (word-selection) 問題:どのように順番の単位となる構成要素が選択されるのか?また、どのようにその選択が、受け手が理解を達成できるように知らせ、形成されるのか? 

\item  全体構造の組織化 (overall structural organization) 問題:相互行為の出来事の全体的な組織は、どのように組み立てられるのか?その構造とは何か?また、どのように全体構造の配置が、その構造と、シークエンスや順番としての会話を知らせるのか? 

\end{itemize}

以上に見るように、会話分析の対象は「会話構造」、つまり、どのように会話が開始され、行われ、広がり、発話内の問題を解決し、終了に持ち込み、何らかの行為を達成したり会話全体を認識させるのか、ということにある。本論文では会話自体は主要な研究の対象ではないため、そのすべてには触れない。しかし、会話構造のもっとも基礎的な部分、つまり、シークエンスの組織化と隣接対に関して述べる。

会話分析においては、会話の録音と、それを文字に起こして分析を容易にするトランスクリプトが分析の基礎になる。先駆的な研究によって、会話の組織化には発話の間や複数の発話のオーバーラップなどが有意であるということが明らかになっている。これらを含めて書き起こせるようにしたのが、Jefferson Systemであり、後の相互行為分析に使われるトランスクリプトでもその拡張が使われている。特有の記号などについては実際の分析で必要なものをその都度説明する。 

\subsection{会話の順番取りシステム}

会話構造は、シークエンス、つまり個々の発話や相互行為が、時間的な前後関係の繋がりをもった形で組織化されているという特徴がある。このシークエンスの組織化そのものが、会話分析の主要な研究対象の一つとなる。その顕著な例が、複数の人間がいる状況で、次に誰が話すかという問題である。Sacks、Schegloff, Jefferson(1974)は、会話の順番取りシステムの導入により、これに最初に取り組んだ。

Sacksらは、多くの録音データの中から順番交代に一定の規則があることを発見した。これに彼らは社会学的な関心を寄せた。その理由は、まず順番交代が組織だっていることである。順番交代が多様であるのに対し問題なく行われるということは、順番交代の方法の組織化の研究へとつながる。また、順番交代組織は文脈から自由であり、かつ敏感である。会話は「状況の中にある」が、会話の参加者は多様であり、状況の変化にも対応できるためである。

彼らが会話の中に見出した順番取りシステムのモデルは以下のようなものである。

\begin{verbatim}
ターン構成成分:ターン構成ユニットのタイプと、その完了点は予測可能である。順番を獲得すると、その一つを産出する権利を得る。単位を産出すると、そこが移行が適切となる場となる。
ターン配分成分:ターンの配分は、現在の話し手が次の話し手を選ぶ(他者選択)か、次の話し手が自分で自分を選択(自己選択)する。
順番交代は、以下の規則に従う。上から順番に優先される。
(1)最初のターン構成ユニットが完了点に達し、最初の移行が適切となる場に到達したとき
   (1a)他者選択が行われた場合、選択された話し手が順番を獲得し、移行はその場で生じる。
   (1b)他者選択が行われなかった場合、自己選択を行ってもよく、自己選択が行われた場合、その話し手が順番を獲得し、移行はその場で生じる。
   (1c)他者選択も自己選択も行われなかった場合、現在の話し手が話しつづけてよい。
(2)最初の移行が適切となる場で(1a)(1b)が行われなかった場合、(1c)に従って現在の話し手が話し続け、次の移行が適切となる場で(1)の諸規則が適用される。最終的に移行が行われるまでそれは続く。
\end{verbatim}

この順番取りシステムの特徴は、「局所的に」「相互行為的に」管理運用されるということである。まず、順番を1つ(次の順番)しか扱えない、包括的、排他的、逐次的なシステムであるため、局所的なシステムと特徴づけられる。このため、システムは多様性を受け入れる。また、このシステムの執行は参加者自身に委ねられる。相互行為的な側面は、参加者がシステムを用いる際に、他の参加者の貢献を考慮しなければならないことからわかる。順番の大きさや順序は、「受け手に合わせてデザイン」される。これが、会話を「聞く」ことへの同期につながる。

\subsection{隣接対}
一方で、基礎的には隣接している2つのターンが持つ構造が、「隣接対」である。(Schegloff 2007: 13-21)に沿ってまとめる。隣接対は、以下のような特徴を持つ。

\begin{itemize}
\item 2つのターンからなる
\item 異なる話者からなる
\item 隣接している
\item 最初の対のパーツ(FPP)と次の対のパーツ(SPP)からなる
\item 対のタイプに関連する:対には「挨拶-挨拶」「質問-応答」などの型があり、ある型のFPPの次には同じ型のSPPが来る
\end{itemize}

隣接していることは、「相互行為の中のトーク」が組織され、理解される中心的な方法である。隣接性は次のターンが前のターンに「関連して聞かれる」ことと明らかに関わっており。次のターンは、話者の直前のターンへの理解と、またその理解に沿って直前のターンに応答する行為を示すものとして、他の参加者に理解される。これは、次のターンの存在、前述のターンが1つずつ順番に起こることに支えられている。隣接対は、強力な「将来の操作」を持つ。FPPが予期の適切性を投射、つまり次のターンに何が来るのが適切かを制限する。

順番交代の組織化は、言われていないこと、されていないことなどの「ネガティブな観察」を可能にする。とはいえ、そのようなことは無限にあるため、その観察には「適切性の規則」、つまり起こったことを適切であるとできる規則を必要とする。これがあるため、起こらなかったことが「欠如」となる。逆にその「適切な欠如」がその規則の観察を可能にする。隣接対はその強力な手段となる。FPPによってSPPが制限されることを「条件付き適切性」と呼ぶ。次に来るはずのSPPが来ないという事態、さらに誰も話していないと言う事態も、「FPPによって期待されるSPPがない」と観察可能である。また、次のターンは、例えば普通の質問への回答でなかったとしても「直接的でない」SPPとして受け取られる場合もある。会話の中の配置がそれを決めるのである。

ここでは述べないが、隣接対は徹底的に付け加えられ、中に更なるシークエンスが挿入され、修復され、さらには会話自体を開始したり停止させ、会話を完成させる。しかし、その中の隣接したターンを分析することは、何がその会話でなされているかを理解する強力な道具となる。会話は、社会的な相互行為の中でも中心に位置する。その中での隣接対という「説明」を分析するということは、その場面の局所的な秩序の解明につながる。

\section{相互行為分析}
「相互行為分析」は、主にGoodwin, Heathらによって始められた、会話も含めた身体的相互行為をビデオによって分析する方法である。対面した相互行為では、会話の書き出しだけでは発話のポーズなどを説明できない場合がある。もしくは、会話がなくても何らかの相互行為を組織させる、ということはよくあることである。相互行為分析は、前述の会話分析の拡張ではあるが、環境、指示などのあり方にさらに迫ることができる。　

\subsection{発話から身体的相互行為へ}
視線や指差しへの研究者の注目は、会話分析の中の、特に順番交代やトラブルについて解明する作業から始まった。GoodwinとHeathの初期のこの種の研究について少し触れる。Goodwinは、発話の開始の際の間、途中で発話を止める「ポーズ」、途中の発話をやり直す「再スタート」などの、一見して発話の中のトラブルと見える現象に注目した(Goodwin 1981)。これらは、秩序が壊れているということではなく、それ自体秩序だった現象である。しかし、その秩序は音声発話の中のみでは解明することができなかった。 

その秩序を見るために、Goodwinはビデオ撮影によるデータの収集を行い、視線と発話の前後関係を詳細に分析した。その結果、話者が受け手の視線を維持することを気にかけ、それに合わせて、あるいは戦略的にポーズや再スタートを用いることがわかった。1つ例を見る。

\begin{figure}[!h]
\begin{verbatim}
(4) DEBBIE:  Anyway. (0.2) Uh:, (0.2) We went t- I went ta bed
                                             [
    CHUCK:                                    X_______________
\end{verbatim}
\caption{再スタートと視線の獲得、(Goodwin 1982)より引用}
\end{figure}

この例では、CHUCKが視線をDEBBIEに向ける(X)直後にDEBBIEが再スタートを行っている。このような再スタートに見るように、話し手は聞き手に合わせて発話を産出しており、視線の獲得の問題がその一つになっていることがわかる。一方で、話し手は聞き手をただ見ているわけではない。この例とは違い、話し手が先に再スタートを行い、聞き手が視線を向けることがある。この場合、「呼びかけ-応答」連鎖のように、「再スタート-視線」という連鎖が起こっている、つまり視線の獲得の「ために」再スタートを行っていることが示唆される。このように、話し手と受け手が相互に調整しあいながら会話を作っていくことを、視線から見て取ることができる。

一方、Heathは次の話者を選択する際の「受け手性」の問題に目を向け、それが身体的相互行為と関連していることを発見した(Heath 1982)。相互行為においては行為がどう受け取られ、注目されるかが焦点となる。「次のターン」の選択はその重要な例である。また、次のターンにおいては話し手も、どう他の参加者が発話に注目しているかを判別するため、他の参加者の行為を志向する。ここに、話し手が参加者がどう受け手性を表示しているかを研究することで、相互行為について解明する動機が生まれた。子の問題に取り組むためにHeathが利用したビデオデータは病院の診察場面で、主に診察が始まる、患者が部屋に入り初めてから本題の診察が始まるまでを分析している。 

診察という「話題」は、単に診察室にいるから始まるというものではない。話題の開始には「挨拶」などの会話の開始や、話題が開始するターンが適切な位置に置かれる必要があることは既に電話会話などで示されている(Schegloff 1968)。この話題を開始する際に、患者はドアを開け、椅子に座る。この際、電話会話のように話し手への注目が維持されているとは限らない。 

診察場面の一例を参照する。 

\begin{figure}[!h]
\begin{verbatim}
   01    (door opening)
   02    (0.5)
   03 D: Hello
   04    (2.3)
   05 D: Mohammed Oola?
   06 P: Yes
   07 D: Yes could you sit down (.) please
   08    (7.3)
   09 D: What can I do for you?
   10 P: ゜hhh (0.2) um:: (0.7) um: last week in
   11    our::::fff holiday (0.7)
\end{verbatim}
\caption{診察場面での受け手性の表示、(Heath 1984)から引用}
\end{figure}
患者が入ってきて挨拶を交わし、医師が座るよう促す。その後、「どうされました」と医師が話題を開始するまでに7.3秒の沈黙がある。この部分をさらに詳細に見ると、以下のようになる。 

\begin{figure}[!h]
\begin{verbatim}
  D reads records
  ---------------------------------
  D:,----------,----------,--- what can I do for you ?
                            ..___________, ,
    ↑                   ↑↑
    P lands and        posture and
    posture shifts     then gaze
    away               shift towards
                       D
\end{verbatim}
\caption{診察場面での受け手性の表示(詳細)(Heath 1984)より引用}
\end{figure}

話題開始ターンの2.3秒前、患者は医師の後方に座る。患者は医師を見てから目を背け、前に動き、もう一度後ろに言ってから前に戻る。そこで患者は医師を見て、医師は即座に話題開始ターンを始める。以上の身体的動きより、まず最初の5秒で患者は医師と共在を達成し、診察開始への応答可能性を提示する。しかしそれに医師は即座には応答せず、次の2.3秒の間に患者が応答可能で、医師が発話を開始できるようになったことが分かる。ここで、患者は視線と身体の向きを通じて、受け手性を提示している。患者の視線の動きと医師の発話の開始が即座に併置されているからである。応答可能性は医師の発話のターンに見て取れる。応答可能性が開始する前の起こりうる範囲の行為の環境を提供するのに対し、受け手性は実際に特定のシークエンスを開始する。このように、ある発話の受け手はその相互行為によって受け手として認識される。

%\section{様々な実世界の環境に関する概念}
%CSCWにおいては、認知科学的な概念を用いて議論がされることが多い。特にいくつかの概念については、相互行為分析などによって深く検討された概念もあり、CSCWにおけるエスノメソドロジー研究においてよく使われている。本節では、そのような概念について検討する。
%
%\subsection{エコロジー}
%\subsection{アウェアネス}
%アウェアネスとは、「人がそこにいる」という感覚である。これは、対面以外の環境では失いがちなものである。
%
%リアルタイムチャットシステムを例に取ろう。基本的に、チャットシステム自体ではアウェアネスは「ログインしているか否か」以外を判別できない。ログインしていても、ユーザーに見えない状態では事実上何もわからないことになる。例えば、複数の部屋と場所にまたがってチャットを使う場合を想定する。参加者は各々が芸術展示の準備をしており、タスクなどが割り振られておらず好き勝手に出入りして、作業をするものとする。その場合、必ずしもユーザーがチャットの前にいるとは限らず、寝ているかもしれない。
%
%この状況で、チャットで誰かに連絡を取ることを考える。もし相手が呼びかけに応答しない場合、複数の可能性が考えうる。これを何らかの形で識別し、解決しなければならない。その一つが、「同じ場所の別の人間に頼む」ということである。しかし、もし頼んだ人間と連絡対象が別の部屋にいた場合、部屋を移動しないと連絡を取ることができない。結果として、チャットシステムでのアウェアネスの問題を、人が実際に移動するという身体的手段で解決することになる。この場合、解決が可能である分、むしろ別の場所にいた方が手間がかからないことになる。
%
%\subsection{コンフィギュレーション}

\chapter{エスノメソドロジーの実世界志向インタフェースへの適用とその意義}
エスノメソドロジーの、その場面で成り立っている秩序を成り立たせている人々の方法への関心は、例えば順番交代のような「包括的」なものだけでなく、ある特殊な場面でのみ成り立っている秩序の方法への関心も生んだ。この種の一連の研究を「ワークの研究」と呼ぶ。ワークの理解は、同じく作業=ワークに関心を向けるCSCWへの応用の可能性を開いた。また、相互行為分析は、人の会話が実世界で行われることについて、明らかに単にジェスチャーが行われているという以上の理解を可能にしている。エスノメソドロジーは、CSCWと実世界志向インタフェースが共通して持つ特徴について明らかにしているとも言える。

一方で、このような関係は、比較的速く進歩する工学分野のパラダイムと、その現状に大きく影響されることになる。特に、反復型開発と「ユーザー経験」の隆盛に伴い、エスノメソドロジー研究を工学のどこに位置づけるかに関して多くの議論や実践が生まれ、まだ明確な結論は出ていない。また、実世界志向インタフェースの分野や、バーチャルリアリティと強く関連付けられた拡張現実感技術分野は、新奇性を強く求める傾向にあり、それもエスノメソドロジー研究の適用を難しくしている可能性がある。

本論文の目的は、空間を扱うようなシステムがどう使われるかを解明することである。しかし、システムに分析者が関わることのできる手段は一つではない。例えば、自分でシステムを作って分析する、システムを作るプロジェクトに参加する、既にあるシステムが使われる場面に参加するなどである。また、これらの手段によって場面が異なるため、分析の方法や分析者の役割にも大きな違いがある。本章では、システムに関わるエスノメソドロジーの様々な側面についてまとめ、その可能性を検討する。 

\section{エスノメソドロジーが貢献しうる役割}
エスノメソドロジーによる共同作業システムの分析がどのような役割を果たすかに関しては、いくつかの見解がある。これは後述するデザインプロセスの問題にも関連している。

Buttonによるまとめ(Button 2009: 39-43)では、エスノメソドロジーのワーク研究が設計の目的に対して使われる際には、4種類の使い道があるとしている(Button 2009: 39) 

\begin{itemize}
\item  批判:既存の設計手法で作られたワークフローシステムは、実際の場面に導入された場合に、詳細な分析をした際に明らかになるような、作業の組織化の状況に埋め込まれており即時的な特徴のために困難に直面してしまうということを示すために用いられる 

\item  評価:特定の技術デザインを評価するために用いられる。実際のワークプレイスにシステムを導入した際に得られたデータを分析し、システムの改善に活かす。 

\item  要求:実際のワークプレイスを分析して得られたデータを元に、システムの要求を決める。 Bentley1992 によれば、ワークプレイスの分析は要求を詳細に定義するのにはあまり有用ではないが、設計の際の適切な意思決定を提供する。 

\item  基礎的な関係:設計者とワークプレイスの分析者 

\end{itemize}

\section{システムデザインへの適用}
相互行為分析などの、エスノメソドロジーに影響を受けた手法(Ethnomethodology-informed Ethnographyや、会話分析なども含む)をどう実際のシステム設計に取り入れるかに関しては、その当初から議論が存在する。前章ではシステムが関わる状況でのエスノメソドロジーについて検討したが、分析のアウトプットは必ずしも設計者の関心の中にないかもしれない。例えば、あるタスクを行わせて各段階での作業時間を計測することは、システムの評価に有用だろう。また、新たなシステムを設計するために以前のシステムについてインタビューを行ったり、SD法によって感性を調査することは、少なくとも筋が通っている。しかし、エスノメソドロジーや相互行為分析に関しては、前章で見てきたように、単純に「実際の環境での使用を見る」「日常生活について理解する」などの視点で見ることができない。何より、分析結果が単純に何が良い悪いということを必ずしも提示しない。 

そのような前提を元に、エスノメソドロジー的調査はどう行えばよいのだろうか。その中には、完全に設計を無視して行う方法から、設計の際に必要なことだけを集中的に分析する方法まで多様な可能性があり得る。また、それに応じて分析の設計に対する位置づけも変わってくる。本章では、エスノメソドロジー的分析の知見のシステムデザインでの位置づけられるか、システムデザインのプロセスの中の分析と分析者の位置づけ、またその実例について検討する。

\subsection{反復型開発と日常的場面、実験}
現在に至るまで、ヒューマンインタフェース、あるいはヒューマンコンピュータインタラクションの研究において中心的な役割を占めるのが「反復型開発」である。これは、従来の「ウォーターフォール開発」、つまり、最初に全てを設計して、後は開発するだけという「一切振り返らない」モデルからの脱却として生まれた。問題が技術的な仕様の特定のみであった時代では、「評価」は中心的な問題ではなかった。例えば、処理速度などの問題は、システム開発側のみであらかじめ吟味することができる。しかし、人間と機械のインタラクションという側面を取り入れた場合、何秒以内の応答が好ましいかなどの、人間の認知や行動に関わる側面を取り入れる必要がある。この際、実際にシステムが導入され、ユーザーに使われないと評価が行われないため、必然的に外部からのフィードバックを取り入れる開発手法を採用することになる。この考え方は、主に認知科学や人間工学の視点から導入された\footnote{反復型開発には、純粋にシステムが肥大化して要求を特定できないというモチベーションもあるが、ここでは取り上げない}。

反復型開発の代表例が、ISO規格(ISO 13407/翻訳JIS Z 8530)となっている、「人間中心設計」である。これは、1999年に策定された、人間工学に基づいた「使いやすいインタラクティブシステム」を作るための設計プロセスの基準で、これを守っているかどうかを認定することが可能である。ISO 13407では以下のようなプロセスのみを特定し、具体的な方法については例示するにとどまっている。

\begin{enumerate}
\item 人間中心設計の必要性の特定
\item 利用の状況の把握と明示
\item ユーザーと組織の要求事項の提示
\item 設計による解決案の作成
\item 要求事項に対する設計の評価
\item システムが特定のユーザー及び組織の要求事項を満足
\end{enumerate}

これの2から4が反復する。もちろん、反復型開発の全てがこれに沿っているわけではないが、一種のリファレンスとしては機能するだろう。これをに組み入れられる調査手法は多く、例えばあるタスクを行い行動をみる「ユーザビリティテスト」などは人間工学由来の手法である。

エスノメソドロジー研究に基づく人間とシステムのインタラクションの調査手法をシステム開発に利用する場合、この既に人間工学が完成させていた反復型開発モデルがその原型となった。「エスノメソドロジーとシステム開発」を主題にする場合、それはまず人間工学由来の反復型開発プロセスに示唆を受けている。例えば、BentleyらによるHCIのプロトタイピングのサイクルは以下のようなものである(Randall 2007)。

\begin{enumerate}
\item 既存のもっとも近いデザインを持ってくる
\item インタラクションを観察する
\item 現象を翻訳する
\item (最初のみ)設計について調査し、最初のデザインを行う
\item 変更を提案する
\item 変更を実装する
\end{enumerate}

このモデルは、「評価」と「改善」の2つのプロセスからなる(Randall 2007)。ここでは「インタラクションを観察する」フェイズは先のISO 13407に当てはめるなら評価と状況の把握の2つの目的を持つが、本質的な部分は変わっていない。

一方で、このモデルでは、ISO 13407にないフェーズが含まれている。「現象を翻訳する」フェーズである。ここで前章で検討したエスノメソドロジー研究を振り返る。「現象を翻訳する」というのは、エスノメソドロジー研究のある意味で「アウトプット」である「文脈指標的表現」を別の「客観的表現」すなわちシステムの要求事項に変換することに最終的に帰結すると言える。これが少なくとも反復型開発における、人間工学にはない問題点として、長らく問題を生んできた。また、この問題は、システム設計者との接点の問題ともなる。

その初期の答えとして、Hughesらによって初期にまとめられたものは、以下のように分類される(Randall 2007)。

\begin{itemize}
\item 「既存の知見の再確認」は、すでに行われた似たような研究、例えば銀行のワークの研究に対する既存のペーパーワークの研究を、改めて確認する作業である。基本的に再利用を目指しているが、状況の細かな違いが重要となる。
\item 「Quick and Dirty Ethnography」は、あらかじめ焦点を定めて行う方法である。基本的にシステムの設計から焦点が生まれ、この先本格的なエスノグラフィー(Concurrent Ethnography)を行う際の手がかりにもなる。
\item 「Concurrent Ethnography」は、システム開発と同時並行的に行う方法で、基本的にシステム開発側と同じ対象を持つが、もっとも自由な方法である。次のデザインプロセスに示唆を与える。
\item 「Evaluative Ethnography」は、既にあるシステムを評価するために使われるエスノグラフィーである。どこが問題になるかをあらかじめ理解した上で行われ、それを解決する策を見出す。
\end{itemize}

これらは基本的に、「評価」と「改善」のどちらか、もしくは両方を開発プロセスとの接点としている。このため、「翻訳」の問題は根本的には解決されておらず、何らかの形で妥協されることになる。これは、反復型開発に内在する問題である。これに対して、システムへの反映は不可能であるという主張(Suchman 1994)や、距離を置くアプローチ(Dourish 2007)もあるが、基本的に「評価」と「改善」に論点が絞られている。

この「翻訳」の問題に取り組んだのがDourish, Hughesの「テクノメソドロジー」である。従来、エスノメソドロジー研究のシステム記述への翻訳は「エスノメソドロジストに学ぶ」つまりエスノメソドロジストの知見をフィールドを代弁するものとして捉えるものである。また、「エスノメソドロジストの説明から学ぶ」は、エスノメソドロジー研究の成果そのものにアクセスし、システム記述に役立てるものである。ここで「知見の代弁」と「成果」が異なることは前章でわかるだろう。どちらのアプローチを採用しても、翻訳が起こることに変わりはない。

Dourishらの主張は、エスノメソドロジー研究の記述とシステム記述を同じ方針でやるということである。この場合、システム記述の仕方そのものに注目をする。具体的には、エスノメソドロジーが社会学に行ったのと同じような批判を加えていく。もちろん、これはシステム記述をエスノメソドロジー研究にするというわけではないが、Dourishらはエスノメソドロジー研究の「説明可能性」の概念と、システム記述における「抽象化」の概念にその活路を見出している。

テクノメソドロジーでは、「インタフェースの抽象の説明可能性」に注目する。通常プログラマーは、「実装」すなわち具体的なコードだけではなく、様々な抽象化の方法、例えば変数と処理を1つの塊として、実際の物体のように扱えるようにした「オブジェクト」などを用いる。これは単に開発上の利便性だけでなく、ユーザーも同じ抽象化を用いるように想定されている場合もある。しかし、実際にはユーザーがシステムを利用する際に与える説明は、その使われる場面に沿った、またその場面で説明可能にする実践によっている。このユーザーの説明可能にする実践に注目し、それに沿った形で実装を行えた場合、「翻訳」の問題は起こらなくなる。

このギャップを埋めるのが、「conputional reflection」という概念であるとテクノメソドロジーは主張する。Dourishらの説明は難解であるが、2011年現在、このパラダイムはWebプログラミングにおいて頻繁に利用されるため、これを例に取る。例えばRuby-on-Railsは、WebにおけるMVCパターン(2.4.3節参照)の簡単な実装を行えるフレームワークであるが、その中の中心的な機能として「O/Rマッパー」というものがある。これは、オブジェクトがどう作られているかによって、関係データベースの処理コードを自動生成する機能である。新たに何らかの属性がオブジェクトに加えられた場合、対応する関係データベースの処理コードを名前から類推し、なかった場合典型的な処理を加える。これにより、関係データベースのことを考慮しなくても、オブジェクトを普通に使うだけでデータベース処理が可能になる。

このようなことがユーザーインタフェースにおいても可能になることをDourishは想定している。ユーザーがシステムの想定していない側面に注目したり、そのような使い方をしたら、それに合わせた処理が可能になるというのである。端的に言えば、この試みは極めて難しい。現状で開発者のみが使うO/Rマッパーですら、想定しない操作を実装することは難しく、開発者はよく関係データベースを直接用いる。著者の見解としては、この仕組みの設計、つまりリフレクションを行う処理自体がユーザーをモデリングしてしまうという問題があり、「翻訳」の問題をある意味で後回しにしているだけとも言える。もっとも、これに関してはさらに吟味する必要がある。システムの設計自体ではなく、「システムの説明可能性」及びその設計論に注目するというのは注目に値する(2.5節参照)。

本題に戻る。ここまでで、反復型開発、さらには「翻訳」を行う方法論自体にエスノメソドロジー研究との「相性の悪さ」が内在することを指摘した。もっとも、これはシステムを開発するプロセス全体をエスノメソドロジー研究として貫徹することが不可能である、と述べているに過ぎず、システムに関わっている人間がディスカッションを行って、何らかの結論に至るという点では、それが不可能であるというわけではない。一方で、エスノメソドロジー研究の「翻訳」を避ける方法論も存在する。それは端的に言えば定義を行わない設計論である。

\section{新しいシステムが使われる場面の観察}
\subsection{イベントの開催による日常の観察}
新技術は、ある日突然日常生活に導入されるわけではなく、いくつかの一般の人間が触れられる領域にまず導入される場合がある。その一つが、エンターテインメントである。エンターテインメント分野は、ユーザーインタフェースやバーチャルリアリティの一般分野での最前線と言える。例えば、最近だと「戦場の絆」や「Kinect」は未来に近い一例である。 

このような場はエスノグラファーが新技術が導入された現場を観察できる、貴重な場となりうる。前節までに見てきたように、システム開発においてエスノグラフィーを行う方法は、実験的状況での特定のタスクの観察と、純粋に現在行われている日常の作業場面の観察に分かれている。その2つの折衷策として、Benfordらは、イベントやアート展示などの分析が、実験的な状況と日常生活の架け橋となることを提案している (Benford 2002) 。バーチャルリアリティやインタラクティブアートの展示会は、しばしば一般人が新たな技術に触れる機会となる。技術を「展示」することで、Benfordらは以下のような利点があるとしている。 

\begin{itemize}
\item  外に出すため、技術を曖昧な概念ではなく、詳細な領域まで落とし込める 

\item  実際の環境で評価できる。公共的な場を研究に巻き込むことが出来、また一般人に新技術のインパクトの理解をプロモートできる。実験では得られない忌憚なき意見も聞ける 

\item  芸術やエンターテインメントの創造性は、新たなアイデアを育てる土壌となる。また、芸術家の持っている技術を研究に利用できる 

\end{itemize}
((Benford 2002) より著者が要約) 

一例を挙げる。Crabtreeらは、「Can You See Me Now」という、位置情報ゲームとバーチャルな都市空間を融合させたゲームを開発し、そのイベントを開催することで、多くの一般人が新しい技術に触れる状況を観察した (Crabtree 2004) 。彼らは、ゲームの中のRunner(主催側の参加者。GPSを持って街を走り、別のRunnerと協力しながらPlayerから逃げる)をビデオで撮影し、通信を録音し、Player(実際の街を再現した3D環境をFPSのように操作し、Runnerを探す)の行動のログを取った。その結果、(この辺Macからサルベージする必要がある) 

\subsection{HCI研究展示のインタラクティブアート的なあり方}
ところで、実際に日本国内でこのようなイベントが行えるかに関しては、いくつかの問題がある。HCI/CSCW研究を外に出す一つの手段が、学会発表であり、そのうちの幾つかは一般に開かれている。恐らくそのような場でユーザーの観察や、ビデオデータなどの取得は可能であると推測される。例えば、「インタラクティブ東京/IVRC」や「インタラクション」などはその一例であるといえる。 

一方で、このような場で多人数を含んだ形でのインタラクションの観察を行うことは難しいと考えられる。というのも、実際にどのようなシステムを扱う論文が通過するか、に関わらず、展示を行うスペースが1ユーザーのインタラクションを想定して設計されているためである。例えば、「インタラクション2011」の「インタラクティブ発表」で通常与えられるスペースは長机2つ程度である。 

このような展示の背景には、SIGGRAPHの影響があると考えられる。SIGGRAPHはもともとACMのコンピュータグラフィックスを扱う分科会であったが、2章に見るような技術的変遷から、ヒューマンコンピュータインタラクション、バーチャルリアリティなども扱っている。一方、SIGGRAPHはインタラクティブアートの主要な展示会でもある。実質的に、SIGGRAPH、もしくはそれに類似した学会発表での展示の場は、インタラクティブアートの展示と似通っている。すなわち、数平方mのスペースで1人が鑑賞を行うというスタイルである。 

以上のような事情から、現状で拡張現実感を使った遠隔共同作業システムなどを、イベントの形で提示することは難しい。一方、このような状況を打破するような展示の試みは、別の形式の芸術展示から得ることができる。 

著者も参加した藤城嘘、黒瀬陽平らのキュレーションによる企画展「カオス*ラウンジ」は、ギャラリーという空間に日常生活そのものを取り入れた展示である。カオスラウンジの全体のコンセプトは、一言でまとめると「Webサービス上で行われるコラボレーションの可視化」である。 

例えばpixivなどのWebサービスでは、ユーザーが絵を投稿することができ、それを例えばキャラクターなどのタグによって一覧することができる。一方、このような絵を「芸術表現」と呼ぶのは難しい。タグによって表示される大量の画像の中で、「作者」を鑑賞者が意識することが極めて薄れているためである。一方で、このような状況下で、日々新たな絵が生まれ、コミュニティが曖昧に増殖していく。 

一方で、pixivにおける作者は、自らこのような状況で匿名の作品を収集するとともに、それを元に作品を製作していく存在である。多くの作品に曖昧に影響を受けながら、自身の作品を製作していくという、極めて薄い層のコミュニケーションがpixivの特徴である。「カオス*ラウンジ」は、このような状況自体を可視化する目的で行われた。 

カオスラウンジは当初はライブペインティングの形式を取っていたが、日常的にツールを活用しながら現実空間で集まっている、元々接点のなかった先端的なインターネット利用者の集団「破滅クルー」をメインにした展示「破滅*ラウンジ」(2010年5月)では、ギャラリーそのものの枠組みを破壊する試みが行われた。元々破滅クルーは「ギャラリーで開催期間生活する」という参加の形式を取っていた。生活を送ることにより、ギャラリーがネット利用者の色に染まっていくことを意図した展示であった。これはいくつかの現代美術にも見られる形式である。しかし、破滅クルーはそれとは別にいくつかの「作品」を展示した。これにより、ギャラリーには「破滅クルーの生活」を含めて作品、展示、生活の区別がつかなくなった。 

その要素自体を分析して再現したのが、2010年12月に開催された「【新しい】カオス*ラウンジ【自然】」である。この展示では、作品との1対1の対峙としての鑑賞を意図的に排除するように、空間自体が設計されている。例を上げれば、入り口の仕切りとディスカウントストア「ドンキホーテ」のような圧縮陳列の採用などがこれにあたる。 

この例に見るように、実世界指向のインタラクションがしばしば目指すような「コンピュータが見えなくなる」という展示を、現在ありふれた展示空間で行うことは可能である。もっとも、このような空間にどう分析者が入っていけばいいかに関しては検討の予知がある。 


\chapter{フィールドワーク:ジオジオスタンプラリー}
これまで見てきたように、あるシステムが使われる状況をビデオに撮影し、分析するということは必ずしも定型的な作業ではない。本研究では、特定の場面やシステムに対して分析を行うのではなく、複合現実感や位置情報技術など、比較的漠然としたコンセプトでまとめることのできるシステムを、どう分析することができるかということを検討するのが目的である。 

現在，iPhoneやスマートフォンなどの高度な携帯電話端末が，一般ユーザーに普及している段階にある．これらは，通話やメールなどの枠を遥かに超え，「セカイカメラ」などの位置に対応した情報をカメラ映像に重ねる技術など，従来からMixed Realityと分類されてきた技術を，エンドユーザーにまでもたらしつつある．現在は未だ普及の段階にまで達していないが，実世界とオンラインを結びつける試みに，携帯電話は今後も重要な役割を果たす可能性がある． 

一方で，実世界の環境で，携帯端末がどう使われるかに関しては，十分な検討がされていないと見られる．携帯電話には，一人で画面に向き合うだけではなく，例えば電車内で若者が携帯電話に表示されたメール，画像などを見せあっているように，複数人で，場面に応じて共同的に利用するものとしての側面がある．本論文では，実際に携帯端末がどのように複数人によって，実世界の場面の組織化に利用されるかに関して，詳細な分析を行う． 

\section{フィールドについて}
屋外での情報機器の使用を観察する際は，公共のイベントなどの利用が有効である．実際の研究としては，Can You See Me NowというMixed Reality Gameの分析が挙げられる．2009年現在，国内ではその一種と言えるiPhoneを利用した位置情報ゲームが複数行われ始めている． 

本研究では，「ジオジオスタンプラリー」という，レーダーのような形式で提示されたポイントの情報やヒントを頼りに，宝探しを行うゲームの調査を行った．これは2009年7月20日に行われた，全体で50人程度が参加したイベントである． 

参加者はGPSの専門スタッフ1人を含む5人程度の8つのチームに分かれ，各チームにiPhoneが1台配布された．iPhoneにはDGRadar（図）がインストールされており，それを用いてゲームを行う．DGRadarはGPSで現在位置を取得し，レーダーのように現在位置を中心として，周辺（拡大縮小可）の登録されたポイントへの方角・距離と画像などの付加情報が表示されるアプリケーションである． 

実際に行われたゲームは，（１）立教大学キャンパス内での人形探し（２）都電沿線でのスタンプラリーの2つであったが，本論文に関連する前者についてのみ記す．人形は1cm程度の高さのアヒルであり，マグネットによって金属部分に接着可能である．この人形がキャンパス内の5カ所に配置され，それぞれのポイントの位置情報のみがDGRadarに登録された． 

各チームはこのアヒルを30分程度で可能な限り見つけるというルールであるが，特に勝敗などを決めるものではなく，純粋に楽しむ目的のものであった．ゲームの終わりに全員集合し，各チームの結果や動いた軌跡などを主催者が発表した． 

本イベントには，田島が技術サポートの集団の一人として参加しており，その中で企画者に調査の提案をした．参加者には最初に集合した際に調査内容に関して説明を行い，全員に口頭で撮影の許可を得た．その後，1チームに対して全体で30分程度，小型のデジタルムービーカメラを用いて追跡して撮影を行った．このチームでは，持参のものと含めて2台のiPhoneを用いていた． 

\begin{figure}[tb]
\centering
\includegraphics[width=0.5\hsize]{DGRadar_image.eps}
\caption{DGRadarのインタフェース}
\end{figure}

\section{分析}
本研究では，携帯端末の使用を，人々の共同作業の相互行為的な達成の観点で分析した．すなわち，単に一人で画面に向き合い，画面上の情報とインタラクションを図るというだけでなく，周囲の環境/人間と協調しながら，実世界に関係する作業を達成していくという観点である． 

共同作業の達成を分析するにあたり，社会学のエスノメソドロジー的な相互行為分析の手法を用いた．これは，ビデオデータなどを用いて，その場に居合わせた人間の会話，指さしなどの身体的な相互行為が，継起的な秩序の中でどのように組織化されるかを分析する手法である．本研究では，特にiPhoneやその使用が，環境の中でどのように見られ，相互行為の中に組み込まれていくかに焦点を当てる． 

\subsection{指さしによる環境の指示}
Goodwinは，環境の特定の対象を指す種類の指さしをSymbiotic Gestureとし，会話と全く異なる記号であるが，会話と協調して使われるものとしている．「ジオジオスタンプラリー」で見られた指さしは20件あったが，そのうちの10件がDGRadarを参照した「方角」の指示であった．典型的なものを断片1（図）に示す．以下では，Aの持つiPhoneをiA，Bの持つものをiBとする． 

\begin{figure}[tb]
\centering
\small{
\begin{verbatim}
p 指さしの方向
----
01 A|一番近いのは::番号では38メーターっての=                                      
  Ag|iA-------------------------------------
02 A|=があった
  Ag|iA-----------
  Bg|        ,A---
03 A|(4.5)
  Ag|iA----------------------------
  Bg|A-----------------------------
  Bm|((Bを見ながらBに向かって歩く))
04 A|38メーターってのがあった(.)向こうに
  Ag|iA--------------------------,p-------,iA--
  Ap|                        ,,,,,,p-----------
  Bg|                                ,,,p----,,
\end{verbatim}}
\caption{断片1}
\end{figure}

\begin{figure}[b]
\centering
\includegraphics[width=0.7\hsize]{seeing_filtered.eps}
\caption{iPhoneを見ていることの提示}
\end{figure}

\begin{figure*}[t]
\centering
\small{
\begin{verbatim}
Am:((道路の方向を指さしている))                          ((              止まりiA見る               ))
Bm:      ((A見る))((指さし方向見る))((停止，A向きiB見る))((iB指さす))    ((iB見ながらAに向かって歩く))
\end{verbatim}}
\caption{断片2}
\end{figure*}

Aは自身のiPhoneを見ながら，次のポイントを発見して報告する．Bはそれを受け，Aの方向を向いて歩き始める．その途中で，AはiPhoneを継続して見ながら，ポイントについてもう一度報告し，一度iPhoneから目を離してポイントの方向を指差し，またiPhoneに視線を戻す．Bはそれを受け，指さしの方向を見てから二人とも歩き始める． 

ここで注目する点が，断片1の2,3行目でAが自身のiPhoneを見ているということを，Bが見ているということである（図）．これにより，Bはその後の指さしがDGRadarの提示するポイントを指していることを理解できる．「向こうに」に伴った指さしは，特定の物体や，道路に沿って指したものではない．iPhoneの，方角を提示するDGRadarを見ているということを見た上で，方角を提示していると，意味のある形で理解できるのである． 

「方角」と，進むべき「方向」は相互行為の中で明確に区別されていた．DGRadarを見た後の指さしと共に「曲がってってもいいんじゃない」という発話を行い，その後チームで建物を迂回する例が見られた．指さしは表示の方角を指しているが，その先には建物があった．このため，「あっち」「東」などの方角ではなく，「曲がってって」という発話が行われた．方角を，進むべき方向に再構成して発話を行ったのである． 

iPhoneを見ているということにより，見ている人の体の向きが，DGRadarの方角を指していると見られた場合があった．ある場面では，Aは最初道路に沿って歩いていたが，iPhoneを覗き込んで横を向いた．それを見た他のメンバーが，向いている方向に歩き始めてしまった．それを受け，Aは「あ，違う，真向こう，真向こう，真向こう，向こう」と訂正を行い，本当にDGRadarが提示している方角を指さす．この場面ではAの見ているiPhoneと，メンバーが利用する資源であるAの体の向きという，2つの異なるエコロジーが問題を起こしている． 

以上のように，ジオジオスタンプラリーではiPhoneを見ていることと，指さしや身体的配置は，関連づけられて理解されていた． 

\subsection{2台のiPhoneによる問題解決の試み}
ほとんどのチームで，GPSの精度の問題が発生していた．GPSの誤差は明確には表示されていなかったが，チームの相互行為の中で，複数のiPhoneを用いて明らかにした部分があった．断片2（図）はもともと進んでいた方向の異常に気づき，集合する直前のデータ，断片3（図）は集合してから問題解決を始めたデータである． 

\begin{figure}[b]
\centering
\small{
\begin{verbatim}
01 A|ずっとこんなんだよ=
   B|                  =北え？きた？
   Bm|                         ((iA指差し))
02 A|北こっち
  Am|  ((iA指差し))((北を指さす))
  Bm|--------
03 B|えっとだからー
  Bm|------(なぞるような動き)
04 A|うん
05 B|これ(　　)まがって，方角的には
  Bm|------------------------------
06 B|=どっちなんですか
  Bm|-------,,((指iから外す))
07 A|え::と方角的には::(.)え:=
  Am|,,,,,,,,,,,,,iA---------
08 A|=:と(2.9)
  Am|((i覗き込む))((体の向き動かす))
  Bm|             ((体の向き動かす))
09 A|イースト(2.6)
  Am|,,,,,,,((東指さす))
10 B|イーストって::っと
  Am|(iをAに持っていく)
11 A|は:い
  Bm|     (i受け取る)
12 B|こうなって
  Bm|        ((体の向き動かす))
13 C|今，衛星状態が非常に悪いんですね
\end{verbatim}}
\caption{断片3}
\label{}
\end{figure}

\begin{figure}[b]
\centering
\includegraphics[width=0.7\hsize]{kita.eps}
\caption{2台のiPhoneでの問題解決の開始}
\label{}
\end{figure}

\begin{figure}[tb]
\centering
\includegraphics[width=0.7\hsize]{2dai2.eps}
\caption{平行になるようにiPhoneを渡す}
\label{}
\end{figure}

当初2人が別のiPhoneを持って歩いており，Aが指さしで先導していた．しかし，BがAの指差しの方向を見て，iBと照らし合わせ，Aに見える形でiBを指差す．Aは止まりiAを見て，BはiBを見ながらAに向かって歩き始める．それを受けてチーム全員が集合する． 

集合後，1行目の発話で，Bの胴の向きがAのiPhoneへ向かい始める．Bの「北」の発話の段階では，Bは自身のiBを見ているが，iAを見て「きた？」と言いiAを指差す（図6）．その後ジェスチャーで2台の向きの違いを指摘し，iAの指す方角を聞く．それを受けたAの「イースト」の発話と指さしの後，iPhoneをBに手渡し，並べて見る．そこで初めて，専門家であるCが衛星状態について述べる（13行目）． 

注目する点は2つある．まず，どのようにBがAのiPhoneを参照する状況ができたかである．集合前に既にBはiBの異常を示していたが，01行目と胴の動きでiAを見る準備がされている．その後，「北」でiBの表示の具体的な内容を示す．その後の「きた？」でiAを指差したことで，iAとiBの違いが示される． 

次が，2台のiPhoneの比較である．iAとiBの表示の違いは理解されていたが，具体的にどう違うのかは，恐らく2台のiPhoneの向きの違いから，直観的にはわかりにくかった．03行目のなぞる動きや，06行目の「どっちなんですか」10行目の「てーと」という疑問がそれを示している．その直後，AはiAをiBと平行になるようにBに渡す（図7）．2つのiPhoneの示す方角は，既に「北」「イースト」で示されている．しかし，精度を問題にする場合，2台を比較可能，つまり平行にすることが必要であった．Cによる専門的な指摘は，2人の比較を見た直後である． 

\section{まとめと応用可能性}
本調査では，GPSを用いた宝探しゲームの中でiPhoneが環境の中でどのように理解され，複数人の相互行為の中に組織化されていくかを分析した．以下に分析の知見をより一般的な形でまとめる． 

\begin{itemize}
\item  携帯端末を見たり操作していることは，他の参加者が見ることができ，使用者の身体的相互行為は携帯端末に関連したものとして理解された． 

\item  身体的配置により，誰かが使っている携帯端末は他の参加者にも利用可能になった． 

\item  複数の端末などがある場合，それらの配置が問題になり，調整される場合がある．また，それも見ることができる． 

\end{itemize}
本分析の知見は，ゲームという特殊な設定の元でのものであるが，携帯端末を見ながら何かを行うということは，位置情報に限らず表示された文書，画像などに関連したものであることが示唆される．例えば「セカイカメラ」の場合，表示されたエアタグを実際に見なくても，ある程度近くにいれば，体の向きからどの方向のエアタグを見ているのか瞬時に理解できる． 

また，例えばiPhoneの場合電子コンパスや加速度センサで，表示を回転させることが可能であるが，これらは持っている人の向きのみを反映でき，他の人間の身体の志向の反映は難しい．場合によっては渡すなどのインタフェース外の相互行為を考慮した設計も必要だろう．このように，本知見を通じて既存のシステムを再検討することも有効である可能性がある． 

\subsection{これによって何がわかったのか？}
このフィールドで行われたことは、ゲームであり、位置や方向の特定という問題の解決であり、iPhoneの使用である。これらは単純に平行しているわけではなく、例えばゲームで点を取るために位置や方向を特定し、iPhoneを使用することでゲームを進めるなど相互に関係している。本分析でピックアップした断片では、iPhoneの使用を取り巻く指差しなどの身体的相互行為に主に注目した。しかし、これはiPhoneでの情報の提示が間違っているという批判にはならない。また、ゲーム全体に関わるような意思決定も主題としていない。このため、主に位置や方向の特定という問題がどのように解決されるか、ということが本分析の主要な知見だろう。これは、より外部環境のデータをセンシングして、提示するようなシステムでは身振りのあり方を考慮でき、またそれが実際に使用される場面で異なっていくということを示している。この点で、新たなシステムへの要求事項を扱っていると言える。 

一方で、この分析では本当にゲームという場面全体を記述できなかったのだろうか。宝探しという主題を元に、我々は様々な場面を想像するだろう。しかし、今回は場面で起こりうる様々な局面を厳密に洗い出し、行為のモデルを作成し、ゲームをデザインしたというわけではない。つまり、ある意味で実際に始まってみないと、ゲームで起こることは予測できないことになる。これはプレイヤーにとっても同様である。この分析で何か場面について分かったものがあったとすれば、それはまだ知られていない事柄である。 

そこでまず指摘できるのが、アヒル探しがチームの共同作業として行われたことである。これは注目に値する。例えば完全に障害物がない状況で、GPSの方角指示を元に移動を行ったとしたら、各人は同じ方向に進むため、コミュニケーションは必要ないと思われる。人が集まったら共同作業がされるとは限らない。 

そこでゲームを一種の問題解決としてとらえた場合、問題とは何かということを問うことができる。前半のキャンバス内でのアヒル探しと、後半の都電沿線での宝探しではどう問題が異なるだろうか。例えば、ゲームのルールとDGRadarを元にすれば、「方向」の問題は見えてこない。また、GPSの不具合がゲームの障害となることは容易に想像できるが、実際にゲームをどう妨げたのか、また本当に妨げたかどうかには疑問が残る。GPSの問題をお互いに共有して、方向を見定めながら移動するということは、ゲームのルールを破壊するようなことではない。むしろ、ゲーム全体の問題解決の中で、間違えながら試行錯誤していく過程の中にうまく取り込まれている。このように、「iPhoneの位置表示アプリを使った」「宝探しゲーム」の見えない特徴が本分析によって明らかになっている。 

この際、本分析はゲームの実際の達成の際の(ゲームのデザインが問題を解決するものではなく、問題をうまく作り出すことにあるという差異はあれど)問題を浮き彫りにしている。これは、ゲームの評価をしているといえ、この結果は例えば方角ではなく方向を提示してみる、GPSにわざと誤差を作っておくなどの、新たなゲームデザインにつなげることができる。 

\chapter{システムの実装と評価:セカイカンヅメ}
本章では、2010年7月に行った実験「パノラマを用いた共同作業」を取り扱う。 

\section{コンセプト}
遠隔で共同作業を行う手段には、様々なものがある。例えば音声や文字(チャット)、映像などは従来から利用されている。本実験で用いられたものは、その中でも「ものを配置する」ということにフォーカスを当て、そのために「パノラマ」すなわち360度全ての方向を写した映像を利用することを考えた。 

\subsection{モバイルによる身体的指示}
一方で、現状でロボットは比較的大きなものになるため、作業場所によっては導入できるとは限らない。このため、別のインタラクションを、似たような設計論で実現できないかということを検討した。結果として首を回すかわりにパノラマの提示を、またパノラマを見ている位置を視覚的に提示する方針を採用した。 

360度の映像は、以下のような利点から、ものの配置に有用であるように見える。 

\begin{itemize}
\item  配置を行う場所の全景を見ることができる 

\item  作業者と物体、配置場所の位置関係を把握することができる 

\item  作業者に指示を行う際に、場所のどこを指すかをわかりやすく説明できる可能性がある 

\end{itemize}
一方で、以下のような問題も起こる。 

\begin{itemize}
\item  パノラマをどう表示するか？ - パノラマは元々全ての方向を写したものであるため、ただ広げただけでは、位置関係がわかりにくい 

\item  パノラマの特定の部分を見ながら指示をしていることを、どう作業者に伝えるか？ 

\end{itemize}
このような問題を解決するために、パノラマを円筒形に表示する形式を採用した。TWISTARに代表される、没入型で360度の視野を確保するシステムでは、人が円筒の中に入り、中から何らかの形で表示された360度の映像を見るという形式をとっている。しかし、この形式では装置が大規模になってしまい、場所をとってしまうという問題がある。このため、本実験で用いた表示形式は、円筒に360度の映像が表示されているのを、外から見る形式を採用した。 

これを実現するために、拡張現実感技術を用いた。ここで用いた拡張現実感技術は、ARToolKitというマーカーを使ったシステムで、民生用として一般的に用いられているものである。ARToolKitでは、以下のようなフローで現実空間に3Dの物体を表示する。 

\begin{itemize}
\item  カメラなどで映像のフレームを読み込む 

\item  画像認識により、マーカーの位置を特定する 

\item  マーカーの位置を原点として、映像に写っている空間の3次元座標を特定する 

\item  3次元空間に3Dの物体を描画する 

\end{itemize}
この3Dの物体を円筒にし、随時パノラマ映像をテクスチャマッピングすることで、先のような表示形式を実現した。これにより、マーカーが表示された位置に、円筒形のパノラマが表示される。マーカーを見る方向を変えたり、回したりすると、パノラマの別の方向を見ることができる。この方式のもう一つの利点は、パノラマのどこを見ているかを画像処理によって特定できるということである。画面の下方向が3Dのどの方向に当たるかを見ることで、ユーザーがどこを見ているかを推定し、作業者に提示することができる。しかし、この特徴は実際には時間の関係から実装しなかった。 

\section{システムの概要}
実際に実装したシステムは、指示者側、作業者側の2つに大きく分かれ、この2つをネットワークで接続することで実現している。 

まず、作業者側では、PCにWebカメラが接続され、パノラマ映像のキャプチャと送信を行う。パノラマ映像は、通常は全方位カメラ(Omni-Directional Camera)という特殊なカメラを用いるが、今回は予算の問題から(本研究は一切大学からの予算を用いていない)、市販のWebカメラと半球ミラーから自作した。WebカメラはLogicool QCAM-200Vを用いた。半球ミラーは、新宿東急ハンズで販売されているいくつかの口径のものを試し、直径7cmのものを採用した。まず半球ミラーを机などの上に設置し、Webカメラを真上から見下ろすように、ちょうど良い高さに設定すればパノラマ映像を取得できる。 

これを、PCでOpenCVという画像処理ライブラリによってキャプチャし、送信するプログラムを作成した。転送の形式はリアルタイム処理の実現のため、無圧縮でそのままフレームを送信している。 

指示者側ではPCに一眼デジタルカメラ(ビデオキャプチャにより接続)が接続され、受け取ったパノラマ映像をARToolKitによってマッピングする処理を行う。一眼デジタルカメラは近くの机に配置され、マーカーを写す。 

\section{実験の目的}
上記のようなパノラマを用いた共同作業システムには、いくつかの根本的に不明瞭な点がある。まず、複合現実感を用いたシステムの中でさらに映像合成を行っているため、システムについての理解や、システムを通じた視点の理解がスムーズに行われるのかという問題がある。これはいわゆるユーザビリティに当たる(できれば定量評価でだめな理由)。また、本システムは簡潔で、基礎技術的な位置づけである。これを共同作業に適したシステムにするために、基礎的な技術のみを用いたインタラクションについて理解することが有用である。主にこの2つを目的とする。 

\section{実験の概要}
本実験では、ミニチュアの家具を配置するタスクを、指示者、配置者の2名の共同作業によって行った。指示者は家具の配置の写真を見ることができるほか、技術的手段によって設定によっては配置の様子を見ることができる。配置者の前には家具配置スペース(紙によって示されている)と、ばらばらに置かれた家具がある。指示者と配置者は同じ部屋にいるが、お互いを見られないように配置されており、肉声によって会話をしながら家具の配置作業を行う。 

指示者の環境設定は、目の前に表示用のPC(MacBook Pro 13inch Early 2009)があり、映像やパノラマ映像が表示される。また、写真表示用のデジタル一眼カメラ(Panasonic DMC-G1)やiPhone 3GS(パノラマ実験ではデジタル一眼カメラがシステムに利用されたためこちらを利用)があり、それぞれ基本的な操作によって写真の閲覧や拡大縮小が可能である。パノラマ実験の場合は、この他にパノラマ操作用にマーカーとマーカー認識用のデジタル一眼カメラが配置されているが、配置は途中で変更した。 

配置者の環境設定は、目の前に2つの机があり、手前と奥に配置されている。手前の机では配置するためのA4の用紙や、パノラマ実験の場合は中央にパノラマ用のカメラが配置されている。奥の机には、あらかじめミニチュアの家具がバラバラに置いてある。 

実験手順を以下に示す。 

\begin{itemize}
\item  前の配置を利用しない場合、ミニチュア家具を配置する 

\item  ミニチュア家具の配置の写真を撮影する 

\item  ミニチュア家具をバラバラに奥の机に置く 

\item  被験者に実験について説明する 

\item  実験と撮影を開始する 

\item  指示者と配置者が共同してミニチュア家具を配置する 

\item  指示者が終わりだと宣言した場合、実験、撮影を終了する 

\end{itemize}
実験は、以下の3つの技術設定で行った。 

\begin{itemize}
\item  音声のみ:指示者は配置を真上から撮影した写真のみを見ることができ、配置者の状況は会話によってしかわからない。 

\item  映像:指示者は写真の他に、配置者を斜め上から撮影した映像(カメラ1をそのまま表示したもの)を見ることができる。 

\item  パノラマ映像:指示者は写真の他に、家具配置スペースの中央から撮影したパノラマ映像を、前節で説明したパノラマ映像表示装置によって見ることができる。 

\end{itemize}
以下に、個別の実験の詳細についてまとめた。 

ただし、2,3,4,6,7,8はそれぞれ実験1,2,3,5,6,7の結果を撮影したものである。 

実験に使用した写真を以下に示す。 

実験1 

\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-1-1.eps}
\caption{写真1-1}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-1-2.eps}
\caption{写真1-2}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-1-3.eps}
\caption{写真1-3}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-2-1.eps}
\caption{写真2-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-2-2.eps}
\caption{写真2-2}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-2-3.eps}
\caption{写真2-3}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-3-1.eps}
\caption{写真3-1}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-3-2.eps}
\caption{写真3-2}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-3-3.eps}
\caption{写真3-3}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-4-1.eps}
\caption{写真4-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-4-2.eps}
\caption{写真4-2}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-4-1.eps}
\caption{写真4-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-4-3.eps}
\caption{写真4-3}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-4-4.eps}
\caption{写真4-4}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-4-5.eps}
\caption{写真4-5}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-4-6.eps}
\caption{写真4-6}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-4-7.eps}
\caption{写真4-7}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-4-8.eps}
\caption{写真4-8}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-4-9.eps}
\caption{写真4-9}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-5-1.eps}
\caption{写真5-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-5-2.eps}
\caption{写真5-2}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-5-3.eps}
\caption{写真5-3}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-6-1.eps}
\caption{写真6-1}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-7-1.eps}
\caption{写真7-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{6-8-1.eps}
\caption{写真8-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}

\subsection{結果}
分析の方針としてまず前提として挙げておきたいのが、このシステムは元々一つの部屋を領域として、本物の家具と同じ程度の物体を配置することを目的として設計されており、ミニチュアの家具を用いた実験を行ったのは、あくまでそれを擬似的に再現したものであるということである。この場合、「映像を用いた実験」のような設定を行うことは難しくなる。映像を用いた実験では、ミニチュアの家具よりかなり高い場所にカメラが配置され、全体を俯瞰できるようになっている。しかし、実際に部屋にこのようなカメラを配置することは物理的に難しく、例えば監視カメラのような配置だと死角ができるだろう。このため、もし「パノラマを用いた実験」が「映像を用いた実験」より何らかの劣った面があったとしても、それは必ずしもパノラマシステムが劣っていることを意味しない。 

また、この実験をミニチュアで行うことが、実際の部屋で家具を配置することと異なる特徴を持つ可能性がありうる。しかし、パノラマ表示インタフェースに関しては、ミニチュア家具、展示会場、都市空間で特に特性が変わらないことを確認している(以下の写真を参照)。あまりに小さすぎる場合だと焦点距離の問題で像がぼやけてしまうが、今回の実験はA4の用紙を配置場所として選択しており、パノラマの周囲4cm(カメラの接近できる限界)には物体が配置されていない。 

結果に関しては、分析が間に合わなかった。初期観察として言えるのは以下のとおりである。

パノラマ映像を積極的に利用していた被験者は2名いたが、パノラマ映像の操作の方法は違っていた。基本的に映像やパノラマ映像は指示が成功しているか確認するために利用されていたが、確認の際に、どの方向を見ているかを正確に把握する必要がある。その際に、片方は前見ていた位置から相対的に把握していたのに対し、もう片方はその都度最初の位置に戻していた。これは、ある意味キーボードで言う「ホームポジション」と言える。

\section{Mobile ARを用いた実装}
本研究では、先の実験用システムを改善したシステムを開発した。元々拡張現実感を用いたパノラマ提示は、デバイスやマーカーを自由に動かして、自由な視点を得るというコンセプトであるため、より自由度が高まった設計だと言える。技術的には、Androidスマートフォン「Nexus One」を用いて、Android用ARToolKit実装「AndAR」を採用した。秒間5フレーム程度が出ていたと考えられる。

\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{int2011.eps}
\caption{セカイカンヅメ モバイル版}
\end{center}
\end{minipage}
\end{center}
\end{figure}

これに関して、初歩的な実験を行った。2010年12月27日の13時にシステムが完成し、同日23時59分が「インタラクション」の投稿締切だったため、ウェブサービス「twitter」上で被験者を募集し、被験者5名を集めることに成功した。実験設定に関しては、前述の実験設定を一人用の遠隔指示でないものに設定し、以下のフローで実行した。なお、時間がなかったため現地(秋葉原)で全ての実験用具を調達せざるを得ず、前の実験でのミニチュア家具を調達できなかったため、大きさが同程度で色の区別が付きやすいアニメキャラクターのフィギュアを採用した。

\begin{itemize}
\item 机上にARマーカーと、配置用の紙が配置されている
\item フィギュアを紙の上にランダムに配置する
\item 紙の上から全方位撮影を行う。この際の半球ミラーの配置は決まっていない
\item 全方位映像を作成し、スマートフォンに転送する
\item フィギュアと半球ミラーを紙から撤去し、横に寄せる
\item 被験者は机の前に座り、セカイカンヅメを利用しながらフィギュアを配置する。撮影を開始する
\item 指示者が終わりだと宣言した場合、実験、撮影を終了する
\end{itemize}

2度ほど初期評価実験を行ったところ、ARマーカーの認識の問題と、方向の問題が起こったことが参加者に共有された。また、1人が他の参加者の実験に口出しをする場面が見られたが、その際に方向の問題の解決を行っているような行動が見られた。このため、本実験では2人で同じ机に並んで行う実験と、1人で行う実験の2つを撮影し、特に2人での実験に焦点を当て分析を行った。

\subsection{結果:Computer Mediated 三角測量}
撮影したビデオデータのうち、15秒の断片を以下に示す。
\begin{figure}[!h]
\centering
\small{
\begin{verbatim}
Ag:Aの視線 Ap:Aの手の動き
Bg:Bの視線 Bp:Bの手の動き
S:セカイカンヅメ F1/F2:フィギュア M:マーカー
_:動きの維持 .:動きの途中 (.):間

01A :えと扉の向こうに(.)これかな
  Ag:(S)________________(F1)_____
  Ap:          ....(扉)...(F1を触れる)..
  Bg:(S)__________________________(扉)
  Bp:(鏡)__________________________(扉)
02Ag:____(S)_________________________
  Ap:(F1移動)______(M操作)____________
  Bg:(F1)____(S)____..(F2).(S)________
  Bp:(F1指す)___(鏡)____......(F2)____
03B :    あれどこ行ったんだ(.)これこっちか
  Bg:_____________________________________
  Bp:__..(鏡近く)___________...(壁)________
  Ag:_____________________________________
  Ap:_____________________________________
\end{verbatim}}
\caption{断片1}
\end{figure}

この実験では、実世界の物体とその配置、セカイカンヅメの画面、画面内の物体とその方向などの多くの異なる特性を持つ物体の関係を把握し、またそれを共有することが効果的な配置作業の条件となる。この場面の「これこっちか」の後、物体を積極的に配置し始め、何度かの間違いを経て正確に配置した後は微調整が行われるにとどまった。また、この場面は操作を始めて全体を見た直後である。つまり、この場面でその把握と共有がなされた可能性がある。

まず言えることは、位置と方向の関係の把握に2つの物体が使われたことである。2つの物体の実世界での方向がわかれば、セカイカンヅメの提示する方向が直感的でないことに関わらず、他の物体の方向の関係もそれを元に類推できる(半球ミラーの位置を含めた三角測量)。また、実際に2つの物体を配置した時点で、実世界とセカイカンヅメの画面に対応関係が生まれたと考えられる。この場合、この対応関係の精度は実際に正確な配置がされる度に高まっていくと考えられる。

また、01行目から02行目の開始部にかけて扉とF1に双方が注目したことも、重要な点である。これにより、2人は準拠点、つまり実世界とセカイカンヅメが共通して持つ位置と方向の特徴を共有した。この作業は、前述の作業、つまり2つの物体の位置関係の把握の準備であると考えられる。このように、まず1つの物体の位置を特定し、そこから2つ目の物体との関係を把握するという順序で、実世界とセカイカンヅメの画面の位置関係の対応が行われたと考えられる。

\subsection{まとめと応用可能性}
大学のキャンパス程度の大きさから机上の実験に変わったが、前章と主な主題は変わらなかった。つまり、位置と方向の問題の解決である。

本実験を通じて、正確な位置の把握を目指す3種類の解決方法が見られた。

\begin{itemize}
\item 一つの準拠点を定めて、何度もそこに戻る方法
\item 相対的な位置を常に把握する方法
\item 2つの準拠点からの三角測量
\end{itemize}

このうち、最後のものは、前の2つと衝突せず、改めて分析を行えば前の実験でも示されていたかもしれない。最後のものを容易に発見できた理由は、作業を複数人で行っていて、視線や指差しによって相互行為を調整していたためである。一方で、対面でのリソースが使えない前の実験でのインタラクションは、両者の映像が提示されていたにもかかわらず分析が難しかった。Heathらは、映像を用いたコミュニケーションにおいて身体的リソースが欠如してしまう問題を最初に指摘した。「セカイカンヅメ」は当初から複数人での使用を予想していたものの、基本的には1人向けのシステムとして、セカイカンヅメをどう見ているかを考えずに設計した。

例えば、Agora(Kuzuoka et al. 1997)のようなシステムとセカイカンヅメを併用した場合、さらなる成果があった可能性もある。もっとも、本実験では、作業者が最終的に動ける環境にいながら、円滑に共同作業をできることを目指して、その条件を検討するものであったため、Agoraは利用することができない。より小型の機器を利用して、指差しなどを効果的に共有できる必要がある。

\chapter{結論}
\section{前章までのまとめ}
本論文では、コンピュータを利用した作業が現実世界のものに広がる可能性を探るため、実世界を志向したインタフェースについて研究を行った。

そのステップとして、実世界を志向したインタフェースについてのレビューを行った。その結果、「何が実世界か」についての明確な定義が見られないことに注目した。このため、まず曖昧な「実世界」とは何かを解明するため、特に位置を扱うようなインタフェースについて検討した。

その手法は、ワークプレイスや実際の世界の相互行為に目を向ける「エスノメソドロジー研究」特に「相互行為分析」を選択し、それが何を理解できるのかについて検討した。

さらに、この研究が実際のシステムについて何を言えるのかについて検討したが、エスノメソドロジー研究とシステム記述の「翻訳」には常に問題が存在することがわかり、根本的な解決には至らなかった。

それから実際の分析に移り、位置情報を扱うゲーム「ジオジオスタンプラリー」では、本来個人用のモバイル端末が視線や指差し、身体的配置によって複数人で使われること、また「方角」と「方向」を参加者が区別し、その変換を行っていたことを解明した。

次の「セカイカンヅメ」では著者自身が製作した、拡張現実感を用いて全方位映像を机上で提示できるシステムについて実験し、分析を行った。これは、本来我々を取り巻く視覚の全てを、一つの円筒に表示するというもので、実世界に存在はするが不自然なものであった。しかし、使用者はその対応関係を三角測量を局所的に用いることで解決し、実世界との関係を様々な戦略で維持していた。

\section{本研究が目的をどう果たしたか}
既に見たとおり、本研究では実世界での作業を遠隔で行うということの基礎にあるインタフェースの、さらに基礎にある実世界に対する知覚について検討した。これを遡り、分析の結果が実世界での作業の可能性をどう明らかにしたかについて述べる。

2つの設定の分析の結果をまとめると、インタフェースが提示する情報を、両方とも人と人がお互いを見られる範囲の空間に変換して捉え、適切な指示を行っていた。これは逆に言えば、お互いを見られる空間と、その中にあるインタフェースがあれば、その外の多様な空間を扱えることを示唆する。これは、オフィスワークの延長線上として実世界の作業を行うという本論文の趣旨から見れば、極めて好意的な結果だと言える。

Dourish(2001)は、この区別に関して興味深い知見を残している。空間spaceと、場所placeの区別である。空間は、物理的な環境に強く関わり、インタフェースのメタファーとしてもよく使われる。一方、場所は、社会的な、複数の人が集まって、相互行為が発生するような環境のことである。本論文で見てきた「変換」は、「物理的空間」から「社会的場所」への変換と捉えることもできるだろう。物理的環境の場所は動かすことはできないが、社会的環境はその場その場で局所的に生じる。そこに物理的環境へのインタフェースを用意すれば、そこから作業を始めることができる。少なくとも基礎的な部分では、オフィスワークで実世界での作業を扱うことは可能であるといえる。

\begin{thebibliography}{99}
\bibitem[Garfinkel 1967]{Garfinkel 1967} Garfinkel, H.,1967, Studies in Ethnomethodology, Prentice-Hall
\bibitem[Randall 2007]{Randall 2007} Randall, D., et al., 2007, Fieldwork for Design, Springer
\bibitem[Button 2009]{Button 2009} Button, G. and Sharrock, W., 2009, Studies of Work and the Workplace in HCI, Morgan amd Claypool
\bibitem[Schegloff 2007]{Schegloff 2007} Schegloff, E., A., 2007, Sequence Organization in Interaction: A Primer in Conversation Analysis I, Cambridge University Press
\bibitem[Suchman 2006]{Suchman 2006} Suchman, L., 2006, "Human-Machine Configuration: Plan and Situated Action 2nd Edition", Cambridge University Press
\bibitem[椎尾 2010]{椎尾 2010} 椎尾一郎, 『ヒューマンコンピュータインタラクション入門』, サイエンス社, 2010
\bibitem[歴本 1996]{歴本 1996} 暦本純一, 『実世界志向インタフェースの研究動向』, コンピュータソフトウェア, Vol.13, No.3, pp.418
\bibitem[Ishii 2008]{Ishii 2008} Ishii, H., 2008, "Tangible User Interfaces", The Human-Computer Interaction Handbook Second Edition, Laurence Eribaum Associates, pp.470-487
\bibitem[Ishii 1990]{Ishii 1990} Ishii, H., 1990, "TeamWorkStation: Towards a Seamless Shared Workspace", Proc. CSCW 90., pp.13-26.
\bibitem[Ishii 1992]{Ishii 1992} Ishii, H., et al., 1992, "ClearBoard: A Seamless Medium for Shared Drawing and Conversation with Eue Contact", Proc. CHI92, pp.525-532.
\bibitem[Ishii 1997]{Ishii 1997} Ishii, H., Ullmer, B., 1997, "Tangible Bits: Towards Seamless Interfaces between People, Bits and Atoms", Proc. CHI97, pp.234-241.
\bibitem[Apple 2010]{Apple 2010} Apple Computer Inc., "iOS Human Interface Guidelines", (Retrieved Jan 2011,  http://developer.apple.com/library/ios/documentation/UserExperience/Conceptual/\\MobileHIG/MobileHIG.pdf)
\bibitem[Wellner 1993]{Wellner 1993} Wellner, P., 1993, "Interacting with paper on the DigitalDesk", Commun. ACM 36, 7 (July), pp.8796.
\bibitem[Benford 2002]{Benford 2002} Benford, S.D., et al., 2002, "Staging and evaluating public performances as an approach to CVE research", CVE '02, pp.80-87.
\bibitem[Garfinkel and Sacks 1970]{Garfinkel and Sacks 1970} Garfinkel, H., and Sacks, H., 1970, "On Formal Structures of Practical Actions", Theoretical Sociology: Perspectives and Developments, edited by J.C. McKinney and E. Tiryakian, New York: Appleton-Century-Crofts, pp.337-366.
\bibitem[Buxton 1995]{Buxton 1995} Buxton, W., 1995, "Living in Augmented Reality: Ubiquitous Media and Reactive Environments", Finn, K., Sellen, A., and Wilber, S. (Eds.),  Video Mediated Communication. Hillsdale, N.J.: Erlbaum, pp.363-384.
\bibitem[Azuma 1997]{Azuma 1997} Azuma, R.,1997 "A Survey of Augmented Reality" Presence: Teleoperators and Virtual Environments 6, 4, pp.355-385.
\bibitem[Milgram 1994]{Milgram 1994} Milgram, P., and Kishino, F., 1994, "A Taxonomy of Mixed Reality Visual Displays", IEICE Transactions on Information Systems, Vol E77-D, No.12, pp.1321-1329.
\bibitem[Sacks et al. 1974]{Sacks et al. 1974} Sacks, H., Schegloff, E., and Jefferson, G., 1974, "A simplest systematics for the organization of turn-taking for conversation" Language 50, pp.696-735.
\bibitem[Goodwin 1981]{Goodwin 1981} Goodwin, C., 1981, Conversational Organization: Interaction Between Speakers and Hearers, New York: Academic Press.
\bibitem[Heath 1984][Heath 1984] Heath, C., 1982, "Talk and recipiency: sequential organization in speech and body movement", Atkinson, J., Heritage, J.,Structures of Social Action, Cambridge: Cambridge University Press, pp.247-265.
\bibitem[Schegloff 1968]{Schegloff 1968} Schegloff, E., 1968, "Sequencing in conversational openings", American Antholopology 70, 1075-95.
\end{thebibliography}
\end{document}

