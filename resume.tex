\documentclass[a4j,11pt,report]{jsbook}

%% package
\usepackage{plext, layout, geometry}
\usepackage[dvipdfm]{graphicx}
%%\usepackage{picins}

%% layout
\geometry{top=25mm, left=30mm,right=20mm, bottom=20mm}

%% 以下2行が章のラベルを書き換える^M
%%\renewcommand{\presectionname}{第}^M
%%\renewcommand{\postsectionname}{章}

%% command definition - begin
\setcounter{tocdepth}{2}

\makeatletter
\long\def\@makecaption#1#2{%
\vskip\abovecaptionskip
\iftdir\sbox\@tempboxa{#1\hskip1zw#2}%
%% \else\sbox\@tempboxa{#1: #2}%
\else\sbox\@tempboxa{#1: #2}%ここで変更
\fi
\ifdim \wd\@tempboxa >\hsize
\iftdir #1\hskip1zw#2\relax\par
\else #1: #2\relax\par\fi
\else
\global \@minipagefalse
\hbox to\hsize{\hfil\box\@tempboxa\hfil}%
\fi
\vskip\belowcaptionskip}
\makeatother

\makeatletter
\def\@makechapterhead#1{%
  \vspace*{2\Cvs}% 欧文は50pt
  {\parindent \z@ \raggedright \normalfont
    \huge\headfont
    \ifnum \c@secnumdepth >\m@ne
      \if@mainmatter
        \@chapapp\thechapter\@chappos
        \hskip1zw
      \fi
    \fi
    #1\par\nobreak
    \vskip 3\Cvs}}
\makeatother

\renewcommand{\emph}[1]%
{\bou{#1}}

\newcommand{\result}%
{\begin{math}\rightarrow\end{math}}

\newcommand{\note}[1]{{\footnotesize
#1}}

\newcommand{\sic}%
{{\tiny ママ}}

\newenvironment{thesis}{%
    \par \parindent=0pt \em%
    \vspace{5mm}\hspace{5mm}%
    \begin{minipage}[t]{160mm}
}{%
    \end{minipage}%
    \vspace{5mm}%
    \par%
}
\newenvironment{terms}{%
    \par \parindent=0pt%
    \vspace{5mm}\hspace{5mm}%
    \begin{minipage}[t]{160mm}
}{%
    \end{minipage}%
    \vspace{5mm}%
    \par%
}

\makeatletter
\count@\z@
\@whilenum\count@<16\do{%
   \advance\count@\@ne
   \expandafter\newinsert\csname bx@\romannumeral\count@\endcsname
   \@cons\@freelist{\csname bx@\romannumeral\count@\endcsname}}
\makeatother

%% command definition - end

\begin{document}
\setcounter{page}{2}
%\begin{titlepage}
\tableofcontents
\listoffigures

%\end{titlepage}
\newpage

\chapter{背景と目的}
本論文では、実世界の環境の提示の中でも、空間に関するものが、離れた環境でどのように用いられるかを、相互行為分析の手法を用いて分析した。この背景には、コンシューマコンピューティングの技術の進展により、新たな遠隔地での共同作業の可能性が開かれたことがある。現在、SOHOやノマドワーキングなどの、特定の組織や場所に縛られない働き方が提唱されている。一方で、このような働き方ができるような業種は、いわゆるホワイトカラーや、ソフトウェア開発など一部に限られる。これは、現在普及しているPCのインタフェースがオフィスワークを目的としたものであることに大きく起因すると考えられる。画像処理、拡張現実感技術や、「タッチ」を中心としたタンジブルなインタフェースが安価に手に入りつつあるが、これを実用的に応用する試みはまだ少ない。本論文では、この可能性を模索することを目的とする。 

\section{本論文の構成と全体の方針}
本論文では、エスノメソドロジー、相互行為分析のシステムデザインへの適用が主軸に置かれている。しかし、これ自体が主題ではなく、あくまで技術的環境の変化がこのような手法への注目や重要性を喚起している。よって、本論はまず、昨今の技術的環境の変化を概観しながら(2章)、エスノメソドロジーとシステムデザインとの関係についてのレビューを行い(3,4章)、その実際例として著者が関わったフィールドワークと実験について取り扱う(5,6章)。これらを便宜上第1部から第3部とする。

一方、本研究の状況と主題特有の困難な点について、後の議論を先取りする形ではあるが述べておく。まず結論から言えば本研究は失敗である。著者の主に行った作業は、以下の通りである。

\begin{itemize}
\item 両面液晶端末の開発と、デザインコンセプト「Jointed Reality」の考案(2章)
\item 位置情報ゲーム「ジオジオスタンプラリー」のフィールドワークと分析(5章)
\item 実験「画像と音声を用いた道案内」(撮影に失敗したため分析できず)
\item 360度全方位の視点を確保できる「セカイカンヅメ」の開発と分析
\end{itemize}

エスノメソドロジー研究によって、あるシステムを分析して知見を得る際には、以下の全ての条件が整っている必要があると考えられる。

\begin{enumerate}
\item 分析の可能性を判断できる最低限の方法論的知識
\item システムの新規性を評価できる概念史的知識
\item システム
\item データ収集のためのビデオ、音声などの機材
\item システムを実際に導入できる環境とユーザー
\end{enumerate}

1に関しては、システム開発者/工学者としての成否と、エスノメソドロジー研究者の関心をもつ事柄が異なるために必要となる。システムの使用の明らかな失敗、例えばタスクを実行できなかったりしたとしても、それに至る相互行為の組織には興味を引く部分があるかもしれない(一例として、システムへのエスノメソドロジーを最初に適用したSuchmanは、コピー機の使用の「失敗」を題材に状況的行為の概念を明らかにした(Suchman 2006))。2に関しては、本研究では、ある程度日常に浸透したテクノロジーを扱う場合がある。この際、システムが研究の先端からある程度外れた場合、「工学的」研究としては成立しない場合がある。3に関しては、自作する場合著者自身の開発能力とリソースに依存する。4に関しては、ある程度の機材があれば問題はないかもしれない。5に関しては、通常は実験が行われることが多いが、イベントなどのより日常に近い状況を分析できる機会もありうる。

次に、なぜエスノメソドロジーによるシステムの分析の研究がうまくいくのかについて述べる。基本的に、工学者との共同研究を行えば多くのリスクは回避される。まず、システムとその新規性が担保される。また、4章でこれに関する問題も取り上げるが、工学者とエスノメソドロジー研究者の共同開発の場合、お互いの情報交換によって、エスノメソドロジー研究者の持つ知識の範疇で評価できるようにシステムを設定できる可能性がある。最後に、プロジェクト自体がの規模が大きくなるため、実験環境の整備と被験者のリクルートを行いやすい。

一方、本研究では著者がシステムコンセプトの着想と開発を行うか、著者が関わった民間団体の開催したイベントのフィールドワークを行った。この段階で、以上のあらゆる条件の成立が難しくなる。具体的には

\begin{itemize}
\item 両面液晶端末:2章3節、4節を見ればわかるように、このコンセプトの新規性は担保される。実際、CHI2009において類似のシステムが提唱されている。「セカイカンヅメ」の次期インタフェースとして考慮している。しかし、当時の著者の実世界志向のイメージは五感を提示するものであったため、このコンセプト自体が棄却された。
\item ジオジオスタンプラリー:システムは新しいものではない。機材は足りなかった。「道案内」の考案の過程である程度分析の可能性は見つけられたが、手持ちのビデオデータでは例証が難しかった。
\item 実験「画像と音声を用いた道案内」(撮影に失敗したため分析できず):自明。
\item 「セカイカンヅメ」:新規性がある程度担保されており(情報処理学会「インタラクティブ発表」preprint)、システムも何とか実験をできるようにはなっていた。機材もあり、実験も行えたが、分析の方法がまったく思いつかなかった。
\end{itemize}

本論文の2,3,4章は単なる文献のレビューではなく、後の章での私の研究が失敗であると判断できる要素を過不足なく含んでいる。異分野の研究者でも比較的わかりやすくするよう配慮したため、多少難しい部分はあるが全ての章を読んで欲しい。

\section{公開された場合の不特定の読者に向けて}
本論文の執筆過程は全てgithubによって公開されており、著作権の都合上最終稿の直前まで公開される予定である。本論文の利用に関して、著者は一切の権利を行使しない。本論文の2,3,4章は、ヒューマンコンピュータインタラクションや拡張現実感、ユーザビリティの実務者にとって有用である可能性があるが、他の部分に関しては一切読む必要はないと思われる。

\chapter{技術的概観}
本論文では、コンピュータとのインタフェースの中でも、実際の空間で手で触ることができるようなものや、実際の空間から何らかの形で情報を得るようなものを取り扱う。実際の空間を指向したような技術は、情報分野では複数の研究分野から生まれ、互いに影響しあって形成されている。このため、似たように見える技術コンセプトでも、実世界での作業を支援する側面、あるいはテーブルトップでの作業を拡張したもの、空間の境界自体をインタフェースにしたものなど、多くのバリエーションや、また先端の分野で忘れられた概念なども存在する。このため、まず実空間を志向した様々な分野のレビューを行い、概念史をまとめる。 

\section{実世界以前}
本論文では、バーチャルリアリティや実世界を志向したインタフェースに関連する分野について取り扱う。その中で重要なのが「実世界」とは何かということである。例えば実世界を、見て触ることのできる世界と定義できるだろう。しかし、現存するパーソナルコンピュータなどは明らかに見て触ることができるものの、実世界を志向したものとして扱われることはほとんどない。この問題を明確にし、バーチャルリアリティや実世界志向インタフェースが何を実現するのかについて検討するため、まずは現在のパーソナルコンピュータや、実世界を指向する以前の試みについて少しまとめる。 

\subsection{GUI}
パーソナルコンピュータのユーザインタフェースの類型として現在典型的なものが、GUI(Graphical User Interface)である。例えば、本論文の執筆環境は、LinuxのCompizというオーソドックスなGUIに、論文本体の編集画面、文献をまとめたファイルブラウザ、文献を表示するドキュメントビューワーの3つのウインドウからなる。これらをタッチパッドのクリックによって切り替えることができ、タッチパッドの右端を上下になぞると文献のページをめくることができる。 

GUIによるコンピュータの操作を可能にする概念は、椎尾によって以下のようにまとめられている。 

\begin{itemize}
\item  直接操作:コンピュータ画面に表示した物体を、ユーザが指示装置で動かすことで、コンピュータを操作する手法。ユーザは物理的な物体を操作している錯覚を覚え、わかりやすいインタフェースを実現できる。また、状態を直感的に見て操作できるため、コンピュータの動作を把握、支配している感覚を得られる。物を操作する能力は幼児期に獲得するものであるため、緊張感や負担が少なく、知的作業の妨げになりにくい。 

\item  メタファー:GUIでは、コンピュータ画面を事務机の上(デスクトップ)に喩えた、デスクトップメタファー(desktop metaphor)が採用されて(椎尾 2010, p.108)いる。つまり、書類、フォルダ、アプリケーションなどが実際の机を模してアイコンとして表示されている。メタファーはコンピュータの機能の理解と学習を容易にし、現実世界の知識を利用できる。ただし、現実とかけはなれた挙動をする場合はこの限りではない。 

\item  WYSIWIG:What you see is what you getの略。最終的に出力される文書や図版と、見かけ上全く同じものをディスプレイに表示し、操作することができる。 

\item  やりなおし:GUIでは操作の手がかりが多く表示されているため、ユーザーは試行錯誤によって操作を習得する。このためにはやり直しができる機構が必要である。 

\item  モード:コンピュータシステムの状態によって、ユーザーが行う操作の意味が変わったり、実行できる操作に制限がかかるインタフェース(椎尾 2010, p.111)を、モーダルなインタフェース、そうでないものをモードレスなインタフェースと言う。モードはユーザーの作業の妨げになるため、モードレスが推奨されるが、作業を中断してでも通知、確認する重大な場面ではモードが使われる。 

\item  GUI設計のガイドライン:複数のアプリケーションで統一した操作を提供すれば、ユーザが操作方法を学習する負担を削減できる。そのために設計のガイドラインと、共通して使える部品を開発者に提供する必要がある。 

\end{itemize}
以上 (椎尾 2010: 107-115)より著者が作成 

この2つの重要性は開発者にも同様に認知されている。最初に普及したGUIを搭載したコンピュータであるAppleのMacintoshでは、「Macintosh Human Interface Guidelines」という書籍を開発者向けに出版している。その中の「ヒューマンインタフェースの基礎」という章では、メタファー、直接操作、WYSIWIG、一貫した操作、モードなどについて取り上げている。これは、以上の概念が単なる設計思想に留まらないことを示している。 

この2つは、一見して身体的な「タッチ」という操作を実現しているAppleの「iPhone」にも一貫して重要視されている。iPhoneのアプリケーションを開発者が提供する際にはAppleの審査を受ける必要があるが、その中で最も重要な審査基準である「iOS Human Interface Guidelines」では、タッチ機能は直接操作やメタファーをさらに補強するものと位置づけている。 

\begin{figure}[!h]
\begin{verbatim}
   iOSのユーザーはマルチタッチのため、直接操作の強い感覚を楽しむことができる。ジェスチャーの利用は、画面上の見ている物体に大きな親近感と、それを制御している感覚を与える。(Apple 2010: 20)
   人々は現実的な画面上の物体と物理的にインタラクションを行い、多くの場合現実世界の物体に対するかのように操作できる。(Apple 2010, p.21)
\end{verbatim}
\caption{iOSの開発ガイドラインに見るGUIの要素}
\end{figure}
iPhoneでは触るという操作は、あくまで画面上のメタファーに対して行われる。これは明らかにGUIの延長線上にある製品である。 

\section{CSCW}
一方で、実世界を重視するという流れには、CSCW(コンピュータ支援共同作業)分野の一連の研究が深く関わっている。CSCWは、一言で言えば、実際のオフィスワークを念頭において、それをコンピュータによって支援する研究を総称する。その中には、例えばスケジュール管理に代表される「グループウェア」も当然重要な位置を占めるが、実際のオフィスについての分析を行う、もしくは実際のオフィスに適合するようなインタフェースの研究は、前節の実世界志向インタフェースにも接続されている。 

(WIP) 

\section{机の拡張}
CSCWの中でも、机上の共同作業を支援する試み、特に紙の文書とデジタル文書をシームレスに扱うようなモデルは、複数の研究者によって提唱されており、後の実世界を志向したインタフェースや、映像を用いたコミュニケーションへの礎となっていった。本章でのレビューはこれを出発点とする。 

\subsection{TeamWorkStation}
石井らによるTeamWorkStation(TWS)は、デスクトップ画面をビデオ制御することで作業領域の共有を可能にするシステムである(Ishii 1991)。これは単純な概念であるが、拡張現実感に至る出発点であった。TWSのキー概念は以下のようになる。 

\begin{itemize}
\item  ホワイトボードのような「共有描画表面」があり、全員が見て差し、描くことができる 

\item  共有作業領域と個人作業領域の間をシームレスに移行できる 

\end{itemize}
これらを実現するために、「個人作業領域をオーバーレイする」ようにTWSは設計されている。つまり、例えばAの画面にBの画面が表示され、Bの画面をAがマウスポインタで指すことで、それがフィードバックされAの画面にも現れるような設計になっている。この他にも様々なオーバーレイの形式が提示されている。それだけではなく。基本的にビデオ媒体を利用しているため、ビデオカメラ映像のオーバーレイも可能である。これにより、実際の机や顔なども共有することができ、デスクトップに留まらない「作業領域」の共有が可能になる。 

\subsection{DigitalDesk}
紙の文書とデジタル文書における作業の統合を目指したのがWellnerによる、「DigitalDesk」(Wellner 1993)である。Wellnerは、紙とデジタルの文書が分離されている状況を「dual desk」として描写している。紙文書とデジタル文書は別の機能を持ち、媒体の違いから相互に変換することも難しい。この両者をうまく統合させる方法が「Computer Augmented Environments」だとWellnerは提唱する。 

Computer Augmented Environmentはバーチャルリアリティ(VR)に着想を得ているが、逆のアプローチを取っている。VRはコンピュータの作り出した世界に仮想的な物体を配置することができ、それは日常生活を支援するのに有用であるが、実際の世界から遮断されてしまう。これに対してComputer Augmented Environmentは実世界の物体をコンピュータによって拡張することを目指す。これによって物理的環境の慣れ親しんだ特徴を失わずに、コンピュータの支援を受けることができる。この考えはユビキタスコンピューティングと拡張現実感ともつながっている。 

DigitalDeskでは、実際の机の上にプロジェクターによりコンピュータ画面を投影し、またカメラで机の画面を撮影することで、実際の机上の紙をコンピュータで処理することを可能にしている。これによって、メタファーではなく実際のペンや指での操作が可能になる。また、紙の上にコンピュータの画像をオーバーラップさせたり、紙文書を認識してスキャンすることもできる。DigitalDeskのインタラクションは、指を用いた現実、仮想の物体との「tactile interaction」を目指す。つまり、紙とデジタルデータの両方に同じ方法で接することができる。 

\subsection{ClearBoard}
石井らによる「ClearBoard」(Ishii 1992)は、以上のような「ホワイトボード的」な共同作業支援システムが、視線やジェスチャーの問題を持っていることから考案されたシステムである。TeamWorkStationの実験から、対面会話から共有描画活動にスムーズに移行することが重要であるという結果が出た。 

対面の会議では「隣接した空間」、つまりホワイトボードと人の間に物理的な継ぎ目がないものとして部屋が知覚され、目や頭を動かすだけで参加者とホワイトボードを見渡せる。しかし、TWSでは分かれて扱われ、仮想的な会議空間が分離してしまった。この問題に対処するため、シームレスな共有作業空間と、アイコンタクトに焦点を当てた2人用の遠隔リアルタイムコラボレーションシステムが、ClearBoardである。 

ClearBoardではシームレスでアイコンタクトのある空間を実現するために、「ホワイトボードの前にいて」「テーブルの向こうにいる」、そして「通り抜けて話し、描けるような透明なガラスのウインドウ」の3つのメタファーが用いられる。この3つにより、まず仲間の顔を見ることができ、次にあまり目を動かすことなく、仲間の顔と描画の間で視線を動かすことができる。 

\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/digitaldesk.eps}
\caption{DigitalDeskの概念図(Wellner 1993)より}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/clearboard.eps}
\caption{ClearBoardの概念図(Ishii 1992)より}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\section{実世界志向インタラクション}
CSCWにおける、机などのオフィスの実際の物体に即したインタフェースの試み、もしくはオフィスワーク以外の現実世界での活動の支援の試みは、現実世界に十分適合したインタフェースの研究へと継承されることになった。このテーマはそれ自体が独立したものであり、実際に現在研究されている実世界を指向したインタフェースが、必ずしも共同作業の支援という問題意識につながっているわけではない。本節では、実世界を指向したインタフェースの初期の概念について整理し、現状についてまとめる。 

\subsection{Augmented Reality/Mixed Reality}
実世界を指向したインタフェースの一つの方向性が、拡張現実感(Mixed Reality)、拡張現実感(Augmented Reality)と呼ばれるものである。この2つの概念は互いに重複することも多いため、本節では同じものとして取り扱う。これは、単純に要約すれば現実世界の物体や空間と、コンピュータが作り出した知覚を重ね合わせるという概念であるが、2つのまったく異なる起源を持つ。 

その一つが、前節で触れた「Computer Augmeneted Environments」(Wellner 1993)やClearBoardをはじめとするテーブルトップ環境である。既に見てきたように、共有作業空間と、実際の人間の視線や指差しなどのを両立させる試みは、仮想的なデータ表示と実際の映像を重ねるデザインに至った。 

こちらの拡張現実感のイメージは、ユビキタスコンピューティングに近い。Buxtonは、ユビキタスメディアは拡張現実感であるとする(Buxton 1995)。 

もう一つが、バーチャルリアリティ研究から派生した、シースルー型HMDなどの利用の研究である。 

(WIP) 

\subsection{実世界志向インタフェース}
前の節で見たように、基本的にコンピュータや携帯電話のインタフェースはGUIの延長線上にある。しかし、GUIの問題点やコンピュータを取り巻く環境の変化を元に、新たなインタフェースが幾つか生み出されている。それらはGUIのような一つの概念ではないが、相互に影響しながら研究が行われてきた。 

実世界志向インタフェース (歴本 1996) は、その中でも「実世界での人間の作業を支援しようという研究の流れ(歴本 1996: 2)」という広い範囲を取り扱う概念である。暦本は、実世界志向インタフェースの特徴を以下のように要約している。 

\begin{itemize}
\item  インタフェースの透明化:利用者のタスクは実世界のもので、実世界に注意を向けているため、システムに注意を集中させることはできない。このため、メタファーのように「見せる」方向ではなく「透明にする」方向が問題となる。究極的には人間がコンピュータを認識しなくなる。 

\item  実世界状況の認識:実世界のタスクを支援するためには、利用者が実世界で置かれている状況や意図をコンピュータが認識する必要がある。このため、コンピュータには状況を認識して積極的に情報を提供するような能動性が求められる。 

\item  人間の能力の強化:実世界志向インタフェースの目標は、人間の代わりではなく人間の能力そのものを擬似的に増強することが一つである。 

\item  実世界情報とコンピュータ情報の関係:現実世界の情報とコンピュータの情報をいかに連携させるかが重要なテーマである。これにはいくつかの種類がある(図)。(a)(左上)従来型インタフェース。コンピュータと対面する。実世界のインタラクションとの間にギャップがある。(b)(右上)仮想現実感。完全にコンピュータの作り出す世界に限定され、現実世界とのインタラクションはなくなる。(c)遍在型コンピュータによる実世界志向インタフェース。コンピュータを遍在させることで実世界と仮想世界を一体にする。(d)携帯型コンピュータによる実世界志向インタフェース。cは現実を、dは人間を強化するアプローチといえる。 

\end{itemize}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/interactionstyle.eps}
\caption{インタラクションスタイルの比較、(歴本 1996)より著者が作成}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\subsection{タンジブルインタフェース}
MIT Media Lab. の石井が提唱した「タンジブルユーザーインタフェース」(TUI)も、GUIの代わりとして実世界を志向したインタフェースの一つである。 

TUIは、97年に4つの学問領域の影響を受けて、建築空間に関するものとして提示された(Ishii 1997)。1つめがWeiserの提唱するユビキタスコンピューティングである。これについては詳しくは取り扱わないが、コンピュータが「透明」になり、遍在化することを予測している。この結果、物や建築の表面にコンピュータが埋め込まれる。次が、先に取り上げたAugmented Realityで、物を直接つかみ操作するという焦点を導入した。次がCSCWである。机上の遠隔仮想空間の提示(ClearBoard)は、表面を仮想空間と現実空間の間で、情報が自由に行き来するアクティブ・インタフェースにするという着想を与えた。最後がGrapsable User Interfaceである。これも情報を直接手でつかむという着想を与えた。 

以上のような領域に受けて、「Tangible Bits」という一連の研究のコンセプトが提示された。 

\begin{itemize}
\item  インタラクティブな表面:建築世界の表面を物理世界とディジタル世界のインタフェースとする 

\item  ビットとアトムとの結合:手で操作できる物理オブジェクトとディジタル情報をリンクできる 

\item  アンビエント・メディア:建築空間内の音や空気などを、サイバースペースとのバックグラウンドインタフェースとして利用する 

\end{itemize}
(Ishii 1997)より著者が作成 

以上により、ディジタル情報を認知の焦点でビットを直接つかんで操作でき、また認知の周縁で情報の気配にアウェアでいられるようにすることを目指す。つまり、GUIでコンピュータに焦点を当てていたものをより現実世界とスムーズにすることを目指している。 

近年の研究では、その概念はさらに具体的になっている。TUIは、人の物理的環境を感知して操作する能力を活用するため、デジタル情報を物理的空間で物理的に身体化された形で扱うものである(Ishii 2008: 470)。GUIはディスプレイ上のピクセルとして情報を表すが、それとのインタラクションは我々が生活する物理的環境と不整合であり、物理的な物体を扱う能力を十分に発揮できない。TUIはデジタル情報に物理的な形を与えることを基礎とし、デジタル情報を手で「直接操作」することを可能にする。しかし、TUIは特定の目的のために特定の物理的形状を与えるもので、GUIのようにあらゆる目的にかなうものではない。 

TUIの基本的なモデルには、GUIと共通する部分と異なる部分がある。TUIは、GUIと同じようにMVC(Model-View-Controller)という設計モデルを採用している。これは、データの取扱いを決める「モデル」、情報の提示を管理する「ビュー」、プログラム全体の制御をする「コントローラー」の3つにプログラムの部品を分ける手法で、近年のWebアプリケーションなどにも採用されている。TUIでは、コントローラーはタンジブルなものを扱うものと、そうでないものに分かれる。また、モデルは「デジタル情報」として一般化される。 

TUIはGUIと同じく、デジタル情報の直接操作を行うが、タンジブルな表象を提示する。タンジブルな表象は物理的世界との架け橋となるとともに、デジタル情報と計算モデルの制御を可能にするように計算論的に結合されている。つまり、手などによる物理的な操作による位置などのパラメータが、制御に利用されている。一方で、TUIには物理的な制約があるため、映像投影や音声などの「インタンジブルな」インタフェースも補完的に使われる。 

TUIの基本的な特徴には以下のようなものがある。 

\section{補論:消えるコンピュータと人間の拡張}
以上の「ポストGUI/実世界志向」アプローチに共通する点は、「コンピュータを見えないものにし」「人間の能力を拡張する」ことである。この2つの主張は一見して独立したものに見える。しかし、これらはある意味で共通した面を持ち、その共通点を見ることこそが実世界志向インタフェースの別の側面を明らかにする。 

例えばARToolKitについて、 

\begin{itemize}
\item  カメラで認識した映像フレームの中の特徴点を元に3次元位置の推定を行い、それを基準として3Dモデルとカメラの映像を重ねてディスプレイに表示する 

\item  現実世界に置かれたマーカーの上に、3Dモデルが配置されることで、あたかも仮想的な物体がそこにあるかのように見える 

\end{itemize}
以上のような2種類の記述を行うことができる。前者は画像処理の結果をディスプレイに表示している点で、GUIに属するものと見られる。一方、後者は実世界に仮想的な物体を提示するARシステムである。しかし、この2つは全く同じシステムである。また、この2つは「実世界で使われているから」あるいは「使い方が異なる」という理由で異なっているのではない。使われる状況や使い方に依存しない記述である。 

システム自体ではなく、この記述からARToolKitが実世界を志向している、つまり「コンピュータを見えないものにし」「人間の能力を拡張する」ことを示す。まず、「カメラ」「ウインドウ」は後者では消えているため、コンピュータは確かになくなっている。また、前者ではただ表示しているだけだが、後者では仮想的な物体を見ることができるようになっているため、例えば有用な物体を表示することを考えれば人間の能力は拡張されていると言える。 

以上のように、コンピュータによる人間の能力の増強を考える際には、達成されたものがコンピュータの能力に属するか、もしくは人間かという帰属の問題が起こる。これに関しては、人間とコンピュータの境界の問題としてSuchmanが論じている(Suchman 2006)。 

\section{現況}
よく知られている製品の例が、ARToolKitとセカイカメラである。ARToolKitは、「マーカー」という、コンピュータが認識しやすい模様を用い、それが映像の中で認識された場合、その場所を基準として3Dの物体を表示するものである。セカイカメラは、iPhoneのアプリケーションで、主にGPSや加速度センサーなどの情報を元に、カメラ映像の上に文字などが書き込まれた吹き出しを表示させ、あたかも吹き出しが実世界にあるかのように見せるものである。 

コンシューマ領域での実世界志向技術の現況は、どのような技術がコモディティになっているかによってある程度知ることができるだろう。 

\subsection{補論:Jointed Reality}
2009年5月、著者は「実際に何か実世界に関連したもの」を製作し、それを評価することで研究を進めることを計画していた。その際、「モバイルデバイスで空間を取り扱う」ことをコンセプトに、「Jointed Reality」(これはネーミングが先行している。「コンピュータビジョン・拡張現実感に関する普通じゃない勉強会」というセミフォーマルな発表会において、発表内容に「VR」「AR」に変わる「*R」を表す名称を付けるという条件が課された。その際国鉄になぞらえた名称である)というコンセプトを発表した。それが、タンジブルインタフェースの「表面にインタフェースが埋め込まれる」という当初のコンセプトに関連していると思われるので、ここで取り上げる。 

「Jointed Reality」は、元々表と裏に液晶を持つモバイル端末の使用法について検討している中から生まれた。当初検討していた2つの液晶を持つ利点は、モードを直観的に切り替えられることである。つまり、表と裏に関連した別の機能を割り当て、それを回転させて切り替えることで直観的で豊富な機能を扱えるというコンセプトである。また、巻物のメタファを導入し、回転させると次のページが現れるようなインタフェースも試作した。しかし、これらは現状のGUIに対して大きな利点とならないと推測された。 

次に著者が検討したのが、モバイル端末の空間性の利用である。モバイル端末には、当然幅、高さ、奥行きが存在する。ある意味で、それは常に一定の空間を占有していると言える。この空間とバーチャル3D空間をマッピングし、何らかの形で操作を与えることで、平面ではなく空間を扱えるようなインタフェースが可能になると考えられる。 

具体的なインタラクションの形式は、基本的に「タッチ」操作の応用となる。試作した両面液晶端末は、表と裏にMID(Mobile Internet Device)を貼り付け相互に通信を行い、表裏判別用にWiiリモコンが横に貼り付いているという構造である。当時はMIDに本格的な3D機能がなかったため、拡大縮小回転による擬似3D機能を用いて、インタラクションのデモを作成した。その中には、両面の液晶をつまんで物体を移動できる「つまむ」機能、両面の液晶で別の方向に指を動かすことで物体を回転させる「まわす」機能などが含まれる。このように、2つのタッチ液晶を「Joint」させることで、その中に3D空間を発生させるというコンセプトが「Jointed Reality」である。 

これは、元々2D+GUIのシステムをTUIとして再提示した例と言える。【もう少し前の部分をまとめてから書く】 

\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/jointedreality.eps}
\caption{2台のMIDによる「つまむ」インタラクション}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\section{まとめ}
以上のように、実世界を志向したインタラクションという技術的な挑戦は、その初期においては人間同士の共同作業という、比較的純粋な技術から離れた分野と密接な関わりを持っていた。その接点には、人間同士の机上、オフィス空間などでのインタラクションを、可能な限り円滑な形でシステムに取り入れようというモチベーションがある。「実世界」というものを志向する意義は、人間がそこにいてこそのものであるといえる。 

一方で、幾つかの本質的な疑問が残る。例えば、共同作業システムの完成形として、人間同士のインタラクションで必要な要素のみを提示できる、という状況を考えれば、共同作業の支援に「世界」を提示するというのは冗長である。また、幾つかの研究では「視線や身体的動きなどが行われる空間」を「実世界」と呼んでいる。一方、先に見た例では、人間とシステムの境界そのものが曖昧である。それに応じて「視線や身体的動きなどが行われる空間」も変わってくるはずである。このように、「実世界」という言葉の定義は不明瞭である。既にそのような「実世界」を志向したシステムがコンシューマー領域に入りつつある。 

以上から、本論文で扱うテーマをある程度確定することができる。つまり、「実世界を志向したインタフェースは、実世界をどのように扱うのか」である。これに対して、工学的な観点のみから問題をとらえることは難しい。接近する手段があるとすれば、 

\begin{itemize}
\item  人間がインタラクションの中でどう「実世界」を形成するのか 

\item  実世界を志向したインタフェースの導入で、どう「実世界」が変わるのか 

\end{itemize}
を通じてである。本研究では、この2つに焦点を当てる。 

\section{研究対象技術:位置提示インタフェース}
本研究では、以上の問題に迫るため、実世界を指向したインタフェースの中でも、位置を提示するものに焦点を当てる。物理的な位置は、実世界を指向したインタフェースの多くが備えている要素であるが、ここでは位置を提示することが目的であるようなインタフェースを指す。 

\chapter{分析の方法論と方針}
前章では、テーブルトップ型の共有システムに人の視線や身体的配置、行為の問題が発生し、それがCSCW研究者の実世界への関心を呼び起こしたことについて論じた。実世界を指向したインタフェースは、単に現実世界を模倣したり、改変するだけでなく、複数人が共同作業をする基盤となりうる。 

一方で、実世界を指向したインタフェースは多様化し、必ずしも作業、ひいては身体の問題を指向しなくなった。むしろ、人間にさらなる別の世界をみせるような、新奇なデバイスやインタフェースの開発が推奨されている。例えば、このようなインタフェースを組み合わせて、もしくはそこから継承して新たな共同作業システムを作るとすると、その複雑さからどのような「実世界」を作り出すのか、また何を支援するようなシステムなのかが不明瞭になる可能性がある。 

ここでCSCWの別の文脈を検討する。共同作業支援システムが実世界を指向していることは、人間同士のインタラクションの研究者にとっても関心を引くテーマであった。日常会話において視線や指差しなどに注目していた研究者は、実際の作業の場面で、どのように特有の仕事を達成するかということにも、視線や指差し、付近の人工物が関わっていることを見出した。また、上記のような「実世界を指向した」システムが、実際に身体的な行為にどう影響を与えるか、ということに関しても、様々な発見をしている。 

システムの研究者と、共同作業や身体的相互行為の研究者にある程度共通の方向性があったことを推測することはたやすい。しかし、実際に共同で研究が行われたことは、比較的少なかった。相互行為の分析が、どこまで現在の状況に適用しうるかは未知数である。そこで、本章では相互行為分析とその基盤となるエスノメソドロジーの概念について、少なくとも著者の理解を示す。また、相互行為分析のCSCWへの応用と、CSCWの分野で用いられている別のエスノメソドロジー的手法についても概観する。 

以降の議論では、主に分析の方法について取り扱うが、社会学の分析手法と、システムデザインの目的、手法、アウトプットなどを混在して扱うことになるため、それらが錯綜してしまいがちである。つまり、 

\begin{itemize}
\item  エスノメソドロジーは何に焦点を置き、どうやってそれを分析し、それによって何を得るのか 

\item  システムのコンセプトはどう決定され、どう作って、どうちゃんと作られているかを評価するのか 

\end{itemize}
という2種類の異なる立場から、少なくとも分析を行う立場において以下のようなことを決定しなければならない。 

\begin{itemize}
\item  システムのデザインという目的設定の元で、エスノメソドロジーをどう行い、何を得るのか 

\end{itemize}
本章ではこの3点について、それぞれを検討することによって、エスノメソドロジーによるシステムが関わる状況の分析について明らかにする。なお、ここでは主に分析を行う側にのみ焦点を当てるが、分析側とデザイン側が共同で作業を行うことの問題については次章で検討する。 

\section{概要}
エスノメソドロジーは、単に日常生活を研究するのではなく、それが既に秩序だっているような手続きを研究する分野である。これを実際に記述する手法が会話分析や相互行為分析で、これらは相互行為のシークエンス的な組織化を詳細に明らかにする。これは、その場面である作業を達成するために、どのようにその場その場で成立する秩序を成員が理解し、次の相互行為につなげているかということがわかる。 

\section{エスノメソドロジー}
エスノメソドロジーは、創始者のHarold Garfinkelによって以下のように特徴づけられている。「私が「エスノメソドロジー」という言葉を使う際は、日常生活の組織立った巧妙な実践の、偶発的で継続的な達成としての、文脈指標的表現やその他の実践的行為の規範的特徴の研究を指す」(Garfinkel 1967: 11)。つまり、我々が何かの枠組みをもって行為を説明する以前に、人々の実践的行為はすでに秩序立っている。この秩序を解明することが、エスノメソドロジーの最も基本となる考え方である。とはいえ、エスノメソドロジーは、単に人々の日常を明らかにする、ということではない。この点を、(Garfinkel, 1967)(Garfinkel and Sacks, 1970)からまとめて説明する。

その問題の一つが、文脈指標的表現である\footnote{エスノメソドロジーは元々社会秩序の問題への取り組み、特にラザーズフェルド、パーソンズなどの「構築的分析」を行う社会学への反論として生まれた。だから、当然この議論は文脈指標的表現でなく、社会秩序から始めるべきであるが、本論文では簡潔な説明のため文脈指標的表現から始めている}。文脈指標的表現とは、ある文脈の中でしか解釈できない表現のことで、素人も専門家(社会学者)も広く利用している。しかし、この文脈指標的表現を取り扱い、日常の秩序を明らかにすることは不可能である。文脈指標的表現を客観的表現に置き換えることが不可能であるためである。ある文脈指標的表現を客観的表現にしたとしても、それに対するさらなる解釈を与えることが可能であり、また本当に客観的であるならそれが必要になる。とすると、完全に客観的な表現を与えるのは不可能である。

一方で、普段生活を行う上では、この作業を行っていながら、なおかつこの問題を我々はうまく乗り越えている。この2つは明らかである。まず、人々が日常言語を話しているように聞こえることから、明らかに「メンバー」つまり、自然言語に精通「していること」(ここでメンバーは特定の個人、あるいは集団を意味する用語ではない)が観察される。自然言語に精通しているということは、そこで起こっていることを「説明」(見て言うこと)でき、またメンバーならその説明を「理解」できることを帰結する。この「説明」は客観的表現である。また、これを「理解」しているということは、客観的表現が完全でないことがメンバーにとっては問題でないということである。これは、説明が文脈に適合したものであるためである。そのうまくいっていることを解明することが、日常の秩序を理解することにつながる。この種の説明を、エスノメソドロジストでない社会学者が行うような客観的表現への変換=社会学的推論になぞらえ、実践的社会学的推論と呼ぶ。

では、説明がうまくいっていることをどう研究すればいいのだろうか。説明を何らかの形で切り出して、それを客観的に述べることは、先に述べた通り不可能である。エスノメソドロジーは、説明がありふれていることに焦点を当てる。我々は日常のあらゆる異なる場面で説明を行うが、それができるのはそれぞれの説明の方法、説明を可能にしている方法が確立しているということで、そこには方法論の研究の余地がある。この方法論は、実際の相互行為にみる説明の方法を、何の解釈も与えず形式的に示すことでのみ立証することができる。だから、エスノメソドロジーは人々の相互行為の形式的な側面に焦点を当てる。

では、説明の方法論の研究が、何を明らかにできるのだろうか。それには、実践的社会学的推論の、「相互反映的」な特徴が関わっている。相互反映的であるとは、説明をすること自体が場面、つまりその場の社会的な秩序の組織を形作っているということである。つまり、説明は場面の一部となる。これにより、説明の方法論を解明することが、場面の成り立ちを理解することにつながる。

このようにして、エスノメソドロジー研究=自然言語に精通した「人々」の、説明の「方法」に関する「研究」は、その場の社会秩序の解明という社会学の問題に寄与する。

\section{会話分析}
この議論では、具体的にどう明らかにするのか、というところまでは踏み込んでいない。エスノメソドロジーを具体的にどうやっていくのかということに関しては、当時エスノメソドロジーが大きな影響を与え、またその代表的な研究手法となった会話分析について触れる。会話分析は、主にSacks, Schegloff, Jeffersonらによって開始された、会話の組織化に関する広範な研究である。会話分析の対象は近年 (Schegloff 2007: xiv)によって以下のように特徴づけられている。 

\begin{itemize}
\item  順番交代 (turn-taking) 問題:会話において誰が次に話すのか?またそれはいつ行われるのか? 

\item  行為形成 (action-formation) 問題:どのように、言語、身体や、相互行為の環境、相互行為内の位置などのリソースが、設計された通りの構造に、また受け手に、その規模もわからないのに特定の行為 (例えば、依頼、招待、許可、不平、同意、知らせ、警告、拒絶など) として認識されるように形成されるのか? 

\item  シークエンス組織 (sequence-organazational) 問題:どのように、次の順番が前の順番と「筋の通った」ものとして形成されるのか?また、そもそも「筋が通った」の本質とは何か? 

\item  トラブル (trouble) 問題:どのように話し、聞いたり、会話や相互行為を理解する際のトラブルが、それが起こった際に止まらず、間主観性が維持、修復され、順番やシークエンス、活動が可能な完了へと進むように扱われるのか? 

\item  言葉の選択 (word-selection) 問題:どのように順番の単位となる構成要素が選択されるのか?また、どのようにその選択が、受け手が理解を達成できるように知らせ、形成されるのか? 

\item  全体構造の組織化 (overall structural organization) 問題:相互行為の出来事の全体的な組織は、どのように組み立てられるのか?その構造とは何か?また、どのように全体構造の配置が、その構造と、シークエンスや順番としての会話を知らせるのか? 

\end{itemize}

以上に見るように、会話分析の対象は「会話構造」、つまり、どのように会話が開始され、行われ、広がり、発話内の問題を解決し、終了に持ち込み、何らかの行為を達成したり会話全体を認識させるのか、ということにある。本論文では会話自体は主要な研究の対象ではないため、そのすべてには触れない。しかし、会話構造のもっとも基礎的な部分、つまり、シークエンスの組織化と隣接対に関して述べる。

会話分析においては、会話の録音と、それを文字に起こして分析を容易にするトランスクリプトが分析の基礎になる。先駆的な研究によって、会話の組織化には発話の間や複数の発話のオーバーラップなどが有意であるということが明らかになっている。これらを含めて書き起こせるようにしたのが、Jefferson Systemであり、後の相互行為分析に使われるトランスクリプトでもその拡張が使われている。特有の記号などについては実際の分析で必要なものをその都度説明する。 

\subsection{会話の順番取りシステム}

会話構造は、シークエンス、つまり個々の発話や相互行為が、時間的な前後関係の繋がりをもった形で組織化されているという特徴がある。このシークエンスの組織化そのものが、会話分析の主要な研究対象の一つとなる。その顕著な例が、複数の人間がいる状況で、次に誰が話すかという問題である。Sacks、Schegloff, Jefferson(1974)は、会話の順番取りシステムの導入により、これに最初に取り組んだ。

Sacksらは、多くの録音データの中から順番交代に一定の規則があることを発見した。これに彼らは社会学的な関心を寄せた。その理由は、まず順番交代が組織だっていることである。順番交代が多様であるのに対し問題なく行われるということは、順番交代の方法の組織化の研究へとつながる。また、順番交代組織は文脈から自由であり、かつ敏感である。会話は「状況の中にある」が、会話の参加者は多様であり、状況の変化にも対応できるためである。

彼らが会話の中に見出した順番取りシステムのモデルは以下のようなものである。

\begin{verbatim}
ターン構成成分:ターン構成ユニットのタイプと、その完了点は予測可能である。順番を獲得すると、その一つを産出する権利を得る。単位を産出すると、そこが移行が適切となる場となる。
ターン配分成分:ターンの配分は、現在の話し手が次の話し手を選ぶ(他者選択)か、次の話し手が自分で自分を選択(自己選択)する。
順番交代は、以下の規則に従う。上から順番に優先される。
(1)最初のターン構成ユニットが完了点に達し、最初の移行が適切となる場に到達したとき
   (1a)他者選択が行われた場合、選択された話し手が順番を獲得し、移行はその場で生じる。
   (1b)他者選択が行われなかった場合、自己選択を行ってもよく、自己選択が行われた場合、その話し手が順番を獲得し、移行はその場で生じる。
   (1c)他者選択も自己選択も行われなかった場合、現在の話し手が話しつづけてよい。
(2)最初の移行が適切となる場で(1a)(1b)が行われなかった場合、(1c)に従って現在の話し手が話し続け、次の移行が適切となる場で(1)の諸規則が適用される。最終的に移行が行われるまでそれは続く。
\end{verbatim}

この順番取りシステムの特徴は、「局所的に」「相互行為的に」管理運用されるということである。まず、順番を1つ(次の順番)しか扱えない、包括的、排他的、逐次的なシステムであるため、局所的なシステムと特徴づけられる。このため、システムは多様性を受け入れる。また、このシステムの執行は参加者自身に委ねられる。相互行為的な側面は、参加者がシステムを用いる際に、他の参加者の貢献を考慮しなければならないことからわかる。順番の大きさや順序は、「受け手に合わせてデザイン」される。これが、会話を「聞く」ことへの同期につながる。

\subsection{隣接対}
一方で、基礎的には隣接している2つのターンが持つ構造が、「隣接対」である。(Schegloff 2007: 13-21)に沿ってまとめる。隣接対は、以下のような特徴を持つ。

\begin{itemize}
\item 2つのターンからなる
\item 異なる話者からなる
\item 隣接している
\item 最初の対のパーツ(FPP)と次の対のパーツ(SPP)からなる
\item 対のタイプに関連する:対には「挨拶-挨拶」「質問-応答」などの型があり、ある型のFPPの次には同じ型のSPPが来る
\end{itemize}

隣接していることは、「相互行為の中のトーク」が組織され、理解される中心的な方法である。隣接性は次のターンが前のターンに「関連して聞かれる」ことと明らかに関わっており。次のターンは、話者の直前のターンへの理解と、またその理解に沿って直前のターンに応答する行為を示すものとして、他の参加者に理解される。これは、次のターンの存在、前述のターンが1つずつ順番に起こることに支えられている。隣接対は、強力な「将来の操作」を持つ。FPPが予期の適切性を投射、つまり次のターンに何が来るのが適切かを制限する。

順番交代の組織化は、言われていないこと、されていないことなどの「ネガティブな観察」を可能にする。とはいえ、そのようなことは無限にあるため、その観察には「適切性の規則」、つまり起こったことを適切であるとできる規則を必要とする。これがあるため、起こらなかったことが「欠如」となる。逆にその「適切な欠如」がその規則の観察を可能にする。隣接対はその強力な手段となる。FPPによってSPPが制限されることを「条件付き適切性」と呼ぶ。次に来るはずのSPPが来ないという事態、さらに誰も話していないと言う事態も、「FPPによって期待されるSPPがない」と観察可能である。また、次のターンは、例えば普通の質問への回答でなかったとしても「直接的でない」SPPとして受け取られる場合もある。会話の中の配置がそれを決めるのである。

ここでは述べないが、隣接対は徹底的に付け加えられ、中に更なるシークエンスが挿入され、修復され、さらには会話自体を開始したり停止させ、会話を完成させる。しかし、その中の隣接したターンを分析することは、何がその会話でなされているかを理解する強力な道具となる。会話は、社会的な相互行為の中でも中心に位置する。その中での隣接対という「説明」を分析するということは、その場面の局所的な秩序の解明につながる。

\section{相互行為分析}
「相互行為分析」は、主にGoodwin, Heathらによって始められた、会話も含めた身体的相互行為をビデオによって分析する方法である。対面した相互行為では、会話の書き出しだけでは発話のポーズなどを説明できない場合がある。もしくは、会話がなくても何らかの相互行為を組織させる、ということはよくあることである。相互行為分析は、前述の会話分析の拡張ではあるが、環境、指示などのあり方にさらに迫ることができる。　

\subsection{発話から身体的相互行為へ}
視線や指差しへの研究者の注目は、会話分析の中の、特に順番交代やトラブルについて解明する作業から始まった。GoodwinとHeathの初期のこの種の研究について少し触れる。Goodwinは、発話の開始の際の間、途中で発話を止める「ポーズ」、途中の発話をやり直す「再スタート」などの、一見して発話の中のトラブルと見える現象に注目した(Goodwin 1981)。これらは、秩序が壊れているということではなく、それ自体秩序だった現象である。しかし、その秩序は音声発話の中のみでは解明することができなかった。 

その秩序を見るために、Goodwinはビデオ撮影によるデータの収集を行い、視線と発話の前後関係を詳細に分析した。その結果、話者が受け手の視線を維持することを気にかけ、それに合わせて、あるいは戦略的にポーズや再スタートを用いることがわかった。1つ例を見る。

\begin{figure}[!h]
\begin{verbatim}
(4) DEBBIE:  Anyway. (0.2) Uh:, (0.2) We went t- I went ta bed
                                             [
    CHUCK:                                    X_______________
\end{verbatim}
\caption{再スタートと視線の獲得、(Goodwin 1982)より引用}
\end{figure}

この例では、CHUCKが視線をDEBBIEに向ける(X)直後にDEBBIEが再スタートを行っている。このような再スタートに見るように、話し手は聞き手に合わせて発話を産出しており、視線の獲得の問題がその一つになっていることがわかる。一方で、話し手は聞き手をただ見ているわけではない。この例とは違い、話し手が先に再スタートを行い、聞き手が視線を向けることがある。この場合、「呼びかけ-応答」連鎖のように、「再スタート-視線」という連鎖が起こっている、つまり視線の獲得の「ために」再スタートを行っていることが示唆される。このように、話し手と受け手が相互に調整しあいながら会話を作っていくことを、視線から見て取ることができる。

一方、Heathは次の話者を選択する際の「受け手性」の問題に目を向け、それが身体的相互行為と関連していることを発見した(Heath 1982)。相互行為においては行為がどう受け取られ、注目されるかが焦点となる。「次のターン」の選択はその重要な例である。また、次のターンにおいては話し手も、どう他の参加者が発話に注目しているかを判別するため、他の参加者の行為を志向する。ここに、話し手が参加者がどう受け手性を表示しているかを研究することで、相互行為について解明する動機が生まれた。子の問題に取り組むためにHeathが利用したビデオデータは病院の診察場面で、主に診察が始まる、患者が部屋に入り初めてから本題の診察が始まるまでを分析している。 

診察という「話題」は、単に診察室にいるから始まるというものではない。話題の開始には「挨拶」などの会話の開始や、話題が開始するターンが適切な位置に置かれる必要があることは既に電話会話などで示されている(Schegloff 1972=2003)。この話題を開始する際に、患者はドアを開け、椅子に座る。この際、電話会話のように話し手への注目が維持されているとは限らない。 

診察場面の一例を参照する。 

\begin{figure}[!h]
\begin{verbatim}
   01    (door opening)
   02    (0.5)
   03 D: Hello
   04    (2.3)
   05 D: Mohammed Oola?
   06 P: Yes
   07 D: Yes could you sit down (.) please
   08    (7.3)
   09 D: What can I do for you?
   10 P: ゜hhh (0.2) um:: (0.7) um: last week in
   11    our::::fff holiday (0.7)
\end{verbatim}
\caption{診察場面での受け手性の表示、(Heath 1992)から引用}
\end{figure}
患者が入ってきて挨拶を交わし、医師が座るよう促す。その後、「どうされました」と医師が話題を開始するまでに7.3秒の沈黙がある。この部分をさらに詳細に見ると、以下のようになる。 

\begin{figure}[!h]
\begin{verbatim}
  D reads records
  ---------------------------------
  D:,----------,----------,--- what can I do for you ?
                            ..___________, ,
    ↑                   ↑↑
    P lands and        posture and
    posture shifts     then gaze
    away               shift towards
                       D
\end{verbatim}
\caption{診察場面での受け手性の表示(詳細)(Heath 1982)より引用}
\end{figure}

話題開始ターンの2.3秒前、患者は医師の後方に座る。患者は医師を見てから目を背け、前に動き、もう一度後ろに言ってから前に戻る。そこで患者は医師を見て、医師は即座に話題開始ターンを始める。以上の身体的動きより、まず最初の5秒で患者は医師と共在を達成し、診察開始への応答可能性を提示する。しかしそれに医師は即座には応答せず、次の2.3秒の間に患者が応答可能で、医師が発話を開始できるようになったことが分かる。ここで、患者は視線と身体の向きを通じて、受け手性を提示している。患者の視線の動きと医師の発話の開始が即座に併置されているからである。応答可能性は医師の発話のターンに見て取れる。応答可能性が開始する前の起こりうる範囲の行為の環境を提供するのに対し、受け手性は実際に特定のシークエンスを開始する。このように、ある発話の受け手はその相互行為によって受け手として認識される。

\section{様々な実世界の環境に関する概念}
CSCWにおいては、認知科学的な概念を用いて議論がされることが多い。特にいくつかの概念については、相互行為分析などによって深く検討された概念もあり、CSCWにおけるエスノメソドロジー研究においてよく使われている。本節では、そのような概念について検討する。

\subsection{エコロジー}
\subsection{アウェアネス}
アウェアネスとは、「人がそこにいる」という感覚である。これは、対面以外の環境では失いがちなものである。

リアルタイムチャットシステムを例に取ろう。基本的に、チャットシステム自体ではアウェアネスは「ログインしているか否か」以外を判別できない。ログインしていても、ユーザーに見えない状態では事実上何もわからないことになる。例えば、複数の部屋と場所にまたがってチャットを使う場合を想定する。参加者は各々が芸術展示の準備をしており、タスクなどが割り振られておらず好き勝手に出入りして、作業をするものとする。その場合、必ずしもユーザーがチャットの前にいるとは限らず、寝ているかもしれない。

この状況で、チャットで誰かに連絡を取ることを考える。もし相手が呼びかけに応答しない場合、複数の可能性が考えうる。これを何らかの形で識別し、解決しなければならない。その一つが、「同じ場所の別の人間に頼む」ということである。しかし、もし頼んだ人間と連絡対象が別の部屋にいた場合、部屋を移動しないと連絡を取ることができない。結果として、チャットシステムでのアウェアネスの問題を、人が実際に移動するという身体的手段で解決することになる。この場合、解決が可能である分、むしろ別の場所にいた方が手間がかからないことになる。

\subsection{コンフィギュレーション}

\chapter{エスノメソドロジーの実世界志向インタフェースへの適用}
本論文の目的は、空間を扱うようなシステムがどう使われるかを解明することである。しかし、システムに分析者が関わることのできる手段は一つではない。例えば、自分でシステムを作って分析する、システムを作るプロジェクトに参加する、既にあるシステムが使われる場面に参加するなどである。また、これらの手段によって場面が異なるため、分析の方法や分析者の役割にも大きな違いがある。本章では、システムに関わるエスノメソドロジーの様々な側面についてまとめ、その可能性を検討する。

\section{エスノメソドロジーとCSCW}

CSCWは、エスノメソドロジーが深く関わることのできた分野である。その動機は、まずその場面で行われている作業を理解できるということ、また、物理的環境で、どう人々が発話と身体的な相互行為を組織化させているかを理解できることである。本節では、既に行われたCSCWへのエスノメソドロジーの貢献について、特に一連のワークプレイス研究と前述のHeath, Luffらの相互行為分析に焦点を当てて検討する。

\subsection{遠隔システムの相互行為分析}
Heath, Luffは、前章で取り上げたようなテーマを拡張する形で、メディアスペース、つまり映像と音声を用いた遠隔コラボレーションシステムの分析を行った。EuroPARCでは2つのオフィスが回線でつながれており、研究者とスタッフが映像と音声でコミュニケーションを取ることができる。

(Brownらの地図に関する研究) 

(Kirkらのテーブルトップの実験) 

\section{エスノメソドロジーが貢献しうる役割}
エスノメソドロジーによる共同作業システムの分析がどのような役割を果たすかに関しては、いくつかの見解がある。これは後述するデザインプロセスの問題にも関連している。

Buttonによるまとめ(Button 2009: 39-43)では、エスノメソドロジーのワーク研究が設計の目的に対して使われる際には、4種類の使い道があるとしている(Button 2009: 39) 

\begin{itemize}
\item  批判:既存の設計手法で作られたワークフローシステムは、実際の場面に導入された場合に、詳細な分析をした際に明らかになるような、作業の組織化の状況に埋め込まれており即時的な特徴のために困難に直面してしまうということを示すために用いられる 

\item  評価:特定の技術デザインを評価するために用いられる。実際のワークプレイスにシステムを導入した際に得られたデータを分析し、システムの改善に活かす。 

\item  要求:実際のワークプレイスを分析して得られたデータを元に、システムの要求を決める。 Bentley1992 によれば、ワークプレイスの分析は要求を詳細に定義するのにはあまり有用ではないが、設計の際の適切な意思決定を提供する。 

\item  基礎的な関係:設計者とワークプレイスの分析者 

\end{itemize}

\section{システムデザインへの適用}
相互行為分析などの、エスノメソドロジーに影響を受けた手法(Ethnomethodology-informed Ethnographyや、会話分析なども含む)をどう実際のシステム設計に取り入れるかに関しては、その当初から議論が存在する。前章ではシステムが関わる状況でのエスノメソドロジーについて検討したが、分析のアウトプットは必ずしも設計者の関心の中にないかもしれない。例えば、あるタスクを行わせて各段階での作業時間を計測することは、システムの評価に有用だろう。また、新たなシステムを設計するために以前のシステムについてインタビューを行ったり、SD法によって感性を調査することは、少なくとも筋が通っている。しかし、エスノメソドロジーや相互行為分析に関しては、前章で見てきたように、単純に「実際の環境での使用を見る」「日常生活について理解する」などの視点で見ることができない。何より、分析結果が単純に何が良い悪いということを必ずしも提示しない。 

そのような前提を元に、エスノメソドロジー的調査はどう行えばよいのだろうか。その中には、完全に設計を無視して行う方法から、設計の際に必要なことだけを集中的に分析する方法まで多様な可能性があり得る。また、それに応じて分析の設計に対する位置づけも変わってくる。本章では、エスノメソドロジー的分析の知見のシステムデザインでの位置づけられるか、システムデザインのプロセスの中の分析と分析者の位置づけ、またその実例について検討する。 

90年代の論文(Suchman, Button, Hughes etc.)
00年代の解説書(Crabtree, Randall) 

10年の入門書(Button, Heath)
Button「Studies of work and workplace in HCI」
1.motivation
■Grudinの「HCIのfifth stageはユーザーとの対話だ」はwork settingへの注目を意味するが、それはCSCW、特に社会学と共同した分野である。社会学の中でも、経験的なアプローチが理論より好まれる。
■Suchmanは、従来のHCIにおける認知科学的アプローチ、つまりユーザーを単独で見ることに対抗し、「使用」の社会的文化的状況という視点を導入した。一方、CSCW分野でも、人々の共同作業を促進するには、認知科学的モデルは適切でないことがわかった。Suchmanはそれに対してEMCAによる経験的研究という指針を示した。このほか、スカンジナビアのParticipatory Design運動は、技術開発における、ユーザーの作業状況での使用の重要性を指摘しつづけてきた。
2.Overview: A Paradigmatic Case
■HCIに対するワークの研究の適用は、システムへの批判につながる場合がある。Suchman-Winograd論争の事例。Bowersらの研究では、印刷作業が今までどうだったか、システムが導入されたらどう変わったかを分析した。システムが導入されたら、円滑な共同作業が妨げられてしまった。この原因は、設計者がワークフローを強制してしまったためだった。様々な過程は、状況に合わせられなければならない。そのためにうまくいかせるプロセスがあったはずだが、たまたま起こらなかったためにシステムに反映されなかったのだ。
■ワークの研究は、組織化をうまくいかせるやり方を明らかにする。それは、デザイン方針への批判だけでなく、それをうまくいかせることにもつながる。
4.Detailed description
1.批判:Suchman-Winograd論争
2.評価:Disembodied Conduct→読むか
3.要求定義
4.基礎的関係:Technomethodology 

\subsection{反復型開発と日常的場面、実験}

\section{新しいシステムが使われる場面の観察}
\subsection{イベントの開催による日常の観察}
新技術は、ある日突然日常生活に導入されるわけではなく、いくつかの一般の人間が触れられる領域にまず導入される場合がある。その一つが、エンターテインメントである。エンターテインメント分野は、ユーザーインタフェースやバーチャルリアリティの一般分野での最前線と言える。例えば、最近だと「戦場の絆」や「Kinect」は未来に近い一例である。 

このような場はエスノグラファーが新技術が導入された現場を観察できる、貴重な場となりうる。前節までに見てきたように、システム開発においてエスノグラフィーを行う方法は、実験的状況での特定のタスクの観察と、純粋に現在行われている日常の作業場面の観察に分かれている。その2つの折衷策として、Benfordらは、イベントやアート展示などの分析が、実験的な状況と日常生活の架け橋となることを提案している (Benford 2002) 。バーチャルリアリティやインタラクティブアートの展示会は、しばしば一般人が新たな技術に触れる機会となる。技術を「展示」することで、Benfordらは以下のような利点があるとしている。 

\begin{itemize}
\item  外に出すため、技術を曖昧な概念ではなく、詳細な領域まで落とし込める 

\item  実際の環境で評価できる。公共的な場を研究に巻き込むことが出来、また一般人に新技術のインパクトの理解をプロモートできる。実験では得られない忌憚なき意見も聞ける 

\item  芸術やエンターテインメントの創造性は、新たなアイデアを育てる土壌となる。また、芸術家の持っている技術を研究に利用できる 

\end{itemize}
((Benford 2002) より著者が要約) 

一例を挙げる。Crabtreeらは、「Can You See Me Now」という、位置情報ゲームとバーチャルな都市空間を融合させたゲームを開発し、そのイベントを開催することで、多くの一般人が新しい技術に触れる状況を観察した (Crabtree 2004) 。彼らは、ゲームの中のRunner(主催側の参加者。GPSを持って街を走り、別のRunnerと協力しながらPlayerから逃げる)をビデオで撮影し、通信を録音し、Player(実際の街を再現した3D環境をFPSのように操作し、Runnerを探す)の行動のログを取った。その結果、(この辺Macからサルベージする必要がある) 

\subsection{HCI研究展示のインタラクティブアート的なあり方}
ところで、実際に日本国内でこのようなイベントが行えるかに関しては、いくつかの問題がある。HCI/CSCW研究を外に出す一つの手段が、学会発表であり、そのうちの幾つかは一般に開かれている。恐らくそのような場でユーザーの観察や、ビデオデータなどの取得は可能であると推測される。例えば、「インタラクティブ東京/IVRC」や「インタラクション」などはその一例であるといえる。 

一方で、このような場で多人数を含んだ形でのインタラクションの観察を行うことは難しいと考えられる。というのも、実際にどのようなシステムを扱う論文が通過するか、に関わらず、展示を行うスペースが1ユーザーのインタラクションを想定して設計されているためである。例えば、「インタラクション2011」の「インタラクティブ発表」で通常与えられるスペースは長机2つ程度である。 

このような展示の背景には、SIGGRAPHの影響があると考えられる。SIGGRAPHはもともとACMのコンピュータグラフィックスを扱う分科会であったが、2章に見るような技術的変遷から、ヒューマンコンピュータインタラクション、バーチャルリアリティなども扱っている。一方、SIGGRAPHはインタラクティブアートの主要な展示会でもある。実質的に、SIGGRAPH、もしくはそれに類似した学会発表での展示の場は、インタラクティブアートの展示と似通っている。すなわち、数平方mのスペースで1人が鑑賞を行うというスタイルである。 

以上のような事情から、現状で拡張現実感を使った遠隔共同作業システムなどを、イベントの形で提示することは難しい。一方、このような状況を打破するような展示の試みは、別の形式の芸術展示から得ることができる。 

著者も参加した藤城嘘、黒瀬陽平らのキュレーションによる企画展「カオス*ラウンジ」は、ギャラリーという空間に日常生活そのものを取り入れた展示である。カオスラウンジの全体のコンセプトは、一言でまとめると「Webサービス上で行われるコラボレーションの可視化」である。 

例えばpixivなどのWebサービスでは、ユーザーが絵を投稿することができ、それを例えばキャラクターなどのタグによって一覧することができる。一方、このような絵を「芸術表現」と呼ぶのは難しい。タグによって表示される大量の画像の中で、「作者」を鑑賞者が意識することが極めて薄れているためである。一方で、このような状況下で、日々新たな絵が生まれ、コミュニティが曖昧に増殖していく。 

一方で、pixivにおける作者は、自らこのような状況で匿名の作品を収集するとともに、それを元に作品を製作していく存在である。多くの作品に曖昧に影響を受けながら、自身の作品を製作していくという、極めて薄い層のコミュニケーションがpixivの特徴である。「カオス*ラウンジ」は、このような状況自体を可視化する目的で行われた。 

カオスラウンジは当初はライブペインティングの形式を取っていたが、日常的にツールを活用しながら現実空間で集まっている、元々接点のなかった先端的なインターネット利用者の集団「破滅クルー」をメインにした展示「破滅*ラウンジ」(2010年5月)では、ギャラリーそのものの枠組みを破壊する試みが行われた。元々破滅クルーは「ギャラリーで開催期間生活する」という参加の形式を取っていた。生活を送ることにより、ギャラリーがネット利用者の色に染まっていくことを意図した展示であった。これはいくつかの現代美術にも見られる形式である。しかし、破滅クルーはそれとは別にいくつかの「作品」を展示した。これにより、ギャラリーには「破滅クルーの生活」を含めて作品、展示、生活の区別がつかなくなった。 

その要素自体を分析して再現したのが、2010年12月に開催された「【新しい】カオス*ラウンジ【自然】」である。この展示では、作品との1対1の対峙としての鑑賞を意図的に排除するように、空間自体が設計されている。例を上げれば、入り口の仕切りとディスカウントストア「ドンキホーテ」のような圧縮陳列の採用などがこれにあたる。 

この例に見るように、実世界指向のインタラクションがしばしば目指すような「コンピュータが見えなくなる」という展示を、現在ありふれた展示空間で行うことは可能である。もっとも、このような空間にどう分析者が入っていけばいいかに関しては検討の予知がある。 


\chapter{フィールドワーク:ジオジオスタンプラリー}
これまで見てきたように、あるシステムが使われる状況をビデオに撮影し、分析するということは必ずしも定型的な作業ではない。本研究では、特定の場面やシステムに対して分析を行うのではなく、複合現実感や位置情報技術など、比較的漠然としたコンセプトでまとめることのできるシステムを、どう分析することができるかということを検討するのが目的である。 

現在，iPhoneやスマートフォンなどの高度な携帯電話端末が，一般ユーザーに普及している段階にある．これらは，通話やメールなどの枠を遥かに超え，「セカイカメラ」などの位置に対応した情報をカメラ映像に重ねる技術など，従来からMixed Realityと分類されてきた技術を，エンドユーザーにまでもたらしつつある．現在は未だ普及の段階にまで達していないが，実世界とオンラインを結びつける試みに，携帯電話は今後も重要な役割を果たす可能性がある． 

一方で，実世界の環境で，携帯端末がどう使われるかに関しては，十分な検討がされていないと見られる．携帯電話には，一人で画面に向き合うだけではなく，例えば電車内で若者が携帯電話に表示されたメール，画像などを見せあっているように，複数人で，場面に応じて共同的に利用するものとしての側面がある．本論文では，実際に携帯端末がどのように複数人によって，実世界の場面の組織化に利用されるかに関して，詳細な分析を行う． 

\section{フィールドについて}
屋外での情報機器の使用を観察する際は，公共のイベントなどの利用が有効である．実際の研究としては，Can You See Me NowというMixed Reality Gameの分析が挙げられる．2009年現在，国内ではその一種と言えるiPhoneを利用した位置情報ゲームが複数行われ始めている． 

本研究では，「ジオジオスタンプラリー」という，レーダーのような形式で提示されたポイントの情報やヒントを頼りに，宝探しを行うゲームの調査を行った．これは2009年7月20日に行われた，全体で50人程度が参加したイベントである． 

参加者はGPSの専門スタッフ1人を含む5人程度の8つのチームに分かれ，各チームにiPhoneが1台配布された．iPhoneにはDGRadar（図）がインストールされており，それを用いてゲームを行う．DGRadarはGPSで現在位置を取得し，レーダーのように現在位置を中心として，周辺（拡大縮小可）の登録されたポイントへの方角・距離と画像などの付加情報が表示されるアプリケーションである． 

実際に行われたゲームは，（１）立教大学キャンパス内での人形探し（２）都電沿線でのスタンプラリーの2つであったが，本論文に関連する前者についてのみ記す．人形は1cm程度の高さのアヒルであり，マグネットによって金属部分に接着可能である．この人形がキャンパス内の5カ所に配置され，それぞれのポイントの位置情報のみがDGRadarに登録された． 

各チームはこのアヒルを30分程度で可能な限り見つけるというルールであるが，特に勝敗などを決めるものではなく，純粋に楽しむ目的のものであった．ゲームの終わりに全員集合し，各チームの結果や動いた軌跡などを主催者が発表した． 

本イベントには，田島が技術サポートの集団の一人として参加しており，その中で企画者に調査の提案をした．参加者には最初に集合した際に調査内容に関して説明を行い，全員に口頭で撮影の許可を得た．その後，1チームに対して全体で30分程度，小型のデジタルムービーカメラを用いて追跡して撮影を行った．このチームでは，持参のものと含めて2台のiPhoneを用いていた． 

\begin{figure}[tb]
\centering
\includegraphics[width=0.5\hsize]{DGRadar_image.eps}
\caption{DGRadarのインタフェース}
\end{figure}

\section{分析}
本研究では，携帯端末の使用を，人々の共同作業の相互行為的な達成の観点で分析した．すなわち，単に一人で画面に向き合い，画面上の情報とインタラクションを図るというだけでなく，周囲の環境/人間と協調しながら，実世界に関係する作業を達成していくという観点である． 

共同作業の達成を分析するにあたり，社会学のエスノメソドロジー的な相互行為分析の手法を用いた．これは，ビデオデータなどを用いて，その場に居合わせた人間の会話，指さしなどの身体的な相互行為が，継起的な秩序の中でどのように組織化されるかを分析する手法である．本研究では，特にiPhoneやその使用が，環境の中でどのように見られ，相互行為の中に組み込まれていくかに焦点を当てる． 

\subsection{指さしによる環境の指示}
Goodwinは，環境の特定の対象を指す種類の指さしをSymbiotic Gestureとし，会話と全く異なる記号であるが，会話と協調して使われるものとしている．「ジオジオスタンプラリー」で見られた指さしは20件あったが，そのうちの10件がDGRadarを参照した「方角」の指示であった．典型的なものを断片1（図）に示す．以下では，Aの持つiPhoneをiA，Bの持つものをiBとする． 

\begin{figure}[tb]
\centering
\small{
\begin{verbatim}
p 指さしの方向
----
01 A|一番近いのは::番号では38メーターっての=                                      
  Ag|iA-------------------------------------
02 A|=があった
  Ag|iA-----------
  Bg|        ,A---
03 A|(4.5)
  Ag|iA----------------------------
  Bg|A-----------------------------
  Bm|((Bを見ながらBに向かって歩く))
04 A|38メーターってのがあった(.)向こうに
  Ag|iA--------------------------,p-------,iA--
  Ap|                        ,,,,,,p-----------
  Bg|                                ,,,p----,,
\end{verbatim}}
\caption{断片1}
\end{figure}

\begin{figure}[b]
\centering
\includegraphics[width=0.7\hsize]{seeing_filtered.eps}
\caption{iPhoneを見ていることの提示}
\end{figure}

\begin{figure*}[t]
\centering
\small{
\begin{verbatim}
Am:((道路の方向を指さしている))                          ((              止まりiA見る               ))
Bm:      ((A見る))((指さし方向見る))((停止，A向きiB見る))((iB指さす))    ((iB見ながらAに向かって歩く))
\end{verbatim}}
\caption{断片2}
\end{figure*}

Aは自身のiPhoneを見ながら，次のポイントを発見して報告する．Bはそれを受け，Aの方向を向いて歩き始める．その途中で，AはiPhoneを継続して見ながら，ポイントについてもう一度報告し，一度iPhoneから目を離してポイントの方向を指差し，またiPhoneに視線を戻す．Bはそれを受け，指さしの方向を見てから二人とも歩き始める． 

ここで注目する点が，断片1の2,3行目でAが自身のiPhoneを見ているということを，Bが見ているということである（図）．これにより，Bはその後の指さしがDGRadarの提示するポイントを指していることを理解できる．「向こうに」に伴った指さしは，特定の物体や，道路に沿って指したものではない．iPhoneの，方角を提示するDGRadarを見ているということを見た上で，方角を提示していると，意味のある形で理解できるのである． 

「方角」と，進むべき「方向」は相互行為の中で明確に区別されていた．DGRadarを見た後の指さしと共に「曲がってってもいいんじゃない」という発話を行い，その後チームで建物を迂回する例が見られた．指さしは表示の方角を指しているが，その先には建物があった．このため，「あっち」「東」などの方角ではなく，「曲がってって」という発話が行われた．方角を，進むべき方向に再構成して発話を行ったのである． 

iPhoneを見ているということにより，見ている人の体の向きが，DGRadarの方角を指していると見られた場合があった．ある場面では，Aは最初道路に沿って歩いていたが，iPhoneを覗き込んで横を向いた．それを見た他のメンバーが，向いている方向に歩き始めてしまった．それを受け，Aは「あ，違う，真向こう，真向こう，真向こう，向こう」と訂正を行い，本当にDGRadarが提示している方角を指さす．この場面ではAの見ているiPhoneと，メンバーが利用する資源であるAの体の向きという，2つの異なるエコロジーが問題を起こしている． 

以上のように，ジオジオスタンプラリーではiPhoneを見ていることと，指さしや身体的配置は，関連づけられて理解されていた． 

\subsection{2台のiPhoneによる問題解決の試み}
ほとんどのチームで，GPSの精度の問題が発生していた．GPSの誤差は明確には表示されていなかったが，チームの相互行為の中で，複数のiPhoneを用いて明らかにした部分があった．断片2（図）はもともと進んでいた方向の異常に気づき，集合する直前のデータ，断片3（図）は集合してから問題解決を始めたデータである． 

\begin{figure}[b]
\centering
\small{
\begin{verbatim}
01 A|ずっとこんなんだよ=
   B|                  =北え？きた？
   Bm|                         ((iA指差し))
02 A|北こっち
  Am|  ((iA指差し))((北を指さす))
  Bm|--------
03 B|えっとだからー
  Bm|------(なぞるような動き)
04 A|うん
05 B|これ(　　)まがって，方角的には
  Bm|------------------------------
06 B|=どっちなんですか
  Bm|-------,,((指iから外す))
07 A|え::と方角的には::(.)え:=
  Am|,,,,,,,,,,,,,iA---------
08 A|=:と(2.9)
  Am|((i覗き込む))((体の向き動かす))
  Bm|             ((体の向き動かす))
09 A|イースト(2.6)
  Am|,,,,,,,((東指さす))
10 B|イーストって::っと
  Am|(iをAに持っていく)
11 A|は:い
  Bm|     (i受け取る)
12 B|こうなって
  Bm|        ((体の向き動かす))
13 C|今，衛星状態が非常に悪いんですね
\end{verbatim}}
\caption{断片3}
\label{}
\end{figure}

\begin{figure}[b]
\centering
\includegraphics[width=0.7\hsize]{kita.eps}
\caption{2台のiPhoneでの問題解決の開始}
\label{}
\end{figure}

\begin{figure}[tb]
\centering
\includegraphics[width=0.7\hsize]{2dai2.eps}
\caption{平行になるようにiPhoneを渡す}
\label{}
\end{figure}

当初2人が別のiPhoneを持って歩いており，Aが指さしで先導していた．しかし，BがAの指差しの方向を見て，iBと照らし合わせ，Aに見える形でiBを指差す．Aは止まりiAを見て，BはiBを見ながらAに向かって歩き始める．それを受けてチーム全員が集合する． 

集合後，1行目の発話で，Bの胴の向きがAのiPhoneへ向かい始める．Bの「北」の発話の段階では，Bは自身のiBを見ているが，iAを見て「きた？」と言いiAを指差す（図6）．その後ジェスチャーで2台の向きの違いを指摘し，iAの指す方角を聞く．それを受けたAの「イースト」の発話と指さしの後，iPhoneをBに手渡し，並べて見る．そこで初めて，専門家であるCが衛星状態について述べる（13行目）． 

注目する点は2つある．まず，どのようにBがAのiPhoneを参照する状況ができたかである．集合前に既にBはiBの異常を示していたが，01行目と胴の動きでiAを見る準備がされている．その後，「北」でiBの表示の具体的な内容を示す．その後の「きた？」でiAを指差したことで，iAとiBの違いが示される． 

次が，2台のiPhoneの比較である．iAとiBの表示の違いは理解されていたが，具体的にどう違うのかは，恐らく2台のiPhoneの向きの違いから，直観的にはわかりにくかった．03行目のなぞる動きや，06行目の「どっちなんですか」10行目の「てーと」という疑問がそれを示している．その直後，AはiAをiBと平行になるようにBに渡す（図7）．2つのiPhoneの示す方角は，既に「北」「イースト」で示されている．しかし，精度を問題にする場合，2台を比較可能，つまり平行にすることが必要であった．Cによる専門的な指摘は，2人の比較を見た直後である． 

\section{まとめ}
本調査では，GPSを用いた宝探しゲームの中でiPhoneが環境の中でどのように理解され，複数人の相互行為の中に組織化されていくかを分析した．以下に分析の知見をより一般的な形でまとめる． 

\begin{itemize}
\item  携帯端末を見たり操作していることは，他の参加者が見ることができ，使用者の身体的相互行為は携帯端末に関連したものとして理解された． 

\item  身体的配置により，誰かが使っている携帯端末は他の参加者にも利用可能になった． 

\item  複数の端末などがある場合，それらの配置が問題になり，調整される場合がある．また，それも見ることができる． 

\end{itemize}
本分析の知見は，ゲームという特殊な設定の元でのものであるが，携帯端末を見ながら何かを行うということは，位置情報に限らず表示された文書，画像などに関連したものであることが示唆される．例えば「セカイカメラ」の場合，表示されたエアタグを実際に見なくても，ある程度近くにいれば，体の向きからどの方向のエアタグを見ているのか瞬時に理解できる． 

また，例えばiPhoneの場合電子コンパスや加速度センサで，表示を回転させることが可能であるが，これらは持っている人の向きのみを反映でき，他の人間の身体の志向の反映は難しい．場合によっては渡すなどのインタフェース外の相互行為を考慮した設計も必要だろう．このように，本知見を通じて既存のシステムを再検討することも有効である可能性がある． 

(オチる) 

\subsection{これによって何がわかったのか？}
このフィールドで行われたことは、ゲームであり、位置や方向の特定という問題の解決であり、iPhoneの使用である。これらは単純に平行しているわけではなく、例えばゲームで点を取るために位置や方向を特定し、iPhoneを使用することでゲームを進めるなど相互に関係している。本分析でピックアップした断片では、iPhoneの使用を取り巻く指差しなどの身体的相互行為に主に注目した。しかし、これはiPhoneでの情報の提示が間違っているという批判にはならない。また、ゲーム全体に関わるような意思決定も主題としていない。このため、主に位置や方向の特定という問題がどのように解決されるか、ということが本分析の主要な知見だろう。これは、より外部環境のデータをセンシングして、提示するようなシステムでは身振りのあり方を考慮でき、またそれが実際に使用される場面で異なっていくということを示している。この点で、新たなシステムへの要求事項を扱っていると言える。 

一方で、この分析では本当にゲームという場面全体を記述できなかったのだろうか。宝探しという主題を元に、我々は様々な場面を想像するだろう。しかし、今回は場面で起こりうる様々な局面を厳密に洗い出し、行為のモデルを作成し、ゲームをデザインしたというわけではない。つまり、ある意味で実際に始まってみないと、ゲームで起こることは予測できないことになる。これはプレイヤーにとっても同様である。この分析で何か場面について分かったものがあったとすれば、それはまだ知られていない事柄である。 

そこでまず指摘できるのが、アヒル探しがチームの共同作業として行われたことである。これは注目に値する。例えば完全に障害物がない状況で、GPSの方角指示を元に移動を行ったとしたら、各人は同じ方向に進むため、コミュニケーションは必要ないと思われる。人が集まったら共同作業がされるとは限らない。 

そこでゲームを一種の問題解決としてとらえた場合、問題とは何かということを問うことができる。前半のキャンバス内でのアヒル探しと、後半の都電沿線での宝探しではどう問題が異なるだろうか。例えば、ゲームのルールとDGRadarを元にすれば、「方向」の問題は見えてこない。また、GPSの不具合がゲームの障害となることは容易に想像できるが、実際にゲームをどう妨げたのか、また本当に妨げたかどうかには疑問が残る。GPSの問題をお互いに共有して、方向を見定めながら移動するということは、ゲームのルールを破壊するようなことではない。むしろ、ゲーム全体の問題解決の中で、間違えながら試行錯誤していく過程の中にうまく取り込まれている。このように、「iPhoneの位置表示アプリを使った」「宝探しゲーム」の見えない特徴が本分析によって明らかになっている。 

この際、本分析はゲームの実際の達成の際の(ゲームのデザインが問題を解決するものではなく、問題をうまく作り出すことにあるという差異はあれど)問題を浮き彫りにしている。これは、ゲームの評価をしているといえ、この結果は例えば方角ではなく方向を提示してみる、GPSにわざと誤差を作っておくなどの、新たなゲームデザインにつなげることができる。 

\chapter{システムの実装と評価:セカイカンヅメ}
本章では、2010年7月に行った実験「パノラマを用いた共同作業」を取り扱う。 

\section{コンセプト}
遠隔で共同作業を行う手段には、様々なものがある。例えば音声や文字(チャット)、映像などは従来から利用されている。本実験で用いられたものは、その中でも「ものを配置する」ということにフォーカスを当て、そのために「パノラマ」すなわち360度全ての方向を写した映像を利用することを考えた。 

\subsection{Body Metaphor}
この表示の形式は、葛岡、山崎らによる一連のGestureManの研究に影響を受けた。GestureManでは、Body Metaphorという設計思想により、首に配置されたカメラを動かして様々な方向を見ることができる。このため、首の動きを見ることで指示者がどこを見ているか作業者が見ることができ、円滑な指示が可能になる。

\subsection{モバイルによる身体的指示}
一方で、現状でロボットは比較的大きなものになるため、作業場所によっては導入できるとは限らない。このため、別のインタラクションを、似たような設計論で実現できないかということを検討した。結果として首を回すかわりにパノラマの提示を、またパノラマを見ている位置を視覚的に提示する方針を採用した。 

360度の映像は、以下のような利点から、ものの配置に有用であるように見える。 

\begin{itemize}
\item  配置を行う場所の全景を見ることができる 

\item  作業者と物体、配置場所の位置関係を把握することができる 

\item  作業者に指示を行う際に、場所のどこを指すかをわかりやすく説明できる可能性がある 

\end{itemize}
一方で、以下のような問題も起こる。 

\begin{itemize}
\item  パノラマをどう表示するか？ - パノラマは元々全ての方向を写したものであるため、ただ広げただけでは、位置関係がわかりにくい 

\item  パノラマの特定の部分を見ながら指示をしていることを、どう作業者に伝えるか？ 

\end{itemize}
このような問題を解決するために、パノラマを円筒形に表示する形式を採用した。TWISTARに代表される、没入型で360度の視野を確保するシステムでは、人が円筒の中に入り、中から何らかの形で表示された360度の映像を見るという形式をとっている。しかし、この形式では装置が大規模になってしまい、場所をとってしまうという問題がある。このため、本実験で用いた表示形式は、円筒に360度の映像が表示されているのを、外から見る形式を採用した。 

これを実現するために、拡張現実感技術を用いた。ここで用いた拡張現実感技術は、ARToolKitというマーカーを使ったシステムで、民生用として一般的に用いられているものである。ARToolKitでは、以下のようなフローで現実空間に3Dの物体を表示する。 

\begin{itemize}
\item  カメラなどで映像のフレームを読み込む 

\item  画像認識により、マーカーの位置を特定する 

\item  マーカーの位置を原点として、映像に写っている空間の3次元座標を特定する 

\item  3次元空間に3Dの物体を描画する 

\end{itemize}
この3Dの物体を円筒にし、随時パノラマ映像をテクスチャマッピングすることで、先のような表示形式を実現した。これにより、マーカーが表示された位置に、円筒形のパノラマが表示される。マーカーを見る方向を変えたり、回したりすると、パノラマの別の方向を見ることができる。この方式のもう一つの利点は、パノラマのどこを見ているかを画像処理によって特定できるということである。画面の下方向が3Dのどの方向に当たるかを見ることで、ユーザーがどこを見ているかを推定し、作業者に提示することができる。しかし、この特徴は実際には時間の関係から実装しなかった。 

\section{システムの概要}
実際に実装したシステムは、指示者側、作業者側の2つに大きく分かれ、この2つをネットワークで接続することで実現している。 

まず、作業者側では、PCにWebカメラが接続され、パノラマ映像のキャプチャと送信を行う。パノラマ映像は、通常は全方位カメラ(Omni-Directional Camera)という特殊なカメラを用いるが、今回は予算の問題から(本研究は一切大学からの予算を用いていない)、市販のWebカメラと半球ミラーから自作した。WebカメラはLogicool QCAM-200Vを用いた。半球ミラーは、新宿東急ハンズで販売されているいくつかの口径のものを試し、直径7cmのものを採用した。まず半球ミラーを机などの上に設置し、Webカメラを真上から見下ろすように、ちょうど良い高さに設定すればパノラマ映像を取得できる。 

これを、PCでOpenCVという画像処理ライブラリによってキャプチャし、送信するプログラムを作成した。転送の形式はリアルタイム処理の実現のため、無圧縮でそのままフレームを送信している。 

指示者側ではPCに一眼デジタルカメラ(ビデオキャプチャにより接続)が接続され、受け取ったパノラマ映像をARToolKitによってマッピングする処理を行う。一眼デジタルカメラは近くの机に配置され、マーカーを写す。 

\section{実験の目的}
上記のようなパノラマを用いた共同作業システムには、いくつかの根本的に不明瞭な点がある。まず、複合現実感を用いたシステムの中でさらに映像合成を行っているため、システムについての理解や、システムを通じた視点の理解がスムーズに行われるのかという問題がある。これはいわゆるユーザビリティに当たる(できれば定量評価でだめな理由)。また、本システムは簡潔で、基礎技術的な位置づけである。これを共同作業に適したシステムにするために、基礎的な技術のみを用いたインタラクションについて理解することが有用である。主にこの2つを目的とする。 

\section{実験の概要}
本実験では、ミニチュアの家具を配置するタスクを、指示者、配置者の2名の共同作業によって行った。指示者は家具の配置の写真を見ることができるほか、技術的手段によって設定によっては配置の様子を見ることができる。配置者の前には家具配置スペース(紙によって示されている)と、ばらばらに置かれた家具がある。指示者と配置者は同じ部屋にいるが、お互いを見られないように配置されており、肉声によって会話をしながら家具の配置作業を行う。 

指示者の環境設定は、目の前に表示用のPC(MacBook Pro 13inch Early 2009)があり、映像やパノラマ映像が表示される。また、写真表示用のデジタル一眼カメラ(Panasonic DMC-G1)やiPhone 3GS(パノラマ実験ではデジタル一眼カメラがシステムに利用されたためこちらを利用)があり、それぞれ基本的な操作によって写真の閲覧や拡大縮小が可能である。パノラマ実験の場合は、この他にパノラマ操作用にマーカーとマーカー認識用のデジタル一眼カメラが配置されているが、配置は途中で変更した。 

配置者の環境設定は、目の前に2つの机があり、手前と奥に配置されている。手前の机では配置するためのA4の用紙や、パノラマ実験の場合は中央にパノラマ用のカメラが配置されている。奥の机には、あらかじめミニチュアの家具がバラバラに置いてある。 

実験手順を以下に示す。 

\begin{itemize}
\item  前の配置を利用しない場合、ミニチュア家具を配置する 

\item  ミニチュア家具の配置の写真を撮影する 

\item  ミニチュア家具をバラバラに奥の机に置く 

\item  被験者に実験について説明する 

\item  実験と撮影を開始する 

\item  指示者と配置者が共同してミニチュア家具を配置する 

\item  指示者が終わりだと宣言した場合、実験、撮影を終了する 

\end{itemize}
実験は、以下の3つの技術設定で行った。 

\begin{itemize}
\item  音声のみ:指示者は配置を真上から撮影した写真のみを見ることができ、配置者の状況は会話によってしかわからない。 

\item  映像:指示者は写真の他に、配置者を斜め上から撮影した映像(カメラ1をそのまま表示したもの)を見ることができる。 

\item  パノラマ映像:指示者は写真の他に、家具配置スペースの中央から撮影したパノラマ映像を、前節で説明したパノラマ映像表示装置によって見ることができる。 

\end{itemize}
以下に、個別の実験の詳細についてまとめた。 

ただし、2,3,4,6,7,8はそれぞれ実験1,2,3,5,6,7の結果を撮影したものである。 

実験に使用した写真を以下に示す。 

実験1 

\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-1-1.eps}
\caption{写真1-1}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-1-2.eps}
\caption{写真1-2}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-1-3.eps}
\caption{写真1-3}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-2-1.eps}
\caption{写真2-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-2-2.eps}
\caption{写真2-2}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-2-3.eps}
\caption{写真2-3}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-3-1.eps}
\caption{写真3-1}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-3-2.eps}
\caption{写真3-2}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-3-3.eps}
\caption{写真3-3}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-4-1.eps}
\caption{写真4-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-4-2.eps}
\caption{写真4-2}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-4-1.eps}
\caption{写真4-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-4-3.eps}
\caption{写真4-3}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-4-4.eps}
\caption{写真4-4}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-4-5.eps}
\caption{写真4-5}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-4-6.eps}
\caption{写真4-6}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-4-7.eps}
\caption{写真4-7}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-4-8.eps}
\caption{写真4-8}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-4-9.eps}
\caption{写真4-9}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-5-1.eps}
\caption{写真5-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-5-2.eps}
\caption{写真5-2}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-5-3.eps}
\caption{写真5-3}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-6-1.eps}
\caption{写真6-1}
\end{center}
\end{minipage}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-7-1.eps}
\caption{写真7-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\begin{figure}[htbp]
\begin{center}
\begin{minipage}[t]{.47\textwidth}
\begin{center}
\includegraphics[width=\textwidth]{thumb/6-8-1.eps}
\caption{写真8-1}
\end{center}
\end{minipage}
\end{center}
\end{figure}
\subsection{これによって何がわかったのか？}
まず前提として挙げておきたいのが、このシステムは元々一つの部屋を領域として、本物の家具と同じ程度の物体を配置することを目的として設計されており、ミニチュアの家具を用いた実験を行ったのは、あくまでそれを擬似的に再現したものであるということである。この場合、「映像を用いた実験」のような設定を行うことは難しくなる。映像を用いた実験では、ミニチュアの家具よりかなり高い場所にカメラが配置され、全体を俯瞰できるようになっている。しかし、実際に部屋にこのようなカメラを配置することは物理的に難しく、例えば監視カメラのような配置だと死角ができるだろう。このため、もし「パノラマを用いた実験」が「映像を用いた実験」より何らかの劣った面があったとしても、それは必ずしもパノラマシステムが劣っていることを意味しない。 

また、この実験をミニチュアで行うことが、実際の部屋で家具を配置することと異なる特徴を持つ可能性がありうる。しかし、パノラマ表示インタフェースに関しては、ミニチュア家具、展示会場、都市空間で特に特性が変わらないことを確認している(以下の写真を参照)。あまりに小さすぎる場合だと焦点距離の問題で像がぼやけてしまうが、今回の実験はA4の用紙を配置場所として選択しており、パノラマの周囲4cm(カメラの接近できる限界)には物体が配置されていない。 

\section{Mobile ARを用いた実装}
本研究では、先の実験用システムを改善したシステムを開発した。小型の端末を表示に使うことで、操作の自由度が向上した 

\chapter{結果としてのシステムコンセプトと、実装例}
\chapter{結論}
\begin{thebibliography}{99}
\bibitem[Garfinkel 1967]{Garfinkel 1967} Garfinkel, H.,1967, Studies in Ethnomethodology, Prentice-Hall
\bibitem[Randall 2007]{Randall 2007} Randall, D., et al., 2007, Fieldwork for Design, Springer
\bibitem[Button 2009]{Button 2009} Button, G. and Sharrock, W., 2009, Studies of Work and the Workplace in HCI, Morgan amd Claypool
\bibitem[Schegloff 2007]{Schegloff 2007} Schegloff, E., A., 2007, Sequence Organization in Interaction: A Primer in Conversation Analysis I, Cambridge University Press
\bibitem[Suchman 2006]{Suchman 2006} Suchman, L., 2006, "Human-Machine Configuration: Plan and Situated Action 2nd Edition", Cambridge University Press
\bibitem[椎尾 2010]{椎尾 2010} 椎尾一郎, 『ヒューマンコンピュータインタラクション入門』, サイエンス社, 2010
\bibitem[歴本 1996]{歴本 1996} 暦本純一, 『実世界志向インタフェースの研究動向』, コンピュータソフトウェア, Vol.13, No.3, pp.418
\bibitem[Ishii 2008]{Ishii 2008} Ishii, H., 2008, "Tangible User Interfaces", The Human-Computer Interaction Handbook Second Edition, Laurence Eribaum Associates, pp.470-487
\bibitem[Ishii 1990]{Ishii 1990} Ishii, H., 1990, "TeamWorkStation: Towards a Seamless Shared Workspace", Proc. CSCW 90., pp.13-26.
\bibitem[Ishii 1992]{Ishii 1992} Ishii, H., et al., 1992, "ClearBoard: A Seamless Medium for Shared Drawing and Conversation with Eue Contact", Proc. CHI92, pp.525-532.
\bibitem[Ishii 1997]{Ishii 1997} Ishii, H., Ullmer, B., 1997, "Tangible Bits: Towards Seamless Interfaces between People, Bits and Atoms", Proc. CHI97, pp.234-241.
\bibitem[Apple 2010]{Apple 2010} Apple Computer Inc., "iOS Human Interface Guidelines", (Retrieved Jan 2011,  http://developer.apple.com/library/ios/documentation/UserExperience/Conceptual/\\MobileHIG/MobileHIG.pdf)
\bibitem[Wellner 1993]{Wellner 1993} Wellner, P., 1993, "Interacting with paper on the DigitalDesk", Commun. ACM 36, 7 (July), pp.8796.
\bibitem[Benford 2002]{Benford 2002} Benford, S.D., et al., 2002, "Staging and evaluating public performances as an approach to CVE research", CVE '02, pp. 80-87.
\bibitem[Garfinkel and Sacks 1970]{Garfinkel and Sacks 1970} Garfinkel, H., and Sacks, H., 1970, "On Formal Structures of Practical Actions", Theoretical Sociology: Perspectives and Developments, edited by J.C. McKinney and E. Tiryakian, New York: Appleton-Century-Crofts, pp.337-366.
\end{thebibliography}
\end{document}

